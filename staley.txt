In this segment we'll offer some advice on how to
study for the midterms

Do the LMQ, labs, any projects due, and
in-lecture questions
Not surprisingly, the single most important
preparations for tests in this class are the lab, LMQ and project
work, and doing a serious job on the in-lecture questions.  In
particular, skipping in-lecture questions, or just reviewing the
answers without having first tried to figure them out yourself, is a
serious error.  

If you're spending up to 30 minutes per in-lecture
question, until you're quite confident of your answer, reviewing
prior lecture if needed, that's the right way to prepare for tests. 
Of course, most in-lecture questions won't take that long, but the
point is that you should be very persistent in finding your own
answers.
If you haven't been following this pattern, you
can recover partly by going back through each lecture, and trying to
answer the in-lecture questions now.  Even though you've seen
answers, remembering the answers or re-figuring them, is somewhat
helpful.  Also, try to come up with in-lecture questions of your own,
related to the ones I ask.  If you're asked to do a query, for
instance, come up with one or two others of similar complexity.

The lectures are meant to introduce major concepts
and themes, not to cover every detail of syntax, every library
function, ets.  At a number of points in the lectures there were
in-lecture questions requiring some outside research, and suggesting
you develop a list of links to good SQL resources.  Spend some time
with the outside resources you found most useful, to learn more
details on C libraries, etc.   The midterms will often permit access
to the C Reference material in the Bibliography; be familiar with
those references.

Vocabulary terms are introduced throughout the
lectures, generally marked in
this font.  Collect a list of these, and know their
definitions.  If a term is difficult to spell, be sure to get it
right. 

Many tests may include a vocabulary section, where
you're asked to give terms to match definitions, and required to
spell the terms correctly.   When you're working professionally, it's
critical to know what you're talking about, but it's also critical to
 like you know what you're talking about.  Using the
wrong term, or misspelling the right one in an Email, makes it look
as though you really don't know your stuff.  That's why we test
vocabulary.
Here's a bit of perspective on the grading process
for vocab.  When we encounter an vocab answer we didn't expect, the
graders and I use what we call the &quot;giggle test&quot;.  We
imagine you sitting at a design table in industry, using the term you
gave on the test.  If the result is a chuckle, that's bad.  (&quot;Heh
heh, just out of school, eh?&quot;).  Chuckle == no points. If the
term would be understood without a chuckle, you get the points.
And remember that vocabulary is broadly defined. 
For instance, at some point I may assign powers of 2 as vocabulary
terms, along with range limits of the various signed and unsigned int
types.  This is more than just having the numbers: you should be able
to answer a question like &quot;What's the square root of 65536?&quot;
almost instantly, knowing that 65536 is 2^16, and its square root is
thus 2^8, or 256.  Good C programmers can work with bit level math
instinctively.

All the course handouts on testing, bug finding,
etc are testable material.  People often ignore these; be sure you
read and fully understand them.

Any material in lectures, assignments, etc due
prior to the test is fair game, though we'll focus more on material
not yet tested.   And we'll focus on the hardest concepts, so any
concept you found hard to understand is worth reviewing.  Others
probably also found it challenging, and we're likely to ask questions
related to it.  


It's also worth mentioning that tests in this
class are curved.  Expect a challenging test, and don't be
discouraged if you can't answer every question.   Tests will be
designed for an average of around 50%, but you don't need a 90% for
an A.  Your absolute score isn't as important as how your score
compares with the average.  If you find yourself in the test thinking
&quot;OMG, I can't answer all of these&quot;, remember, probably
others feel the same way, and 65% may be a perfectly respectable,
perhaps even A-level, score.
Such a low average may seem intimidating, but
remember that it also means that minor mistakes matter less.  If you
make a 5% &quot;dumb error&quot; on a test where scores range from
90% to 100%, that's a disaster.  If you make a 5% error on a test
with a spread from 15% to 95% (as is common for tests in this class)
it's less of a problem. 


Here are some examples of likely test areas you'll
encounter throughout this course, though it's not an exclusive list.

C is a pointer language, and obviously we'll be
testing heavily on pointer concepts, including memory allocation,
pointer arithmetic, double/triple pointers, dynamic data structures,
function pointers, etc.  


Be able to reason quickly about shifting, masking,
etc.  Understand sign extension, two's complement notation and the
rationale for it.  Be able to work quickly with hex and even octal.

Understand the subtleties of static vs nonstatic
declarations, C linking, macros and pass-by-name, etc.

This lecture introduces basic pointer concepts
from C. 



	
	Location of multibyte
	variable is the first byte address
	Address operator and
	pointer targets.
	Pointer assignment and
	dereferencing
	Multiple ways to reach
	the same data
	Declarative vs
	dereferencing asterisk




pointer, address, “points to”, target,
dereference

Before we talk about pointers, we first need a
good visual picture of the computer's memory. 


From prior lectures, you know that the memory is a
series of 8-bit bytes, each one sufficient to store a small integer,
or an ASCII character code. Several bytes may be grouped together to
store larger values. A four byte group, for instance, comprising 32
bits, can store a relatively large integer value of over 2 billion.
What we have not yet covered in detail, though, is the idea that each
byte has an ,
a number uniquely identifying it. 

Here's
a diagram of computer memory that we'll use in our pointer
discussions. I've drawn all the bytes in a downward direction, one
box per byte, and next to each byte is an identifying number, its
address, starting with 0 for the first byte, 1 for the second, etc.
This looks a lot like a vertically-oriented array diagram, in fact,
with the addresses serving the same purpose as indexes do in an
array. This is a very good analogy: the computer memory may be
thought of as an array of bytes, with addresses serving as indexes.
The addresses always begin at 0, and run up to whatever size your
memory is – these days several billion.

Each
variable in your program is located at some place – at some address
– in the memory. Let's use the example code shown here, with its
integer variables and
.
I've drawn these in the memory at addresses 9936 and 9940,
respectively. Of course, the compiler may choose to put your
variables at many different possible memory locations, but for this
program and this compiler, i1
and

ended
up at those locations.
Address
of multibyte variables is first byte's address
And,
by the way, since 
and

are
4 byte integers, they're actually each in 4 successive bytes of the
memory (thus the larger boxes for each), so we might say that 
is
at addresses 9936, 9937, 9938 and 9939. But by convention, we always
use the address of the first byte of a multibyte variable as the
address of the entire variable, so we'd say that 
is at 9936.

iPtr1, iPtr2,

.
They're declared in the same line as and
,
but the star in front of them makes them 
to
integers, instead of ordinary integers. 

A
pointer is a variable that contains an address – the address of
some other variable, generally. Instead of holding integer data,
iPtr1,

gives
you the address at which an int variable may be found. 


Upon
declaration, a pointer holds garbage data, like any other C/C++
variable, so for instance, at line 10 
has
a random address in it. To use the pointer variable, we must first
put a meaningful address into it. There are several ways to do this,
but the most direct is on line 11, where we assign an address into

directly.


Note
that &amp;. It stands for “address of”, and thus the assignment
does not copy the content of 
into
but
rather the 
of
or
9936 in this example, into iPtr1.
The
diagram shows the result, with 
now
containing 9936. I've also drawn an arrow from 
to
,
to symbolize the fact that 
now
“points to” i1
– tells
where 
is
in memory. The arrow is a useful abstraction, and as we do more with
pointers we'll often not show an explicit address in the pointer box,
and instead simply draw an arrow from the pointer box to the variable
to which the pointer points, which variable we'll call the pointer's
.
We'll say, for instance, “iPtr1
points to i1” or
i1 is
iPtr1's target”. Never
forget, though, the underlying fact that the pointer contains a
memory address.
On
line 12, we make 
point
to (it
contains the address 9940). Then on line 14, we print the values of

and
,
using the %d format specifier, which prints their address contents
directly. As you can see from the output at the bottom, the pointers
really do contain addresses. You may use %p to print pointer contents
as well, but this will show the addresses in base-16, hexadecimal,
which isn't as useful for this discussion.

Now that we have pointers with valid targets,
let's see how to use them. On line 16 we have what looks like an
assignment into ,
but is not – it doesn't change 
at
all. Instead, it modifies 's
,
putting
a 5 in it. The asterisk ahead of 
makes
all the difference here. That's a “dereference”
operation – it follows the pointer's arrow (the address in the
pointer) to the target, and affects the target instead 
the
pointer.
This
illustrates what is perhaps the most critical concept to master with
pointers, and the most common source of confusion. When you set up a
pointer to a target, you have two boxes,
two variables,the
pointer and its target. Depending on whether you add that asterisk or
not, you're dealing either with the pointer or its target. Keeping
the difference clear is one of the most important things to learn
when dealing with pointers.

In basic code, you give a name to each variable,
and that's the only way to refer to it from then on. One interesting
side effect of pointers is that there may be several ways to reach
the same data. We can reach ,
for instance, either by directly naming it, or via .
On line 17, we put 10 into 
the
old-fashioned way, but in the following printf, we access 
directly,
and use 
to
reach .
It all works either way. 

A
dereferenced pointer is usable anywhere
And,
another related point: you may use a dereferenced pointer absolutely,
positively, anywhere you could use the target variable directly.
may
be used as a printf argument, on the left or right side of an
assignment, as a loop counter or an array index. Anywhere you could
use an integer variable, you may use a dereferenced integer pointer.
Declarative
vs dereferencing asterisk
You
declare a pointer to a given type by placing an asterisk before what
would otherwise be a normal variable declaration of that type. You
also use an asterisk to dereference a pointer. Students sometimes
become confused between the two, thinking that a declaration like:
int
*iPtr1;
is
dereferencing the pointer, which is not so. It's useful to think of
these as two related but distinct uses of asterisk: the declarative
asteriskand
the dereferencing
asterisk,
so as not to be confused. In a declaration, an asterisk means “make
this into a pointer”. In code, it means, “dereference this
pointer”.

But
what if we don't use the asterisk, as in the assignment on line 20?
In this case, we're talking about the pointers ,
not their targets. The assignment copies the content from 
into
.
As you can see in the diagram, this means that the 9936 in 
goes
into ,
and now they both point to (both
hold s
address)In
the lines that follow, we print 
and
its target, and we get 9936 and 5, as you can see. And then changing
to
7 changes both 
and
in
the line-23 printf, because of course both pointers have the same
target: .


Assigning
from one pointer to another is so common in pointer-based code, that
it's worth emphasizing here. If you copy pointer A into pointer B,
then 

Write a single line of code that would make this
if-statement true if done on line 24:


iPtr3 = &amp;i1 would do this, since
it makes i1 the target of iPtr3.

Write a line of code on line 24 of the example
that would make this if-statement false if placed after your line of
code.



No change to i1 will
accomplish this, since iPtr1 and iPtr2 both point to i1. You'd need
to change the pointers themselves so that they don't have the same
target. iPtr1 = &amp;i2, for instance, would do this.

K&amp;R section 5.1 is a good reference on
pointers, as are many websites. Here's a brief research question to
answer via external references:

The * and &amp; symbols are operators, like +, -,
etc. What is their precedence relative to the operators /, +, and !?

They have the same precedence as
other unary operators, like !, but have higher precedence than + or
/.

Copyright
2012, Clinton A Staley

This lecture segment looks more closely at pointer
types, and also shows how to pass pointers as function parameters.

Continuing from lecture segment A, let's look at a
different kind of pointer: ,
which is declared on line 9. This is a pointer to a float, and on
line 25 it's assigned the address of 
as
its target, as the diagram illustrates. The situation here works just
like the integer pointers we used in lecture segment A, but it
illustrates an important point. 
Before
we get into pointer parameters, let's look more closely at pointer
types. A pointer's type determines what kind of variable may be its
target. ,
for instance, may point only to float variables, not ints, chars, or
other types. iPtr1,
which
we discussed in the prior segment,
may
point only to ints. 
to
point these pointers to other types cause a compiler error. And
assigning from a pointer of one type to a pointer of another type
also results in a compile error, with one exception which you'll be
asked to research at the end of this segment.
At
first glance, it might seem odd to require such a limitation. After
all, an address is an address; why not just let pointers point to
anything? But if we dereference a pointer, the compiler needs to know
what type of data to expect as the target. If I write 2/*iPtr1, is
that an integer division or a floating division? It depends on
's
target type. Since 
is
a pointer to an int, the compiler can be sure that its target is an
int, and thus that integer division is in order.
Pointer
Parameters
Among
the things you may do with pointers is to pass them as parameters.
Line 27's scanf is supposed to read a float value into f1, but it
uses as
a parameter. Note the lack of an &amp; here. For all the scolding
you've heard about never forgetting the &amp; in a scanf, we'll be
hitting more and more cases where the &amp; should be omitted, and
this is a good example. Let's look at why:
Why
scanf (sometimes) needs an &amp;
We
could have used &amp;f1 as the scanf parameter instead, with the same
outcome. The reason for the &amp; in all those cases when you've used
(or forgotten) it in a scanf, is that scanf needs to know 
the
variable that it's supposed to fill in is. If scanf is going to read
a float value from the input, and put it somewhere, you need to tell
it where to put the float value. If you used just f1
as
the parameter, you'd be passing f1's current content, not f1's
location. But, the current content is irrelevant, since the scanf is
about to wipe it out by replacing it with new content. What is
relevant is 's
,
and that's what scanf expects you to pass. 

If,
for instance, you make the common beginner's mistake of scanning in,
say, i1 thus:
scanf(“%d”,
i1);
then
you're passing i1's content, perhaps 7 from our example code, where
scanf expects the address of 
instead.
Scanf will mindlessly read an integer anyway, and place it in memory
--- at address 7, not at address 9936, where i1
resides. You
might have had data you cared about at address 7, but it's gone now. 

This
is why you've been told always to add that &amp; -- scanf expects to
be passed a pointer
parameter – an
address or pointer value.
But,
going back to our line 27, 
already
has the address of 
in
it, so by passing alone,
you 
passing
the address of ,
and the &amp; is not needed. 

Question
1
OK,
so the &amp; is not needed, but perhaps we should just add it to be
sure. You can never be too safe, after all.
scanf(“%f”,
&amp;fPtr);
What
(bad) thing does this do? Where does the scanned float value go?
Answer
1

It
passes the address of fPtr to scanf, thus telling scanf to write the
new float value into fPtr itself. (Pointers, being variables in their
own right, have addresses too, though I didn't draw them on the
diagram to avoid confusion.). No data would go into f1, and fPtr
would be trashed. Some floating point value would go into it, and
floating point values, when viewed as an address, are essentially
random garbage.

So now let's create a pointer parameter of our
own. The Double function on line 3 has a pointer declaration for its
parameter ,
and it dereferences 
several
times it its body. Let's trace a call of Double, to see how this
works. To pass a value to a pointer formal parameter like ,
we need an address as the actual parameter in the call. On line 29,
we pass 
to
Double. (And at this point, let's assume f1 contains 10.0 due to the
line 27 scanf.) As with any other type of parameter, this copies the
actual parameter into the formal parameter, but what is copied into
arg
is
the address of f1.
So,
we're setting
up 
to
point to ,
as shown.
This
means that those dereferences of 
in
Double are dealing with f1.
When
we say *arg, we're referring to f1. So, line 4 adds

to
itself to double it. When Double returns, 
will
contain 20.0, as the output shows from the line 30 printf. You can
visualize ,
and any other pointer parameter, as an arm reaching back to a value
in the caller, letting you modify the value by dereferencing the
pointer. Such parameters are one of the most common uses of pointers
in C.


So, what would happen if we declared Double thus:
void Double(float arg) {
   
}
and
passed 
directly:
Double(f1)? Would that be just as good?


No,
because arg would then be a copy of f1. Doubling arg would not affect
f1.

C parameters are
“call-by-value”; the formal parameters in the function header are
copies of the actual parameters passed to them, and changing the
formal parameters won't change the actual parameters. In some cases
you'd rather have changes to the formal parameter reflected in the
actual parameter, so that you can communicate information from the
function back to the caller via the parameter. A parameter used this
way is called an “out parameter” since it sends information out
of the function back to the caller. 

Many languages offer
“call-by-reference” parameters, as a built-in feature, that have
this behavior, and can be used as out-parameters. (For instance, in
Pascal, you add the keyword “var” ahead of the parameter
declaration to get pass-by-reference behavior, in C++ you add an &amp;,
and in C# you add “ref”.)
C, by contrast,
doesn't officially have call-by-reference parameters, but you can
fake them perfectly well by using pointer parameters, as we just did.
Reviewing the somewhat tedious syntax; you must:
1.
Add the &amp; in the actual parameter to pass an address.
2.
Declare the formal parameter as a pointer.
3.
Dereference the formal parameter whenever you use it in the function,
to reach back to the actual parameter.


But if you can
live with that, you can get pass-by-reference behavior. Note that a
pointer parameter is still officially pass-by-value – directly
modifying the pointer parameter itself won't affect anything in the
caller; the pointer parameter is a copy of the pointer or address
that was passed. It's the target

the
parameter, following the “arm” back into the caller's data, to
get the call-by-reference behavior on the target of the parameter,
not on the parameter itself.
External
Reference Work

There is one type of C pointer that is special, in
that it can point to any type of variable. What is this? 


A void* pointer is a “generic”
pointer, that can point to anything. We'll look at these more closely
in a later lecture.


In this lecture segment, we'll wrap up the pointer
basics by going over a number of ways to mess up with pointers. This
may be the most important lecture of the module, so focus in. C
pointers are a legendary source of mysterious bugs.

	memory segment,
	segmentation fault (v)
	

Right at the top of the list is the use of an
. As mentioned in the prior
lecture segments, pointers, like any other variable, have garbage
data in them when declared. This means they contain a random address;
they point to a random location in memory. You can visualize a
just-declared pointer, like iPtr3, which was never initialized in our
code example, as having a “loose cannon” arrow pointing to
anywhere it pleases in the memory. 

You'll save literally days of debugging time with
C pointers, if you heed the following: Upon declaration, a C
pointer is worse than useless; it's a bomb waiting to explode at a
touch. Do not dereference it until you have done something to
initialize it, such as assigning an address into it or copying into
it from another pointer.
Any
experienced C programmer instinctively cringes at code like this:




This
code says in effect: “Put a 42 anywhere you'd like to in memory.
Danger is the spice of life; surprise me.” This will do
unpredictable damage to some data, but may not have any obvious
effect until hundreds of lines later, or, if you are really unlucky,
won't show any obvious effect at all, if p's random target happens to
be memory you don't care about.
We've gone over this
in prior lectures, but it's worth reiterating: The worst C bugs
are those that have no ill effect – if it's a bug, but it works
anyway, you're not lucky; you're .
This
includes using uninitialized variables of any sort. You might get by
with the code above, depending on p's uninitialized content, but
that's just whitewashing the problem. Sooner or later, as the code is
modified, or moved to other computers, possibly decades later, the
uninitialized address will change to some other value, or important
data will be shifted to the pointer's random target, and the bug will
rise from its hiding place and blow up the program.
Segfaults
and bus errors
If
you are lucky, you'll get an immediate fault from dereferencing an
uninitialized pointer, and at least on Unix, it will be one of two
specific faults. The first is the ever popular segmentation fault,
often abbreviated to .
We've talked about this also in prior lectures, but here's a quick
reminder:
Your
program coexists with other programs also running in the computer's
memory. It's bad enough if you trash up your own memory area, but
letting programs randomly trash 's
memory areas is a recipe for complete chaos. Such chaos used to reign
in older operating systems (
old,
e.g. Windows 3.1 or Win95) but any modern OS restrains each program
to its own area (or )
of memory. This is a hardware-enforced restriction, done by a

or
,
a
part of the CPU that catches any attempt by a program to access
memory not its own, and stops the program with a segmentation
faultif
it does attempt such access. A segfault may be caused by a
dereferencing an uninitialized pointer, going past the end of an
array, etc.

While we're at it, the MMU also arranges the fiction that every
program's memory area starts with address 0. Your program's memory
area generally starts at some nonzero address, say address 1,000,000
for example, but the MMU hardware automatically adds 1,000,000 to any
address your program requests, so that what you think of as address 0
automatically maps to 1,000,000, your address 1 maps to 1,000,001,
etc.  You're none the wiser; you think you're addressing from 0.  But
the truth is you're addressing from 1,000,000, courtesy of the MMU.

The MMU is smart enough to keep track of where each running program's
memory is, and do the right thing for each program. (More fully, the
operating system configures tables in the MMU to do this, and this is
one of the bigger jobs of the OS.)
The
second type of fault is something we haven't discussed -- 
This
has nothing to do with public transportation. The “bus” refers to
the band of leads on the motherboard that communicates an address
from the CPU to the memory. In almost all memory hardware, bytes are
not fetched one at a time. More typically, you must fetch them four
at a time, or even eight at a time. This makes fetching of multibyte
variables, such as a four-byte int or an eight-byte double, much
faster. But, because the memory is organized by byte groups, the byte
groups have to start at addresses divisible by four or possibly
eight. We can fetch a 4-byte group that starts at address 0, 4, 8,
etc, but not one that starts at address 1, 2, 3, 5, etc. 


Any valid pointer to an int will hold an address divisible by four,
because any int variable in the program starts at such an address.
But, if the pointer is uninitialized, or otherwise trashed up, then
it may contain any random address, and the odds are 75% that it won't
be divisible by four. Dereferencing such a pointer results in trying
to fetch a four-byte group from an invalid starting address, which
the memory bus cannot handle, and the result is a bus error. A bad
pointer is just about the only way you can make this happen, so if
you get a bus error, examine your pointer code carefully.


This next common pointer error is much simpler. You cannot assign a
pointer of one type to one of another type. Line 37 of the sample
program, for instance, tries to copy an int pointer into a float
pointer. The compiler won't allow this, since it would let you treat
what is actually an int (iPtr1's target) as though it were a float,
and you know from prior lectures that the two have completely
different bit formats. There are actually ways around this rule,
using a pointer cast; we'll get to those later.
Attempting
to get addresses of non-lvalues
Line
38 of our sample code attempts to take the address of the value “10”.
This 10 is an integer, but it's just a constant, not a location in
memory. There's no place in memory that holds the 10, and thus no
address to be taken. You can only take the address of something that
would work on the left side of an assignment statement, such as a
variable, or an array element, or a dereferenced pointer. By
contrast, expressions, constants, function calls, etc do not work on
the left side of an assignment because while they have a value, they
do not have a location in memory associated with them.

// These work

i = 42; a[3] = 42; *iPtr1 = 42;

// These don't

10 = 42; sqrt(5.0) = 42; a+b = 42;
This
concept is important enough that it has a term: .
An lvalue is anything that could go on the left side of an
assignment, anything that signifies a location in memory and not just
a value. 

You
may only take the address of an lvalue.

In this lecture we'll look at the relationship
between pointers and arrays in C. We'll see that although pointers
and arrays are distinct ideas, C allows indexing of pointers in a way
that makes a pointer behave very much like an array.


	
	Pointer type determines
	size of target
	Pointer arithmetic is done
	in terms of 


In our example program for this lecture, we have a
5 element array and
an int pointer   We'll assume throughout the
discussion that intArr starts at
address 4000.  Our program
will ask the user to enter five elements for the array, then will
square the values of each (just to have something to do with them)
and print the resultant 5 elements back out, like the example output
shows And it will do so
without once indexing intArr. Instead,
we'll do all the work on 
through
pointers.
Line
28 assigns 
into
.
Note the lack of an &amp; on .
The name of an array by itself, without indexes, stands for the
address of the array's first element with no need for an &amp;, as
the comment in the code indicates. So, line 28 assigns 
to
,
as the diagram shows. 

Each
element of 
is
an int in its own right, and has an address. So, nothing prevents a
pointer from pointing to just one element of an array, or as we'll
see later, to just one field of a struct.
Pointer
type determines target size
So,
what's the difference between 
pointing
to the first element of 
vs
just pointing to the entire array? The first element and the entire
array have the same starting address, right? So can't we view iPtr
as
pointing to either one? We will encounter pointers a little later on
that have an entire array as their target, but 
is
not one of them. It's declared as a pointer to an ,
and thus its target is always just one int, in this case the first
int in an array. 


This is a good example of the importance of a pointer's type. The
pointer's type determines what type of target it has, and thus
whether it points to just one int, or an entire group of them.
Remember this rule:
The address
in a pointer tells it
points to; its type tells it
points to.

The target type of a pointer will become even more important when we
start doing pointer arithmetic in just a moment

Let's look now at the while loop starting on line
31. This loop reads an int into each element of ,
using 
to
“walk down” the array. 

Ignore the loop test for the moment; we'll get
back to it. The scanf on line 32 reads an int into the target of
, which at present is
the first array element. (Recall the prior lecture's discussions on
why we don't need an &amp; in that scanf.)  So, a 0 from the input
goes into 
But, line 33 is
the really interesting one. Can we increment a pointer? Yes, and the
effect is 
what
you'd expect. The address in the pointer increases, but not
necessarily by 1. It increases by one target size. In our diagram,
for instance, 
is
at address 4000 and 
is
at address 4004 (assuming 4 byte integers). Incrementing 
increases

by
4 bytes, not 1, so it points to intArr[1].
When
you consider it, this is the only sensible thing to do. Increasing

to
4001 would point it 1/4 of the way into ,
which is hardly useful. We're about to encounter a variety of
different 
operations
like this one, and they all follow the same principle:
Pointer arithmetic
is always in terms of the size of the target, adjusting the pointer's
content by some number of target-sizes.
So,
with this we can see that the while loop advances 
down
the array, one element at a time, and that the scanf thus reads
integers into successive elements of the array. 



Just to emphasize that increasing iPtr to 4001 would be senseless,
ask yourself what would happen if you did increase it thus, and then
dereferenced it to get the “int” starting at 4001?

The
result would be a bus error, since ints cannnot begin at an odd
address, per the discussion in prior lectures.
The
only remaining question is: how do we end the loop? We want to do
this when 
is
pointing past the end of ,
at what would be intArr's
element
number 5 (sixth element), as shown in the diagram.

at
that point?

iPtr will contain 4020, five
integer-sizes in from the start of the array.

?
The immediate answer of 20 is incorrect. Consider the above rule
regarding pointer arithmetic and target sizes, and then make a guess
as to what the difference would actually be. 


We'll get 5, the number of
integer-sizes between the two addresses 4020 and 4000. All pointer
arithmetic, including subtraction of two pointer or address values,
is in terms of target sizes.  Pointer subtractions are automatically
divided by the target size.
Pointer subtraction is allowed between any two
addresses or pointers, provided they are of the same type. Again,
this makes sense if you think about it: if the subtraction is in
terms of the target size, so we need a clear target type, and thus
both operands must have the same type.

Pointer arithmetic in general allows the
following:

	
	Incrementing or decrementing a pointer, which increases or decreases
	its address by one target's worth.
	
	Adding or subtracting an integer value to or from a pointer: e.g.
	As in all
	other cases, the addition or subtraction is in terms of target size.
	The example subtraction just cited would compute an address 40 bytes
	less than 
	
	Subtracting two pointers or addresses from one another, if they have
	the same type.


In this lecture segment we'll look at more pointer
arithmetic, and at how array parameters really work, and we'll
discover that they're not arrays at all. In fact, you cannot pass an
array as a function parameter, but pointers make it look an awful lot
like you can.


Take a look a the function SquareArray, which
squares each element of an array passed to it. On line 35, we pass

to it, but the corresponding formal parameter on line 4 is a pointer,
not an array. Remembering that 
does not mean the entire array, but only the address of its first
element, this makes sense. We're copying that address into the
pointer parameter 
so that 
points to the first element, just like 
did in the prior lecture segment. 

The key thing to understand in SquareArray is the
expression *(array
+ ndx). According to the rules of pointer arithmetic,
adding 
to 
actually adds ,
to arrive at the address of array[ndx].

starts at address 4000, and if 
is 3, then 
is 4012, the address of .
Dereferencing that address then gives the target: 
itself.
gets
one of the elements of the array pointed to by 
And in the loop on line 9, we use this to fetch one of the elements
of ,
multiply it by itself (note that that middle * is just a
multiplication, not a dereference) and assign the square back into
the same element.

As we work with more complex pointer expressions
like this, it's important to remember the difference between
pointer/address and target. For example 
is an address; it's not an element of the array. To go from the
address to the element, you need the dereferencing *. 
is still in “pointer land” if you will, and is of type pointer
to int, not int. You never get a dereference, never go to the
target, without using either a *, or one of two other operators we'll
discuss shortly.

What does the following line print, assuning

begins at address 4000 as in the diagram, and that it has the
unsquared contents?

Answer 1:
It prints 4004, 42, 4008. The first
and third parameters are addresses. They're not dereferenced unless
you add the *. It's only the second expression that actually gets one
of the elements of the array.

The expressions on line 9 work, but they're pretty
tedious. There is an alternative. Function PrintArray prints the
contents of an array, and is called from main in the same way as
SquareArray. But, it uses no asterisks at all.
Let's start with the function header on line 13.
It has what looks like an array parameter, using the [] syntax that
you're already familiar with from earlier C lectures. A brief review,
though:
Introductory C classes
usually explain that you pass an array by using [] for the formal
parameter declaration, and that an array parameter, unlike ordinary
parameters, is pass-by-reference, with modifications to the formal
array parameter in the function having an immediate effect on the
actual array parameter in the caller. Also, any length of array may
be passed to the parameter. The parameter is length-agnostic; if you
need the length of the array in the function, you have to pass it
separately, as we do in our example functions here.
This is all a lie. Well, OK, it's a major
simplification suitable for CS 101. But it's time to look at the
reality now that we understand pointers. 

int
array[] declare an
array parameter. There's no such thing as an array parameter in C.
The notation 
in parameter lists is a synonym for .
PrintArray's first parameter is a pointer,
identical to the first parameter of SquareArray. 

OK, so then why are we indexing the parameter in
the body of PrintArray? Can you index a pointer? Yes, and the result
is what you'd expect. 
means the same thing as 
– it offsets the pointer and dereferences, e.g. 
is the fourth element of the array pointed to by array.
So, if a pointer is pointing to the start of an array,
you can index the pointer to get to elements of the array.
The net result is that you can declare a pointer
parameter that looks like an array, and use the parameter by indexing
it. You get what looks like an array parameter, but is in fact a
pointer in disguise.

Nothing requires the pointer to point the start of
an array, by the way.  Consider this question:


contains the data shown in the example: 0 3 42 5 8. What do you think
the following (legal) code would print?


Answer 2:
It would print 8 3 4012. The
assignment makes iPtr point to the third element of intArr. Indexing
by 2 from there arrives at the fifth element. Indexing by -1, which
is allowed, reaches the second element. iPtr+1 is the address of the
fourth element. Skipping in from 4000 by 3 int sizes to get to the
fourth element gives 4012.
It's not unheard-of for C programs to set up
pointers into the middle of an array like this, and index both
backward and forward from the location of the pointer. You're even
allowed to index negatively from the start of an ordinary array, but
you'll get garbage data, or a runtime error, if you do so.

After seeing pointers being indexed, and array
names assigned into pointers, it's tempting to jump to the conclusion
that pointers and arrays are interchangeable, and basically the same
thing in C. This is not correct, and it's important to keep the two
separate in your mind, despite their very similar behavior. A pointer
is still an integer-sized variable that contains an address. If it
points to the first element of an array, then there are two different
pieces of memory involved: the pointer the
larger array.
An array is just one, large piece of memory
comprising its elements. There's no integer-sized variable containing
its address. The array name itself is not a pointer, but just an
address. You could not, for instance, assign a value into 
in our example code. It's not an lvalue. 

And the machine language translation of pointer
indexing and array indexing is subtly different. The former starts by
fetching an address from the pointer variable, indexing off of that.
The latter assumes a fixed array location and indexes from that.
While we're on the subject, the relationship
between an address and a pointer is that between constant and
variable, e.g. between the value 42 and an int variable .
Both 42 and 
are of integer type, but only 
is an assignable lvalue.  Likewise, both 
and 
are of pointer to int type, but only 
is an assignable lvalue.




	
	
	
	
	
	
In this segment we'll look at pointers to structs.
C allows pointers to almost anything, and we'll see more and more
complex types of pointer in the next several segments. We'll also do
a relatively long review block on typedef, arrays of structs and
{}-list initializations.


	
	Complex variable
	initialization (review)
	Struct pad bytes
	(v)
	Using pointer
	parameters for efficiency


One declares a pointer to a struct type in the
same way as other pointers: by taking what would be a normal struct
variable declaration and adding a “declarative asterisk” in front
of it, as we do on line 23, so 
is a pointer to a struct of Student type. As with other pointers, 
is particular about its target type; it can only point to structs of
Student type, not any other struct type.
Recall from prior study that one
sets up a user-defined struct type via the typedef syntax shown on
lines 7-11.  The typedef makes Student a type, not a variable.  We
may use the Student type to declare other variables to be of the
struct type shown in the typedef.  On lines 19-22, for instance, we
use Student to declare our pointer ps, struct variables s1 and s2,
and an array of structs . 



Recall also that one may create
arrays of structs, like ,
and each element of such an array is a full struct in its own right,
as illustrated in the diagram of .



Finally, recall that complex
variable types, either structs or arrays, may be initialized with
{}-enclosed lists of data as shown in the example. To initialize a
struct, you list the values of its fields in the {}, comma-separated,
in the same order that the fields were declared. These values are
automatically assigned into the new struct variable as initial
contents. 



For arrays, you list the values
of the array elements one after another, comma-separated. For an
array of simple type like say int, these are simple values, but for
an array of structs, each element is initialized by a nested {} list
of values for each struct-element of the array of structs. So,
students will have the initial contents shown in the diagram.  



Arrays and structs can be nested
within one another in arbitrarily deep patterns, and {}-initializers
may be correspondingly nested as needed, to match the arrays or
structs being initialized.  Also, the {}-lists may omit some values,
providing only values for the first few fields of a struct, or first
few elements of an array. They may not 
values, however; once they omit any value they must omit all the
remaining ones.  The ones omitted remain uninitialized.


And, an array declaration may
leave out the dimension, showing only [], and letting the length of
the initialization list determine the dimension instead. This is 
the same usage of [] as in a parameter list, where [] signifies
“pointer”. Arrays declared in normal variable blocks with
unspecified dimension are still arrays, not pointers. Their dimension
is just determined through other means, such as {}-lists.


At this point, students usually
ask if this {}-notation can also be used in assignments in the code,
instead of only in initializations. Sadly, the answer is no, and some
think Kernighan and Ritchie should be shot for this omission.
Programmers used to JS or other scripting languages (where
{}-notation and similar syntaxes are routinely used for general
assignments) will find it especially irritating to have to assign the
fields of a large struct one dull assignment statement at a time.
That's what you get with a 1970-vintage programming language.

You may assign the address of a struct into a
struct pointer in the usual way, using an &amp;, as on line 25, and
assigning the struct address into the pointer.   Or, you can assign
the name of an array of structs into a pointer, as in the loop
initialization on line 30, so the pointer will point to the first
struct in the array.
A struct pointer's target is exactly one struct,
not just a field of the struct, nor an entire array of structs, even
if the struct pointer is pointing to an array's first struct element.
Dereferencing a struct pointer thus results in one struct. After
dereferencing, we may do the usual dot notation to pick one field of
the dereferenced pointer, as in the first expression in line 26's
printf: .
The * dereferences from 
to its target (which is 
at this point) and the 
then picks the name field of the , to be
printed out.
This two-step process – deferencing a struct
pointer and then picking a field – is very common, but the way we
just did it is rather tedious. Especially irritating is the need for
parentheses around the pointer dereference. These aren't just for
emphasis; they're required. Dereferencing a pointer is an 
in C, just like +, *, !, etc., and it thus has a precedence.
Curiously, the “.” used to pick a field is also an operation,
with
its own precedence.We'll
find that C interprets a great many things as “operators” and
“operations”, even things like array indexing and field
choosing.) The problem is that the field-choosing “.” has higher
precedence than the dereferencing *, so without overriding
parentheses 
would be interpreted as ,
which is meaningless.
A side note for you Java or
Javascript programmers: you  use a “.”
operation directly on a struct pointer, the way you can on an object
reference in Java or JS. Those languages have no dereferencing *;
they implicitly dereference, so in Java or JS, 
is automatically interpreted as ,
but not in C.


So, with all that, we're left needing a more
elegant way to write “dereference and pick a field”. This is
given by the -&gt; operator (typed as a dash and a greater-than sign,
but meant as an “arrow”), which as you can see we use throughout
the rest of our example. ,
for instance, is a synonym for .
The -&gt; is a single operator, but it represents two
steps
The rest of the example code makes use of these
ideas, first printing the fields of  via
 then comparing s1 and s2 to see if
they are equal. 

That comparison has several interesting aspects. 
First, recall from prior lectures:
Structs may be assigned directly
into one another, e.g. s1 = s2, but they may not be directly
compared, e.g. s1 == s2.  For comparisons you must write code that
hand-checks each pair of fields. 



One good reason for this is that
structs may hold a wide variety of field types, and the correct rule
for equality-comparison is not always clear.  In our Student struct,
we would use  for comparison of the
names, for instance, rather than directly comparing the char array
contents, which might actually differ after the terminating '\0',
without making the strings technically unequal.


Another reason it's hard for the compiler to
automatically check structs for equality has to do with the bus error
concept from a prior lecture.  The field 
a double, must begin on a 4-byte or 8-byte boundary, depending on the
CPU.  But since  is an odd 21 bytes
long, the byte right after the end of 
is unlikely to be on such a boundary.  So, gpa
 directly.  In
this case, the compiler automatically adds a few 
between the end of 
and the start of 
starts at a properly-divisible address.  Those pad bytes hold random
data, and you don't notice them because they're not part of any
field.  But an automated comparison for equality between two structs
would need to know not to compare the random-content pad bytes.  

Any way you look at it, struct comparison requires
more logic than just looking at the raw content of the two structs.
We do a hand-comparison of Student structs in the
IsEqual method on line 13, passing it two Student structs and
comparing each pair of fields, returning true only if the combined &amp;&amp;
of all field-pair equality checks is true. But, we do it by passing
the addresses of the two structs, passing 
and 
and  which we then use to “reach
back” to the original 
and compare their contents.  


and , so why pass pointers instead of
just passing the structs as normal value parameters?
Passing struct
pointers for efficiency
To
see why, consider how many bytes long a Student struct is.  The 
field is perhaps 4 bytes, the  array
21 bytes, and the  field another 8
bytes – 33 bytes in all, plus pad bytes.  And Student is a small
struct.  Passing 
by value would make copies of s2
into the formal parameters, requiring 66 or more bytes of
copying.
But, if we use pointer parameters, passing just
addresses, that's a total of two 4-byte pointers, about 1/8 as much
data.  And again, for a bigger struct, the difference is even more
dramatic.
It's very common to see structs passed via
pointers for this reason, even if the function is not going to modify
the actual parameters.
Big target sizes, big
jumps
Finally, look at
the loop on line 30.  It walks 
down the  array, just like the
loop from our prior lecture.  But, each element of 
is a struct. so...  



change when we do the 

It increases by 33 bytes, the size
of a Student struct.  (Technically, it might be as much as 36 or even
40 bytes due to pad bytes.) 

It may be surprising that a simple ++ operation
can cause a large jump in the pointer's content, but that's what it
takes to jump to the next struct in the array. 


Look more closely into the rules surrounding {}
initialization, and answer this question:

Can I initialize a 2-D array, say an int array of
dimensions 3x4, using {} notation?  If so, what does the
initialization look like to, say, initialize it to all zeros?  And,
can I do the initialization with just one {} pair?

Yes, you can.  Initialization might
be like 

int arr[3][4] = { {0, 0, 0, 0}, {0,
0, 0, 0}, {0, 0, 0, 0} };  

Each row of the array is a subarray,
and gets its own {} block.  But, the inner {} blocks are optional. 
One may also write
int arr[3][4] = {0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0}; 

And the 12 zeros will be grouped
automatically into rows.






	
	
	
	
	
	
In this lecture segment we'll examine pointer
target types more closely, and we'll see some special uses of
character and void pointers.


	void type, void pointer
	(v)
	
	postincrement (v),
	preincrement (v)




As discussed in prior lectures, a pointer's target
type strongly affects its behavior.  Let's look at some examples.  On
lines 30 and 31 of the code sample, we set up pointers 
and 
 The first is a pointer to Student, initialized to point to ,
and the second is a pointer to int, initialized to point to .
 As you can see from the diagram, and from looking at the Student
typedef, these two pointers have the same address in them, since 
starts with .
 

The if-statement on line 34 reinforces this.  (One
may check equality between dissimilar types of pointers.)  Line 35's
printf does occur since the pointers contain the same address.
But, despite containing the same address, the two
pointers do  point to the same thing. 
Pointer 
points to an entire Student struct.  Dereferencing it will get the
whole struct, and adding 1 to 
will add
sizeof(Student)
points to just one int.  Dereferencing it will get just the int, and
adding 1 to it will add 
bytes. 

Recall from prior work that
the sizeof operator returns the number of bytes of memory occupied by
its argument.  You may pass either a type, e.g. Student, or a
variable, e.g. s1,

returns 36, or perhaps 40, depending on padding.  The expression

returns 4, or perhaps 8 on a recent CPU.
An important point about
sizeof is that it is an , despite
looking like a function call.  Operators don't have to be a symbol
like + or !.  They can look like a function call, but still be a
built-in feature of the language.  Ask yourself: how would I make a
function take a  like Student as an
argument?  You can't.  Sizeof has to be built into C for that to
work.  Sizeof even has an operator precedence – a fairly high one,
the same as ! or dereferencing *.
The if-statement on line 36 illustrates this
effect of pointer target type.  Adding 1 to the two pointers does 
produce the same result, and the printf on line 37 does not run.
Pointer target type also determines what you can
assign into a pointer.  In our sample code, we could not have
written: ps =
&amp;s1.idpi
= &amp;s1.  The operand of the &amp; must be of the
same type as the pointer's target type.  There is no such thing as a
generic “address” in C (at least not till the next section). 
There is an address or an address
and the address type must
match the pointer type.


	Target type determines
	what you get when you dereference – how much
	
	Target type determines the
	result of pointer arithmetic – what the multiplication factor is
	on the number you add to or subtract from the pointer.
	Related to point 2, target
	type determines how much you offset when you index a pointer.
	And finally, target type
	determines what you may assign into a pointer.  You cannot assign
	the address of a type different from the pointer's target type.


Having made a big point about the strictness of
pointer target type rules, in this section we'll look at two ways to
get around those rules.  To motivate the discussion, we're going to
write a function to set all the bytes of a large variable, like a
Student, or a Teacher (as declared on line 10-13) to 0.  

The same function will work on any variable. 
We'll pass it the address of the start of the variable, and the
number of bytes in the variable, and the function will loop through
the bytes of the variable, setting one byte at a time to 0.  This
will have the effect of setting all the fields of the variable to 0
values.
What kind of pointer will we need to do this?  It
would have to be one that advances just one byte when we increment
it.  So, its target type must have a “sizeof” one byte.


function on line 15 illustrates one approach.  We'll use v1, a char
pointer, 
is 1 byte.  This means that when we index ,
C will assume 
points to the first char in a sequence of one-byte chars, and will
index one char (byte) at a time.  The loop on lines 18-19 will thus
set 
bytes to 0, starting with the byte pointed to by .

That would be fine if we had a char array to pass
to v1, but on line 39 we want to pass 
,
so that 
will write 0-bytes into ,
the target of as
indicated in the diagram.  

I said earlier that you cannot assign (or pass)
one pointer to another unless their target types matched, but I lied.
 Characteristically for C, there is a way around any rule, and in
this case we'll use a  to
allow the address in 
to be passed to parameter .
 A pointer cast takes the form: (SomeType
*)somePtr and it produces an address of target type

from the pointer 
 In our example, the expression (char
*)ps
 

Note that this takes no actual computation to do. 
The address in question is the same either way.  It's just a shift of
 on the part of the compiler, and
it allows a parameter pass, or an assignment, that otherwise would be
forbidden.  To be clear, 
is still a Student pointer; the cast doesn't change its type.  The
cast just produces a temporary result of a different address type
(though the same actual address) to be assigned or passed into a
different pointer.
So, by virtue of the cast, we've “tricked”

into believing that what is actually a Student is instead an array of
chars, pointed to by v1,

elements, since we passed 
to .
 The function will dutifully write 0 values into all the bytes of 
Take a look at the alternate framing of line 19,
in the comment.  This would also work; be sure you see why.  

From prior learning, recall
that v1++, or any other 
operation, increments its argument, in this example advancing 
by one char or byte.  But, it also produces a value, and can thus be
used as part of a larger expression, such as ,
or, in the case of an integer i, and array 
we could write 

The value returned is a bit
subtle.  It's the value of the argument before
incrementing, as if the program temporarily saved the old value,
incremented v1 to the new value, but then used the old value to
satisfy the expression (which in fact is exactly what the machine
language translation of the postincrement does.). 

new
value, use
the  operation:

or Since
the most common need is to get “one last shot” at the old value,
while still increasing the argument variable to a new value, you see
perhaps 10 postincrements for every one preincrement. 
(Postincrements are marginally slower, by the way, due to the need to
save the old value temporarily, so when either choice will do, prefer
the preincrement.)
It's important that the precedence rules cause
this expression to be interpreted as ,
rather than ,
which would do something quite different.  The 
and * operations actually have the same precedence, but the
association rules for one-operand, or unary,
, so the
rightmost operation, the ++, is automatically done first.

value of ,
setting its target to 0, while also advancing 
to the next address.  Be sure you're OK with this; we'll be using
this pattern a lot in coming lectures.


do?

It would dereference v1, getting its
target char, and increase that target char by 1, leaving v1
unchanged.  Sometimes this is useful, but to do it you must
explicitly parenthesize.

In early versions of C, char pointers were often
used in this fashion as a sort of “generic pointer”.  But they
always required a pointer cast, which is inconvenient.  The ANSI C
standard of 1989 added a new pointer type: void
*, a sample declaration of which can be seen on line 22
in the header of 
 type
follows special rules.  Any pointer may be assigned into it, and it
may in turn be assigned into any other pointer, regardless
of their target type. A void pointer is thus a kind of “pointer
to whatever” -- a truly generic pointer.
But, void pointers have an important limitation. 
Their target size is 0. 
This makes sense if you think about it.  The type “void” is only
used one other place – to indicate that a function returns nothing,
like for instance niceGenZero,
which has a void return.  So, it's a sort of massless
type, having no real content.  Thus, it's no surprise if


If a void pointer's target type of “void” has
size 0, then what happens when you increment the pointer, or add an
integer to it?  Follow the rules for pointer target size to make an
intelligent guess.
void
*ptr = &amp;something;

ptr
= ptr + 1000000;



An intelligent
guess would be that the increment, and even the addition of
1000000, are implicitly multiplied by the target size, which is 0. 
So, the loop on line 25 will fail if we use v1 in it, since v1++
would not advance at all.


In fact, it's even worse
than that.  Technically, the C standard forbids even trying to
increment or dereference a void pointer or take the sizeof(void)
without undefined behavior.  But, many C compilers “helpfully”
adjust the standard so that sizeof(void) == 1, and one can
successfully index a void pointer as though it were a char pointer. 
Don't rely on this, however.  It's the sort of thing that may result
in bugs when you move your code to a different compiler.
Instead, we copy v1 into a char pointer on line
23, with no cast needed, and let the char pointer advance down the
series of bytes.  (Alternatively, as the comment indicates, we could
have done a temporary pointer cast of ,
and indexed the temporary char address that resulted.)

a function that may be called with 
pointer and a corresponding sizeof, as on line 42, with no pointer
cast needed.

Since our LMQs will involve some creative use of
generic pointers, let's try one more example in this lecture.  Let's
build a generic equality-checking function that can compare any pair
of variables, of any type, for equality.  We'll expect to call it
thus:
   if (genEqual(&amp;s2, &amp;s3,
sizeof(Student)))
in this case using Students, though again it will
work with any type.  You pass it the addresses of the two same-type
variables you want to compare, and their length in bytes, and it
compares the two variables for equality, byte by byte.

's
header look like?

int genEqual(void *v1, void *v2, int
size).  We need void pointers if we're to accept any kind of address
without a cast.


OK, so now that we have the addresses passed in,
we need to loop through them, checking each corresponding byte for
equality.  If the bytes are all equal, then the two variables are
equal, and not otherwise.

Oops.  That's not exactly true, about the bytes
being equal if the values are equal, especially in the case of
structs.  What's wrong with that statement?

Structs may have pad bytes, as we
earlier discussed, which means two equal structs might actually have
some (unequal) pad bytes.  We'll ignore this possibility in the
exercise here.



while
(size--)
if
(*v1++ != *v2++)
	
    return 0;
return
1;


No, it won't.  Just for the record, there's
nothing wrong with modifying the parameters, as in 
if it's convenient to do so.  They're ,
and thus ours to trash if we want.  But, there's a deeper issue. 
What is it?

As discussed, void pointers have
“neutrinos” as targets.  “Void” things cannot be compared for
equality, and they have a nominal size of 0 so the ++ operations
won't do anything.





The final result is added to the
diagram, and below.  We need char * pointers, of course.  



int genEqual(void *v1, void *v2, int
size) {
   char *cp1 = v1, *cp2 = v2; 







Look up the memset, memcpy, memmove, and related
routines online, and play around with them until you're confident you
understand them.  There is no in-lecture question on these, but
you'll find them very useful in the LMQs.
Also, note the concise framing of the code in, for
instance, .
 You'll be expected to come up with similarly concise solutions for
various generic-pointer problems in the LMQs, possibly using those
library functions as well.






	
	
	
	
	
	
In this lecture segment we'll review some C string
basics, and then look at strings from a pointer perspective.


	C String organization
	(review)
	String constants and
	string table (v)
	String comparison and
	assignment
	Real definition of string
	in C.





Let's start with a review of
what you have learned in prior C work.  C strings are usually held in
char arrays, like 
and 
on line 17 of our code example.  You can, for instance, pass such
arrays to scanf, with a %s format specifier (ignore the 9 in the
format specifiers for the moment) and scanf will read strings from
the input (blank-delimited) into the arrays.  In our example, we
enter “professor” and “project” into the arrays string1
.
 Printf also works with character arrays and the format specifier %s,
as on line 27.
But, as the diagram
illustrates, neither of these strings completely fills its array, and
in general one cannot predict exactly how long an entered string may
be.  So, we often have extra, uninitialized elements at the end of
character arrays holding strings.  How is the computer to tell
whether 
contains “project”, or “project#@$”?
C solves this problem by
designating one ASCII character, NUL, as an end
of string marker.  All strings automatically end with this
character.  Scanf adds a NUL automatically when reading your strings,
and printf stops printing when it hits NUL.  NUL is writable in code
as '\0'.  It has the very lowest ASCII code: 0.  Normally a
character's specific numerical ASCII code is unimportant, but we'll
find that ending strings with character code 0 makes string
operations much simpler.
So, the full diagram of

and 
should show the NUL characters at the end.  And, interestingly this
means 
is full-up, with the 9 characters of “professor” and the NUL. 
This is an important point:
C strings
always require one extra space for the terminating NUL.
So, what's the 9 for in the
scanf format specifiers?  It's a field length limit, and tells scanf
to stop reading after 9 characters (not counting the NUL) so as not
to overflow the arrays.  Otherwise scanf reads in whatever is typed,
without checking if there is enough space. A malicious user typing
“antidisestablishmentarianism” will trash your memory past the
end of the array.  Indeed, string-length vulnerabilities are a major
source of security flaws in C code.

Also a part of review:
comparing strings directly, as on line 22, does not work, nor does
assigning one char array into another, e.g. string1
= string2.  Instead, we use the library functions

and 
respectively to compare and copy two character arrays' string
contents.  Our code example actually doesn't use these, since it has
its own functions, named 
and ,
which we'll be analyzing.  But, our two functions work exactly like
the real ones from the library, and so the calls to them on lines 25
and 26 are good examples.

takes two character arrays and compares their content
 – a fancy work for “as
in a dictionary”, since lexicon is a $50 word for dictionary. 
That's just standard sorted order, including the rule that if one
string is a strict prefix of another, e.g. “cat” vs “catalog”,
then the shorter string is less -- falls earlier in sorted order.  

returns an integer – a negative value (not necessarily -1) if the
first string parameter is less, a zero if the two parameters have
identical content, and a positive value (not necessarily 1) if the
first parameter is greater. 

That rule can be hard to
remember.  Here's a mnemonic.  It's as if strcmp
subtracts the second string from the first, so that
strcmp(string1,
string2)
in the sense that if 
were larger, we'd expect a positive difference, if they were equal,
we'd expect 0 difference, and if 
were smaller, we'd expect a negative difference.
It's also worth noting that
this way of getting one function to give you all three possible
results is another “C legacy”, having been passed along into many
other languages, including Java, C#, etc, all of which have compare
methods that return negative, 0, or positive in the same way as


copies its .
 Again, a slightly odd rule to remember, but note that this makes

like an assignment statement, copying the right side into the left. 

And, recall that in order to
use ,
or any of the other string library functions, you must add #include
&lt;string.h&gt;

OK, that's it for the (lengthy) review of C string
concepts in this segment.  Let's look at how pointers mix in with all
this.
First, when I said that scanf and printf take
character arrays, that wasn't strictly true.  As we know, when you
pass the name of an array alone, you're passing the address of its
first element.  So, what scanf, printf, and indeed all string
functions expect is a If
we got that from an array, fine, but we'll see there are other ways
to obtain a character pointer to the first character of a string.
Second, now that we understand pointers, we're in
a position to see why line 22 doesn't work.

Under what circumstances, if any, will the test on
line 22 return true?  You should find the answer a little amusing
when you see what the test really does.

It will never return true, because
it's effectively asking if string1 and string2 have the same starting
address, which clearly they do not, regardless of their content.

if
(string1 &lt; string2).  What even more useless thing
do you think this does?

It determines whether string1
appears earlier in memory than string2, since that would be the case
if string1's starting address were smaller.  You can compare pointers
directly like this Sometimes
this is useful if the pointers are both pointing into the same array,
but usually it's useless information.



And, to be complete, assigning character arrays
thus: string1 =
string2, is not only useless, it won't compile.  Why,
exactly?  I'm looking for a specific vocabulary term from an earlier
lecture.

string1, a fixed address, is not an
lvalue, as noted in earlier lectures.  It cannot be assigned into any
more than 42, or sqrt(3.14) can be.


So, then, what about line 30?  Is that assignment
legal?  Sure, because 
 an lvalue.  It's a pointer, not an array,
as declared on line 17.  So the assignment points 
to the start of 


to printf on line 31.  Will printf accept a char pointer instead of
an array?  Why? 


Because, as we indicated earlier,
functions that work on strings really only expect char pointers,
because that's all you can pass anyway.  Passing the array name just
passes the address of the first element.  Printf can't tell the
difference, and it doesn't care.  All you have to do is give it the
address of a series of characters ending with NUL, and it's happy.
String Constants 

You've used string constants since your first
“Hello, world” program.  How do they fit into the pointer model
of strings?

on line 17.  We use a string constant to initialize it.  Is a string
constant a char pointer?  , oddly enough.
 The compiler takes each string constant in your code, and copies the
content between the “”s, with a NUL tacked onto the end, into a
designated area of memory called the string
table.  This string table contains all the string constants you
used in your code, one after another.  The compiler then replaces the
string constant in your code with a char pointer to the first char in
the copy, as shown in the diagram.  So, what looks like a string
constant actually becomes a char pointer to a string table entry
containing that string.  And the initialization of 
makes 
point into the string table as well.
So what does this tell us about the first
parameter – the format string -- of scanf and printf, which up to
now have always been string constants?  Scanf and printf are C
functions, and they have function headers.  Based on what we just
learned about string constants:

What does the declaration of the first parameter
of scanf or printf look like?

It's a char pointer.  So the scanf
header looks like int scanf(char *format, .....


OK, so does that mean I can pass any char pointer
I want as the format string?  Sure, as we do on line 35.  We might
also have assembled a format string in a char array and passed the
array as printf's first parameter.

How does printf know that in one case its format
is a string constant, and in another case it's the address of a char
array containing the format string?

I'll stop doing this after this
question, but the answer is the same as before – printf 
know, and it doesn't care.  The format char pointer may be pointing
to a string table entry, an array, or what have you.  It just follows
the char pointer to wherever it points, and reads the chars at that
location as its format string, until it reaches a NUL.


The same principle applies to any function that
expects a char pointer – a string constant will do just as well, as
we show on lines 33 and 34.  
and 
are none the wiser – a char pointer is a char pointer.  Don't pass
a string constant as the first parameter to strcpy, though – this
would overwrite the string constant itself, in the string table.

So, in the final estimation a C string doesn't
have to be in a char array; that's optional.  The real definition of
a C string is:
A char pointer to the start of
a sequence of chars ending with NUL.
That's it.  It doesn't matter how you set up the
sequence – in an array, as a string constant, by dynamic memory
allocation (see later lecture), or by magic.  As long as you have a
char pointer to a NUL-terminated char sequence, you've got a string,
and all the string library functions will work with it.

Before we close this segment, now that we
understand about string constants and the string table, we're in a
position to understand an interesting debugging phenomenon that every
C programmer encounters eventually.  

You're working on a bit of code with an
inexplicable seg fault or similar runtime error, and you put a printf
into the code to track what's happening:
printf(“Got
to here.\n”);
(or maybe something a little more profane if it's
3am).  You run the program, and... The bug is
gone.  The debug printf runs and you get its output, but the bug
is also cured.
You have no idea why but, especially if it's 3am,
you're not inclined to question your good fortune, and with relief,
you remove the now unneeded debug printf, and.. The
bug returns.  WTH?
Just to be sure you're not delusional from lack of
sleep, you reinsert the printf, and sure enough the bug goes away,
until you remove the printf, whereupon it returns.  This bug is
taunting you!
You're solely tempted at this point to just submit
or release the code with the spurious debug printf, but you figure
someone's sure to notice.  So, what do you do?
Heisenberg
bugs (a private term, not field-recognized) in honor of
Heisenberg's Uncertainty Principle, which as you may know says that
it is impossible to observe a phenomenon without affecting it.
What's almost always happening is that the printf
introduces a new string constant: “Got to here &lt;insert
expletive&gt;!” into the string table.  This slightly adjusts the
layout of memory in the string table, enlarging it and shifting the
rest of the memory as well.  What was a “lucky” (visible) bug now
becomes “unlucky”.  It's  cured; that
bug is still there, just masked when the printf is present.  So, the
trick is to get it to show even with the printf.  This can almost
always be done by reducing the size of the string in the printf, to
change the amount of memory shifting: printf(“Gth,dmit”);
until the bug reappears even in the presence of the
printf.






	
	
	
	
	
	
In this segment we'll continue our discussion of
strings and pointers, looking at the 
function, and doing some important review on why assignment
statements aren't statements at all.


	Assignment expressions
	(review)
	
	



on line 4 of the sample code.  As I said earlier, this is a
handcrafted version of the 
function from the C string libraries, and works the same as .

Note first of all that it takes two char pointers,
consistent with the idea that strings are just character pointers. 

expects the 
to point to a NUL-terminated sequence of chars, and 
to point to enough space into which to copy those characters,
including the NUL.  Guaranteeing this is the job of the caller.  If
you copy a too-large source string into a too-small target space,

(and )
will cheerfully overwrite the end of the target space, with the usual
consequences.
So, how does this code work? Seems like that
little while-loop is doing an awful lot in one header line.  I'm
going to ask you to tell me how it works in some questions shortly,
but first, a bit of C review from prior study is in order here. 

First, recall our
earlier-lecture discussion about expressions such as ,
including relative precedence of the operators, etc.  The
postincrement will be done first, and then the star.
Second, recall from prior C
work that assignment “statements” are actually 
having a value.  So if we write:
a
= 42;
this not only copies the 42
into 
but the entire assignment also The
value is simply whatever was assigned: 42. This means, however, that
we may use 
as part of a larger expression, e.g.

c = 4 + (a=42);  //
Copies 4 + 42, or 46 into c

arr[a=42] = 0;   //
indexes arr by 42

d = sqrt(a=42);  //
takes square root of 42


Importantly, the assignment
into 
takes place in all of these cases.  The value of the assignment is an
additional feature, and allows more concise code, which is a big
virtue in the C mindset.  Our earlier look at pre- and post-
increment/decrement operators ties into this.  Those are also
assignments of a kind, and they have a value.
There's a related concept to
review here, too.  If assignments are expressions, then why can we
use them as a statement, ignoring their value?  Because C allows
expressions as statements, and simply drops the expression's value on
the floor if you don't use it.  You've been taking advantage of this
since your first “Hello, world” program.  Printf is a function,
and it returns an integer, so 

printf(“Hello,
world\n”);
is an expression, not a
statement, but when you use it as a statement, the integer return
value of printf is simply dropped.   (Printf's return value, btw,
indicates how many of the format specifiers were successfully
printed.  It's supposed to allow error-checking of printf calls, but
no one ever bothers with it.)  This “expressions are statements”
rule means you're always welcome to ignore the return value of a
function, and just use the function call as a statement.  

So, let's see.  Does that
mean you could write this as a statement:

Yep.  The machine in effect
says “Wow, 5”, and then forgets it and moves on.  A good
optimizing compiler may just drop the line entirely, since it has no
effect.  This sort of thing is not useful, of course, except as the
source of an occasional entertaining bug.
Like a number of popular C
features, the “assignments are expressions, and expressions can be
statements” rule persists in dozens of languages -- Java,
Javascript, C#, C++, etc., all of whom originally drew it from C.
And, to close this review,
let's talk about perhaps the most famous of C bugs: the “single =”
error.  Every C beginner, and sometimes even a C professional,
accidentally writes:
if
(a = 1) 

if
(a == 1).  

The maddening thing about
this bug is that it compiles and runs, but not the way you'd expect. 
To understand it, you must assume also that 
is an int, and you must recall that C uses int values to represent
true/false, with nonzero values being true and 0 being false.  (C has
no true boolean variables – all comparisons, and “boolean
operations” like &amp;&amp; and || are done with ints.  We won't
review that here; it's expected prior background and you should look
it up if needed.)

So, given that assignments are expressions, and
ints are booleans, why does if
(a=1)

It compiles because you can put an
integer expression into an if-test, and 
is an integer expression, with the value 1.  The 1 value also makes
the test automatically true, regardless of the original value of .
 



This particular example even
has the interesting property of setting  to
1, in effect forcing the intended a
== 1 test to be true.  The baffled programmer sometimes
reaches the following situation:
a
= 0;               // Dammit, it's not equal to 1, OK?
if
(a = 1)
  
printf(“%d”, a);
 // Prints 1.  Huh?


And
they finally realize that they've been 

be 1, not testing it to see if it's 1.



C allows what some call “chained assignments”,
like a = b = c = d = 0; which assigns 0 into all four variables at
once.  But, this is  an added feature of
the language; it follows naturally from what we've just discussed. 
How?  Answer by redundantly parenthesizing the chained assignment in
a way that shows what's happening.

a = (b = (c = (d=0)));  It's a
series of simple assignments, starting with d=0, which puts 0 into d
and has the value 0.  This becomes the right hand side of the c=
assignment, as the redundant parentheses show, and thus c gets 0. 
But this assignment now also has value 0, and is the right hand side
of the b assignment, etc.  It's important, by the way, that
assignment operators associate from right to left, like the * and ++
operators we discussed in the prior lecture


With that review, let's now look at line 5 in
.
 Assume that 
and 
point respectively to 
and 
and that those contain “professor” and “project” as shown in
the diagram.  We'll break this into two questions:

Show what happens on the first while loop
iteration, including any changes to the strings, and the two pointer
parameters.  On this first iteration is the loop test true or false? 
Notice that the test is an  not
an equality check.

As the changed diagram shows, the
increments advance both pointers to the second elements of their
respective strings.  But, since those are postincrements, the
addresses that get dereferenced are actually those of the first
characters, and so the first “p” is copied from string2 to
string1.  This is redundant in this example, but wouldn't be if the
strings had different first characters. 

The value of the assignment is the
ASCII code of the assigned character, which is nonzero, so the loop
test is true.


And the loop is ready for the next iteration, with
the pointers already advanced to the second characters.  So, the loop
continues, walking down the source and target strings, copying one
character at a time across, with the test being “true” as it
copies each character.

When does the loop stop, and what is the last
character to be assigned across?

It stops when source points to the
terminating NUL in the source string.  This gets copied across, and
the value of the assignment is thus 0, or false, ending the loop.


This is an example of why NUL, ASCII 0, was a good
choice for marking the end of a string.  This while loop can be so
concise in part because the only assignment that produces a false
value is that of the terminating character.  

And note that the lingering  r\0 (from the old
“professor” contents) at the end of 
is moot; it'll never be reached by any string function since they all
stop at the NUL after 't'.


a source string that has no NUL at the end?

A lot of chars get copied, since
StrCpy will keep going until it sees a NUL, charging through memory
and copying all the “characters” it sees over to the target. 
Eventually some byte in memory will be 0, and the loop will stop. 
Indeed, it's not uncommon for a 0 byte to be hit, by accident, very
quickly, since many bytes in the overall memory are 0s.  This means
that such a bug might actually go by without damage, making it yet
another 
Research
Question
Look
into outside research materials to answer this question.

Is there a way
to call strcpy, or a version of strcpy, that will ensure that the
loop stops after some number of characters (presumably the limit of
the target string size) even if the source string is too long, or
lacks a NUL termination altogether?

Yes,
the strncpy function takes a third, integer parameter giving the max
number of chars to copy. It's considered good style to use this when
you're at risk of handling malicious user input.




	
	
	
	
	
	
In this segment we'll finish our discussion of
strings and pointers, looking at the 
 function, and other string library concepts.


	Collating order,
	internationalization of same
	
	Indexing and offsetting
	char pointers
	




Let's look at

which is a bit more complex than .
 It takes two char pointers just like ,
and walks them down their respective strings, using the for-loop on
line 10. No initialization is needed since 
and 
already point to the start of their respective strings.  And the
incrementer advances them both by one character on each iteration.  A
bit of for-loop review in case it's needed here:
All parts of a for-loop
header are optional, though the semicolons must remain so it's clear
what you omitted.  If you omit the test, it's automatically true, so

is a synonym for endless-loop.
You can glue together two
incrementing or initializing expressions in a for-loop by joining
them with a comma, e.g.
for
(i = 0, j = 0; j &lt; max; i++, j++)
Technically that comma is an
operator (C's flexible definition of operators at work again) that
joins two expressions into one and has the value of the second
expression.  But almost no one ever uses it except in for-loops, to
glue together a couple of initializations or a couple of increments.
The
main complexity is in the for-loop test.  I'd like you to figure this
out on your own as much as possible, so here's a guided tour in the
form of in-lecture questions:

*s1
!= '\0' &amp;&amp; *s2 != '\0') test?  Summarize it in
a phrase of 4-5 words.

They test that neither s1 nor s2 are
pointing to an ASCII NUL ('\0', recall) and thus that“neither
string is done” as we advance s1 and s2.  So, the loop keeps going
only if neither string has ended. 


*s1
== *s2 ?  In the concrete example of “professor”
and “project”, exactly when will the loop exit, and where will 
and 
be pointing when it does?

That test is true as long as the
targets of s1 and s2 are the same.  The loop is designed to keep
running as long as neither string has ended, and the string contents
are the same. In the case of “professor” and “project”, the
loop will do 3 iterations, skipping over the “pro” in each
string, and then exit with s1 pointing to f and s2 pointing to j.

OK, so with the exit condition as described for
“professor” and “project”, what value does 
return?  Is that the right value, given the specification of StrCmp?
And, what is the general purpose of the subtraction on line 13?

It returns the difference between
ASCII codes for'f' and'j', which will be negative since 'f' has a
lower ASCII code that 'j'.  This is as it should be because
“professor” is less than “project” in lexicographic order. 
The return statement returns the difference between the first pair of
letters for which the two strings differ, which is the pair that
determines whether one string is larger than the other.

What would it take for that return statement to
return a 0?  Where would 
and 
be pointing?

The two strings would have to be
identical, and the loop would end with s1 and s2 pointing to the NUL
characters at their respective string ends.  0-0 == 0, so StrCmp
returns a 0 in this case, and only in this case.

What if we have strings like “cat” and
“catalog”?  How does 
deal with that?  There's no fourth letter in “cat” to compare
against the 'a' in “catalog”.  Does it need a special case to
work properly?  Trace the code and describe what happens. 
Specifically why does this question show once again that ASCII 0 was
a good choice for end of string?

s1 will reach the NUL after cat,
while s2 is at the 'a' in catalog.  The loop ends because one string
is done, and the return statement returns the difference between NUL
and 'a', which have ASCII values 0 and 97, respectively.  A negative
return value is correct since “cat” is less than “catalog”. 
 ASCII code is greater
than NUL, so if one string ends first, the other string's next
character will always “win” in the subtraction.  The choice of
ASCII 0 is perfect in this case.



An interesting side point regarding string comparison is that the
order of characters – the 
-- is determined by their ASCII codes.  In particular, this means
that all capital letters (codes 65-&gt;90 for 'A' - 'Z') are “less”
than all lowercase letters (codes 97-&gt;122 for 'a' - 'z').  You'll
often see computer-sorted word lists with all the capitalized words
first for this reason.  

And,
in the 21
century, the concept of “sorted order” is broader still.  Even
among languages that use the Roman alphabet, the collating order
is different.  Every nation sings a different alphabet song, so to
speak, and modern languages (e.g. Java) often include logic to adjust
the collating order per-culture.  1970's vintage languages, sadly, do
not.
More String Library
Fun
Now that we've
covered StrCpy
let's
return to the main program.  The StrCmp call on line 25, which we
just used as our example, is checking to see if the strings differ,
by checking for a nonzero return.  They do, so the StrCpy on line 26
(which was our example from the earler segment) copies “project”
into The
line 27 printf illustrates the result in the output at the bottom.   

We've already discussed lines 30-36 in earlier
segments.  Be sure you follow those lines and their output, and agree
that by line 38 
contains “new data” and 
contains “project”.
Lines 38-43 show some more interesting uses of
strings and the string library, and introduce two new library
functions. On line 38, we pass

to 
as the target.  This passes a pointer to the 'd' in “new data”,
so 
will copy “stuff” on top of “data”, and 
will contain “new stuff”, as the printf shows.  This is yet
another example of the principle that “the string functions don't
care where you get your pointers from”,  even if it's a pointer
into the middle of a string.  This sort of code can be useful in more
creative string editing.
,
which works like strcpy, but tacks the source onto the end of the
target instead of overwriting the target.  So now 
contains “projectX”.  Per
usual, strcat just assumes the target has enough room for this.
Lines 40-41
print our string changes, and also the result of a strlen call.  The
strlen function returns the number of characters in a string, not
counting the NUL
The final printf on line 43 is a kind of rogue's
gallery of interesting string pointer actions.  See if you can figure
out why the final output line turns out as it does.  For instance,
we've already seen that offsetting from the start of a char array
gets you the address of a char within the string, so 
points to the 's' in “new stuff”.  That explains the “stuff”
at the start of the printed line.

So, what about the next parameter. Can you even
“Test
String”+5?  Evidently so, since it produces an output
of “String”, but why, exactly? 



a pointer to the 'T' in the string table. it may look like a string
constant, but it's converted into a char pointer to a string table
entry.  And like any pointer it can be added to, so we're passing the
'S' in “Test String” from the string table.



What about
“NESW”[3]?  Why does it print 'W', and why is the format
specifier for this one a %c instead of a %s like the rest?

In for
a penny, in for a pound.  If “NESW” is a pointer to the 'N', it
can be indexed, like any other pointer.  The index+3 (fourth) char is
'W'.  Recall from earlier segments that indexing a pointer includes a
free dereference, so it is literally the char 'W, not its address,
that is passed to printf.  A %c specifier is thus in order.  This is
a good example of distinguishing between a pointer and its target. 
If you give printf a char pointer, you use %s, but if you give it a
character, you use %c.
You'll
sometimes see string constants indexed in this way to pik one char
out of a related set.  NESW, for instance, stands for the four points
of the compass.



So we come to
“”+1.  To understand this, we need to look at the empty string
constant “”.  It represents a pointer to something, but what?  To
answer this, first be sure you see that a one-char string constant
like “X” results in 
bytes in the string table: X and NUL.  You always have to have that
NUL.  So, if we reduce the constant down to “”, it makes sense
that there will be one byte in the string table, just the NUL, and
that “” will represent a pointer to that NUL.
A pointer directly to the terminating NUL is the
ultimate in short strings.  It's worth going back over the StrCmp and
StrCpy code, to convince yourself that they work in this boundary
case.  



points directly to the NUL?  Does anything get copied to the target
string?  And, how does StrCmp work if you pass a pointer to the NUL
for one of its parameters?  Is an empty string less than or greater
than a non-empty string, and why?  Trace the code in each case.

StrCpy will copy just the NUL across
to *target, and then the while loop exits because the assignment has
value 0.  This is as it should be: the target string is now an empty
string, just like the source.  And StrCmp will also work, with the
for-loop exiting immediately since the empty string is already
“done”, and the return statement doing a subtraction between the
NUL of the empty string and the non-NUL first letter of the non-empty
string.  The empty string is thus automatically less than any other
string.


So, now that we have a handle on the empty string,
let's look at “”+1.  I might have just printed “”, but that
would be boring, as it would predictably have printed nothing. 
Instead, I decided to end the example code with a bug, which “”+1
certainly is.

Why is it a bug?  What pointer value is being
passed to printf, and how could that possibly have resulted in NESW
being printed, as the output shows?  Think carefully in particular
about the string table concept.

The +1 increments the pointer past
the one NUL character in the empty string, to whatever lies past the
empty string.  Thus it's a bug.  But the empty string is in the
string table, adjacent to other string constants.  It's hard to say
which string constant, if any, follows the empty string, but that's
the one you're going to print, giving a surprising result.  Note that
you may find the code runs differently on your compiler – it
depends on how the string table is organized.






	
	
	
	
	
	
In this segment we look at basic dynamic
allocation of memory in C, a concept we'll use heavily in lectures to
come.


	
	
	


Up to this point, all the variables we've used
have been declared specifically.  Our program starts with a declared
set of variables, and those are all we get.  But, it's not always
possible to know in advance just how much data a program will need,
and more sophisticated programs often need to, in effect, create new
variables while they run, to accommodate data as they get it.
As a simple example, when we declare a char array
to hold a string, we must declare it to be a certain size, and thus
strings larger than that size (less one for the NUL) will not fit,
and smaller strings will waste part of the space.  Being able to
create an array of just the right size while the program runs would
fix this.
An aside here: you may be aware
that C99 compilers will let you declare an array using a variable
instead of a constant, which variable you can set during the program
run, adjusting the size of the array.  The C99 standard is not
universally used, however, and its variable-sized arrays have
limitations.  The C99 feature partially automates a standard method
for creating variable-sized blocks which we'll learn in the next
lecture segments.  You'll be expected to use this “old-fashioned”
approach in the class, and in most industrial development teams.


C reserves a large block of memory, called the
, for the purpose of creating
new variables as the program runs.  There are no variables in this
area of memory when the program starts; it's just uninitialized
space.   But you can create new variables from it while the program
runs, reserving space in the runtime heap for your variables.  This
is called 

Dynamically
allocatedvariables
have no name.  We generally can't predict how many we'll need, and so
cannot plan names in advance.  Instead, we use pointers to access
them.

Look at lines 8 and 9 of our sample code.  Here we
have a double pointer 
and an int pointer ,
initialized not by assigning the address of an existing variable into
them, but instead by dynamically allocating (creating from the
runtime heap) two nameless variables for them to point to.
You can create new variables from the runtime heap
by calling the 
library function (which is available if you #include &lt;stdlib.h&gt;).
 
is one of the most important library functions in C, and a typical
industrial C program will include hundreds or thousands of 
calls.

has one parameter – the number of bytes of runtime heap storage you
want to reserve for your new variable.  You want a number of bytes
just right for the type of variable you're creating.  The best way to
determine this is with a sizeof operation, as we do in the code.   


looks in the runtime heap for an unused space of the size you
requested, marks it as reserved space (we'll look at how it “marks”
it in an upcoming lecture) and then returns the address of the space.
 Typically you then assign the returned address into a pointer, as on
lines 8 and 9.   From then on, you use the space by dereferencing the
pointers.
Since the space is otherwise nameless, the pointer
is the only way to get to it.  You must have pointers in order to
have dynamically allocated variables.


returns, it can be assigned, without casting, into a double pointer
or an int pointer.  (And, as we'll see, to any other type of pointer,
too.)  So, what type does malloc return?

Malloc must return a void pointer,
the only fully generic pointer type.  It's our job to assign that
void pointer return value into the right type of pointer so that the
target will be treated as the right type of variable.


The output from line 10 shows the actual addresses
from the runtime heap that 
returned.  The runtime heap in this case is obviously in the high end
of the memory, since those addresses are a little over two billion,
but the location of the heap is not really predictable; we just trust

to manage it correctly.  

On lines 12-13 we pass the address of our
dynamically allocated variables to scanf, to get values entered into
them, and then we dereference the pointers in the printf, to compute
and print the sum of the two values. The dynamically allocated
variables are just as usable as any other integer or double –
memory space is memory space.  You just have to get to them through
pointers.
(Of course, we would need to be sure the starting
addresses are aligned properly in memory.  Recall the earlier
discussion on bus errors.  
does ensure proper alignment, returning an address divisible by 4 or
8, as needed.)

So far this is nothing we couldn't have done with
a couple of ordinary variables.   What dynamic allocation gives you
that ordinary variables do not is what we might call “variables on
demand” -- you can create as many new variables as you like,
subject to runtime heap memory limits.  And, they may be of any type.
 In later modules we'll do a lot of this, but for now the loop on
lines 15-18 illlustrates the basic principle.
That loop executes three times, and creates a new
double, pointed to by ,
on each iteration.  Look at the output lines below, and you can see
that 
points to a new address on each iteration.  In fact, if you look
closely, the address in 
advances by 16 bytes each time, as 
choses the next available spot in the runtime heap.  (We'll see later
that even if you ask for, say, 8 bytes to hold a double, 
returns a little more than you requested, for housekeeping reasons –
thus the 16 byte jumps.) 

The loop stops after three iterations to keep the
output reasonable, but nothing would have prevented it from running a
thousand, or even a million times.  We can make as many doubles, or
any other type of variable, as we have room for in the runtime heap.

But, there's something wrong with that loop.  The
only way to get to allocated storage is via a pointer, but we're
changing 
to point to a new double on each iteration, and thus losing track of
the prior allocated variable each time.  This illustrates an
important point about dynamic allocation: Keep a
pointer to your allocated variable, or lose it.  There's no way
to find an allocated variable after you've lost the pointer to it.
The lost variables in that loop not only cannot be
used, their space in the runtime heap will be forever marked as
reserved, so that no other call of 
can make use of it.  The runtime heap is not of infinite size, so
running the loop enough times would eventually fill the runtime heap
with doubles that have been created by ,
but which we can no longer access.  Such variables are called dead
storage. There is a way to avoid dead storage, which we'll look
at in the next lecture segment.




	
	
	
	
	
	
In this segment we'll look more at dynamic
allocation, and at how to recycle runtime heap space, to avoid dead
storage.


	
	library function
	
	


The second big advantage of dynamic allocation,
aside from being able to create variables on demand, is being able to
avoid dead storage, and instead reuse the same memory for different
variables as the program runs.  

It's not uncommon to need a variable for a while,
but then be able to dispense with it. We could do that by just losing
track of the variable, changing our pointer to point to a new one, as
in the line 15-18 loop, but to avoid dead storage we really want to
mark the unwanted variable's space as “available for reuse”, so
that it may satisfy the memory needs of later malloc calls.
,
which is the partner to .
 Pass to 
a pointer to the dynamically allocated variable you no longer need,
and 
marks its space as reusable.  Future 
calls will use the space if it fits their needs.
The loop on lines 21-25 is nearly the same as that
on lines 15-18, except that it's allocating ints instead, and it
includes a 
call.  We keep each allocated integer only long enough to print its
address, and then “free” it back into the available space of the
runtime heap.  As you can see from the output, the space is indeed
being recycled, since each malloc call returns the same address,
reusing the same space for each “new” integer.
This ability to recycle memory is one of the
biggest advantages of dynamic allocation.  Like any good recycling
program, the dynamic allocation system takes a limited resource
(memory) and makes it last longer by reusing it.

A common misunderstanding regarding free is that a
statement like 
frees 
itself.  The pointer is just a local variable; its storage is not on
the runtime heap.  It is 's
, in this case an integer on the
runtime heap, that is freed.  Be sure to have this clear.  It's yet
another case where we must distinguish between a pointer and its
target.

We might reasonably ask whether careful memory
recycling is all that important, given that the runtime heap is
several gigabytes large in a modern computer.  A small program that
is sloppy about freeing storage and runs only for a short time may
get away with it, but any professional code is expected to carefully
free all storage obtained via malloc once it's no longer needed, and
never to create dead storage.  

Especially if a program runs for a long time, even
one missing call of 
if repeated over and over in a loop, will build up progressively more
dead storage until finally the runtime heap is choked to the point
where 
calls fail.  This kind of bug is called a storage
leak, as though memory were gradually hissing out of the
program like air from a slowly leaking tire.  It's an especially
insidious bug because it often won't show up until the program has
run for a long time.  You don't want to find out about your missing

call when the deep space probe is past Mars or when the nuclear
powerplant control system has been running for a year.
Lines 28-31 illustrate what happens when you omit
a 
call.  The loop makes several very large allocations so we don't have
to wait a year for the storage leak to build up.   (You don't have to
limit your 
call to just a few bytes, by the way; you may ask for as many as you
like, even 800 million as we do on line 29.  In fact, we'll use such
large allocations in the next module to create dynamically allocated
arrays.) 

Given that we are not freeing any of those big
allocated blocks, you can see from the output that on the fourth
call, malloc starts returning 0.  This is 
an address in the runtime heap; it's 's
way of saying it cannot reserve what you requested because it's run
out of space.  This is what happens, ultimately, when you have a
storage leak – your 
calls start to return zero

That 0 pointer value deserves some discussion.  We
often need some way of indicating that a pointer doesn't point to
anything.  The return value of 
when there is no storage left is just one example.  In another
lecture or so we'll be looking at linked lists in C, which also need
a “pointer to nothing”.  


are represented with a 0 address value.  There's never a good reason
to actually point to address 0, so using 0 to mean “points nowhere”
works well.  The standard C library even includes a #define NULL as 0
so that you may compare or set pointers to 0 using NULL instead of an
explicit 0.  Always use NULL, like we do on line 31 to end the loop
when 
returns a null pointer.




	
	
	
	
	
	
In this lecture segment we'll extend the dynamic
allocation concepts from the last lecture to include creating arrays
of dynamic size, and we'll introduce 
an 
cousin.


	
	




The sample program for this segment does a fairly
simple task: it asks the user for a number of integers, then reads
that many ints and prints them back out.  Saving the ints obviously
requires an array, but the interesting thing is that we cannot
predict the size of the array in advance, not knowing what number of
integers the user will enter.  With fixed-sized arrays, we'd be
caught between making a small array and not being able to deal with
large numbers of integers, or making a larger array, usually wasting
most of its space, and still not being able to accommodate very large
numbers of integers.
What we need is an array whose size we can set
after knowing how how many integers the user wants to store – a
sized
array.  C doesn't offer such arrays directly (except in its
lightly-used C99 variant), but we can use pointers and malloc to make
a pretty effective equivalent.  

Recall that a pointer to the start of an array can
be indexed just like an array, to get to the elements of the array. 
Combine this with 's
ability to give us a memory area of any size, and that means we can
set up a pointer to a , as on
line 24, and then treat it like an array.  If, as in our example, the
user has asked to store 
ints, we call 
to create a block of memory large enough for that many ints – the
same number of bytes as an int array of that size would have – size
* sizeof(int)
to the memory block, then we may use 
in the same way we would an array, indexing it from 0 to .
 We can also pass it to a function like ,
that expects an int array, since of course all that ever gets passed
for an array is its initial address, and 
won't know the difference.  So, 
will read the user input into our memory block.

in the 
call; asking for just 
bytes would be insufficient: each integer occupies several bytes.
As you can see, after creating the memory block on
line 24, we pass it to 
to scan the required number of ints, then to 
(more on that in a moment) to print them, and then, importantly, now
that we're done with the memory block, on line 27 we call 
to free 


on line 27.  What should I have said instead?

Per prior lecture, line 27 frees
the memory block, not the pointer iBlk itself,
which is just a local variable and was not created via malloc.  I
should have said that line 27 freed iBlk's target.  This may seem a
minor point, but it's important. The pointer and its target are
distinct entities, far apart from one another in memory.  Only the
target is part of the runtime heap, and needs freeing.



in a somewhat fancy way (though not atypical of professional code). 
Look at that while loop on line 14.  It's supposed to iterate 
times and print each successive value in the array 

while
(--size) instead?  I did say earlier that preincrement
and predecrement operations are a little faster, right?  Or, would
there be a bug.  And what would the bug be, if so?

Assuming size is 6, consider what
the values of size-- will be on each execution of the while: 6 5 4 3
2 1 0.  The postdecrement has the 
value of size, not the newly decremented one.  This is good, since it
means the while will be “true” the first 6 times, and then
terminate before doing the 7 iteration.  But, a
predecrement would have the values 5, 4, 3, 2, 1, 0, and the loop
would only execute 5 times.  Using a predecrement here would be a
bug.


This kind of off-by-one bug is quite common in any
language, and one good way to diagnose it is to try an actual
concrete example, like I just did by assuming 
was 6 and tracing what the code would do.  

,
be sure you understand what I did on line 13.  I wanted to have
different labels on each call of 
so I passed a string constant (a char pointer) to parameter ,
and then passed label ,
to .
 Since the label string has no format specifiers in it, no other

parameters are needed on line 13.

Just to make the point clear, lines 29 through 31
ask the user to pick another number of ints (this time, 8, in our
example) and create a new memory block of that size instead.  But,
line 32 calls 
on the uninitialized block, just to see what's in there before the
call of 
on line 33.  As you can see in the output, it's garbage data. You
should always assume that memory returned from 
has uninitialized garbage, just like any other C variable.

But, there's also something interesting about that
garbage data.  Look at it closely, especially the middle values.  Do
they look familiar?  And can you explain why?

Yes, they look familiar.  They are
part of the content of the memory block we just freed, though
apparently the 12 and the 23 got trashed up somehow.

Is that just a coincidence, or is there a
reasonable explanation for it?  (Don't worry about the first two
values for the moment, just the middle values.)  Did the values from
the prior block of 6 integers somehow get 
into our new 8-integer block, or what?

They didn't get copied.  Our new
block is in the same area of memory as the prior 6-integer one, since
the prior one's space was freed on line 27 and its space was reused
for our 8-integer block (plus a few more bytes for the additional two
integers).  Apparently the data that was in it, at least part of it,
survived the recycling process.


The reason the first two values were trashed is
that the 
must “mark” the block as available for reuse, and it does this by
writing some information into the first few bytes of the block,
wiping out prior data.


at least makes sure my pointer doesn't point to the block anymore. 
E.g. after line 27, 
no longer points to the 6-integer block from the first set of data,
right?  Right?  Think about it.  You can answer this just knowing how
C parameters work, without knowing the details of .
 Where will 
be pointing after line 27?

iBlk is passed by value; free gets a
copy of it.  Both the original and the copy point to the block to be
freed.  But free has no way of modifying the original iBlk pointer,
since it has only a copy of the pointer.  So, iBlk continues to point
to the storage that was just freed.


This set of questions illustrates three important
points, and two traps to avoid, regarding allocated data:
1. Malloc returns memory that
has trash in it.
2. Free doesn't wipe out the
data in the freed block – it just trashes part of it to mark it as
free. And, the part that gets trashed will vary from
machine to machine.
3. After a call of free, the
pointer you passed to free still points to the now-freed data.
The second and third points mean you can try to
use the data you just freed, and you'll sometimes get away with it. 
The pointer hasn't changed, and of the
data hasn't either.  This is another unlucky bug, since it might not
show immediately. So:
1. Never use just-malloced
data without initializing it.
2. Never use data you just
freed, not even for one last glimpse of it on the next line of code. 
Your pointer still points to it, but it's subtly and partially
trashed by the free call.

There is a way to get dynamically allocated data
already initialized to zeros.  The 
function is a close cousin to .
 It allocates space from the runtime heap just like ,
but it initializes the space to all 0 bytes.  And, it takes two
parameters and multiplies them together to get the total size to
allocate (just in case you're too lazy to write the * yourself). 
This two parameter arrangement fits well with dynamic array
allocation: you give the number of elements you want as the first
parameter, and the size of each element as the second, as we do on
line 37.  And as you can see from line 38's output, the allocated
space has all zeros.

-ed
block.  This is technically a bug, but it won't cause harm in this
case because the program's about to end anyway.  When your program
ends, the runtime heap, whether its content has been freed or not,
ceases to exist along with the rest of the code and memory.  So,
freeing that last block is like recycling your bottles just before
the world is about to end – a nice gesture, but not essential.

call anyway.  You never know when you, or some other programmer, will
add more code to the end of the program, and put off Armageddon.  In
that case, your uncollected trash will cause problems.

Our external research problem for this segment has
to do with the library functions for block allocation.  You'll
probably find online references of good quality a better resource for
this than K&amp;R itself, though either will do.

Say I've allocated a block of 1000 bytes, and I
find I only am using the first 500 of them, and would like to free
just half of my memory, keeping the first half allocated.  What
single function call do I write to do this?  Show the actual code
before looking at the answer.

Use realloc.  It accepts either a
larger or smaller size, and adjusts the block accordingly.  And, btw,
it almost always keeps the current block and just marks its latter
part as free space, when you reduce the block's size.  Here is the
code, assuming blk points to your block:  blk = realloc(blk, 500);






	
	
	
	
	
	
In this lecture we'll start looking at linked
lists in C.  While this may be review material for many, we'll
present it as new material, though at a quick pace.  Even if you have
already worked with linked lists, be sure you understand how they
work in C by reviewing and understanding the code example, and doing
the in-lecture questions.


	
	
	
	





typedef on lines 4-7.  It's a simple-looking struct, but the 
field on line 6 is something special.  It's a field of but
also a pointer to .
 How does that work?  And what's that extra 
keyword on line 6 for?
First, a struct may have fields that are pointers
to its own type.   Such pointers could point to the very struct of
which they are a part, but usually we create several structs of the
type – several 
– and they point to one another via their respective 
fields.
Before we start pointing these structs to one
another, though, let's look at the special syntax needed for a
self-referential pointer like .
 We can't use 
alone to declare such a pointer, because the typedef isn't completed
until line 7 and thus can't be used on line 6.  But, C allows you to
set up a for a struct, by adding
a name after the 
keyword, as we do on line 4.  This tag name can be the same as the
typedef name, or different – it's usually clearer to make it the
same.  The tag name is instantly usable on the following lines, but
you must repeat the 
keyword to use the tag name.  That's why we added the 
keyword on line 6; we're using the tag name there, not the
as-yet-unfinished typedef.  

Once we have the typedef finished, it's more
convenient than the tag name, since we don't have to repeat 
over and over.  So just about the only time a struct tag name is used
is for  fields – those
that point to the same struct type of which they are a field.


pointer field to 
itself lets us set up chains of these structs, as I show in the
diagram.  Each struct's 
pointer points to the next struct in the chain.  The final next
pointer contains NULL.  Typically we have a single pointer (not a
struct) like 
on line 42 to point to the first struct, and then the chain continues
from there.
linked
list. head
pointer,
thus the names 
and 
in the code.
Why set up such an arrangement?  Because each
node, aside from pointing to the next, also carries some data.  In
our simple example that's just an int field called, appropriately
enough, ,
but in a working program the data may be multiple fields, so that
each node carries quite a lot of information.  A university
registration system, for instance, might have a linked list where
each node carries information on a student, and another linked list
where each node has information about a course.
We already have a way to hold such sets of
information, of course: arrays.  And using the concepts from the
earlier lecture, we can even choose the size of the array while the
program runs.  But, even with dynamic allocation, once an array or
memory block has been created, its size may not be changed.  If we
run out of space in the block and wish it were bigger, there's no
recourse but to create another, larger block and copy the smaller one
into it, discarding the smaller one – a time consuming task. 

(It's tempting to think that one might simply ask

or a related function to  “extend” an existing block by a few
more elements, but this assumes that the runtime heap space
immediately after a block is available and not reserved.  This is
rarely so, and thus we cannot reliably increase the size of an
already-allocated block.  There is a C library function 
that appears to increase a block's size, but usually it has to do the
copy-into-a-bigger-block approach from the prior paragraph.)
So, what can we do if we want to store a set of,
say, student data, and we cannot predict how many students we will
have?  The linked list solves this problem, in that it can be
extended one node at a time, ad infinitum, by dynamically allocating
nodes as needed and linking them into the existing list.  In the
following discussion we'll see just how that works.

In the main program, we start with an empty linked
list, and then call 
on lines 45-47 to add nodes to our list. 

Diagrams are essential 


carefully to explain how this is done, but first a critical point. 
You cannot understand linked lists without
drawing diagrams.  And, you have to draw them correctly, in
particular showing an actual box for each pointer, including the head
pointer.  The diagrams for this lecture are a good example to follow.
 Every programmer who works with linked lists does such diagramming
in effect; experienced programmers just do it in their head.  Until
you can confidently diagram linked lists in your head, do
it on paper, 
So let's start with a diagram of an empty list. 
An empty linked list has a head pointer (our variable ,
again) but no nodes, so the head pointer is set to NULL, on line 42. 
A NULL pointer consistently marks the end of a list, whether it's the
value of 
or the value of 
in the last node.
And a note on diagramming: when a pointer contains
NULL,  draw an arrow coming from it. 
There's no place in memory called “NULL”.  A NULL pointer simply
has no target at all.  Also, please don't use the phrase “points to
NULL”.  Say “is NULL” instead, to reinforce the idea that a
NULL pointer 

works by taking an integer to put into the 
field of a new node, and the current head pointer.  It adds a new
node to the start of the list, and returns a new head pointer value
(the address of the added node) which we assign back into 
This is the first time we've seen a function that
returns a pointer.  The syntax for declaring a pointer return type
can be seen on line 9.  You add a * ahead of the function name to
make it return a pointer, just like you add a * ahead of a variable
name to make it a pointer.  Typically such a function sets up a
pointer as a local variable, and returns it.
,
the NULL in 
is copied to parameter oldHead.
,
by calling 
with a request for enough memory to store one node of the linked
list.

now points to a new node that we'll add to our list.  Line 12 copies

into the data field of our new node, and line 13 copies 
into the 
field.


point?  (Bit of a trick question...)

It points nowhere.  It contains
NULL, copied from oldHead.


This is as it should be, because in this case our
new node is the only one on the list, and is thus automatically the
last one.  The last node on a linked list always has a NULL pointer.

so that main can assign it into ,
and we're left with the configuration shown in the diagram, with 
pointing to the one node on our list.
But, does it work for the next node, added by the
call on line 46?  In this case we already have an existing node, and
we need to add the new node ahead of it on the list.  The first few
lines of 
work the same, creating the new node and filling in its 
field, but line 13 has a different effect than the last time.  Now,

points to the existing node on the list.  So rtn-&gt;next
= oldHead
point to 
like the diagram shows.  Uh...

.. no, it doesn't.  What's wrong with what I just
said, and with the diagram?  I'm making a very common and critical
mistake regarding pointer assignment that I want to point out so
you'll avoid it.  What should I have said and drawn instead?

Assigning one pointer into another,
say ptrA = ptrB, does  point ptrA to ptrB!  It
copies the address in ptrB into ptrA, and the result is that they
both point to a third, separate thing from either pointer – ptrB's
target. I should have said that rtn-&gt;next will now point to the
existing node on the list, just like oldHead does.
Now that we have the diagram correct, we return
 so
main can assign it into 
on line 46, and the linked list will have two nodes, as shown.

new nodes to the list, by using the return value of one 
call as the second parameter to the next.  If that surprises you,
note that we can use expression of the
correct type to satisfy a parameter, even a function call's return
value.

What order are the nodes in after that line-47
call?

The 40 is in the first node.  The
innermost Add call, with the 30, is done first, so the final order is
40, 30, 20, 10.




	
	
	
	
	
	
In this lecture segment we'll continue our
discussion of the linked list example, traversing a list, and
covering some important review topics.


	
	Protected/conditional/short-circuited
	and/or (v)


,
which checks to see if the list contains a given value, and returns a
boolean indicating if the value is there.  The for-loop on lines
20-21 does the main work.  We'll trace it through with diagrams,
assuming we have the four-node list resulting from lines 45-47

to be a copy of .
 Per our earlier discussions on pointer assignment, this copies
head's target address into 
and thus points 
to the first node on the list.  The loop test checks to be sure 
is not NULL, and if it isn't, also checks that the 
in temp's target node doesn't match .
  For this example, 
is 20, so we don't have a match yet.
These are the conditions under which we want to
move to the next node in the list.  But, a question first:

Could that NULL test be true at this point in the
code, just after the initialization?  How if so?

If the list is initially empty, then
head will be NULL, and so will temp.  The loop stops right away, as
it should.


And, before going further, a couple of questions
on a review topic that's relevant here:
Question
2:
Could I have swapped
those two tests, writing temp-&gt;data
!= value &amp;&amp; temp != NULL? (Would I even be
asking the question if the answer was yes?).  If not, why does it
work one way, but not the other?  Assume that following a NULL
pointer results in a seg fault.
This question has
nothing to do with linked lists, but rather with an important
property of &amp;&amp; you need to understand.  

Answer
2:
No, you
can't switch them.  Doing so would cause a bug if temp == NULL, since
the temp-&gt;data in the first half of the test will follow a NULL
pointer.  But, in the original version wouldn't it follow a NULL in
the second half?  No!  C's &amp;&amp; operator is 
(also ;
they're all synonyms).  If the first test is false (if temp == NULL,
on line 20) then the second test is not even examined or run.  We
don't need to run it because if the first test of an &amp;&amp; is
false, the &amp;&amp; will fail regardless of the second test.  The
second test is moot, and is ignored.  

This is not an obscure
language feature; it's essential semantics in every modern
programming language, and was first popularized by C.  Perhaps that's
why it has three synonymous terms to describe it.  The protected (or
short-circuited or conditional) &amp;&amp; means that you can rule
out a special case in the first test of an &amp;&amp;, and then
assume the special case does not apply in the second test, since the
second test wouldn't even be run if the first test failed.  (Old
Pascal didn't have this feature, and working around that was a
constant headache.)
Question
3:
Just to be sure you've
got the idea, there's a similar behavior for ||.  If the first test
completely determines the outcome, the second test is ignored.  What
must the first test's result be for the second to be skipped: true or
false?
Answer
3:
It would
have to be true.  If the first test is true in an ||, then the second
one is moot; the || will succeed either way.


So, back to IsOn.  Assuming we haven't found a
node with 
equal to ,
we need to make 
point to the next node, and try that one.  The loop increment
accomplishes this, copying 
(which points to the next node) into ,
so that temp also points to the next node, as the diagram now shows. 
This particular assignment is ubiquitous in linked list code – it's
the equivalent of  “”
in an array loop.


have worked just as well?  That will compile, and it advances ,
right?  Be sure you see why this  work.
 What will it do instead?

It would “advance” temp, all
right, to an imaginary node just after the current one, as if temp
were pointing to an array of nodes.  But, there is no guarantee that
the nodes in a linked list are right after one another.  They were
each created from separate malloc calls, and could be in arbitrary
locations in the runtime heap.



down the list ( the list in
computer-science speak) until 
points to a node whose 
is equal to ,
whereupon the loop-test fails and we drop out of the loop.  That
happens  in our example when we get to the third node.

But, what if no node matches?  Trace exactly how
the loop ends if 
makes it all the way to the end with no match. In particular, how
many times does the loop test get done if, say, the list has four
nodes like our example and none of them match?

When temp reaches the last node, the
loop incrementer assigns NULL into temp, copying it from the last
node's next pointer, which is NULL.  The loop then ends on the next
loop-test.  So there would be 5 executions of the test for a
four-node list if no data matches.


temp
pointing to the third node.  All that remains is to
return true or false based on whether we found a match, as we do on
line 22.  That line illustrates two generally useful design ideas.
First, it's often elegant to arrange a loop that
can end in one of two ways (e.g. with 
pointing to a matching node, or equal to NULL) and then to check
after the loop is done, to see which way it ended.  This is usually
better than embedding an if-statement in the loop.  In our case, if

is not NULL after the loop is done, this means the loop must have
ended by finding a match.  So, we return true if and only if temp
!= NULL.  post
mortem loop test.

write something like this, in C or any other language:
if
(temp != NULL)
return
1;

return
0; 



Just return the test result
directly, as in the example code.  The if-statement looks amateurish,
and is needlessly complex. temp
!= NULL  a boolean (int)
result, and you can return it directly.


Finally, look briefly at line 49 where we call
IsOn as part of a printf.   Sometimes you can customize a printf by
choosing one of two strings via a conditional operator, in this case
one that uses the result of 
as a test.  You insert the string result into the overall printout
via a %s format specifier.  In this case we get “is”, or “is
not” inserted into our printf.  It's a relatively common coding
pattern.








	
	
	
	
	
	
In this lecture segment we'll finish our
discussion of the linked list example, focusing on removing nodes
from the list.  

Even if you already understand linked lists,
please dial in on this lecture, especially if you learned your linked
lists in a language like Java or JS, that offered the convenience of
automated garbage collection.  As you know from prior lecture, C also
has a garbage collector – and it's This
makes node removal more interesting in C.


	
	


,
which removes the first node from the list, and returns a new 
value – a pointer to the remainder of the list after the first node
is removed.  (For simplicity, 
does no error checking; it assumes as a precondition that there is at
least one node.)

starts by initializing its local pointer 
to point to..


point to after that initialization on line 26?

It points to the second node. 
head-&gt;next is a pointer to the second node, and the address in it
is copied into temp, so temp will also point to the second node.



then does a call of free(head),

the head pointer, but its target, right?).  And here's where any
Java,  C#, JS, etc. programmers will notice a difference.  Many
modern languages boast an automatic garbage
collector, which the program automatically runs in the
background.  This senses when you no longer have a reference or
pointer to a dynamically allocated node, and frees it automatically. 
Automated garbage collection is a nice feature, but in C, 
are the garbage collector.  As discussed in earlier lecture segments,
you must call 
to avoid a storage leak.  Absent line 28, the node we are removing
would continue to exist for the rest of the program as dead storage.

returns ,
the pointer to the erstwhile second node, now the first node, to be
assigned back into 
in the main, as on line 52.  All that's left is the three remaining
nodes, pointed to by .
 The printf on lines 53-54 confirms that 30 is now the first value,
and 40 is no longer on the list.


could be simplified.  What's wrong with eliminating 
entirely, and just doing this instead?  


return
head-&gt;next;


Would your answer change if I actually tried it in
the code and it worked?  Why?

Once head is freed, its data,
including its next pointer, is unpredictably trashed by free, per
earlier lecture.  It might be that the next pointer escapes trashing
and the code works anyway, but that will vary per computer and per
compiler, so it's “unlucky” if it does work.  Never use
just-freed data, even on the very next line.




to free all the nodes on the list before the program ends.  As
mentioned in earlier lectures, this is perhaps needless since the
runtime heap will go away anyway when the program ends, but it's good
style since you never know when more code may be added later.

does the same operation as ,
but in a loop that continues as long as the list is not empty.  You
should be able to follow that code pretty easily now.  And, it should
be clear from the question above that we could
not
while
(head != null) {

head
= head-&gt;next;



As a side note, you might
find it amusing to know what the equivalent code would be in the
presence of a garbage collector, say in Java.  As mentioned above,
the garbage collection system is smart enough to automatically free
any nodes you can no longer reach, directly or indirectly.  So,

in Java would be:
head
= null;
And that's it.  By setting

to null, you automatically make the entire list unreachable, which
makes the garbage collector free all the nodes.

So, in closing here are a few more challenging
in-lecture questions to consider:

Assuming there are several nodes already on the
list, what does this code do?  Trace it carefully with diagrams.
head-&gt;next
= head-&gt;next-&gt;next
Note that you may apply “-&gt;next” to any
pointer, including a next pointer.  Each “-&gt;next” implies
another “dereference and pick one field” action.

This removes the second, not the
first, node from the list, since it changes the next pointer of the
first node (head-&gt;next) to have the same target as the second
node's next pointer (head-&gt;next-&gt;next), which target is the
third node.  This cuts out the second node from the list altogether.

If we actually used that code to remove the second
node from a list, even given that the list has at least two nodes,
we'd be introducing a bug.  What is it?

We didn't free the second node. 
It's a storage leak.

Write a single if-statement that compares the
first and second node's data to see if they are equal.  Assume there
are at least two nodes.

if (head-&gt;data ==
head-&gt;next-&gt;data)

Write a test to see if there are at least two
nodes on the list.  Be careful not to cause a seg fault if the list
has no nodes or only one node.  Check what your code will do in each
case to be sure.

if (head != NULL &amp;&amp;
head-&gt;next != NULL).  The second part alone is insufficient, since
it doesn't cover the possibility of an empty list.  If you test
head-&gt;next when head == NULL, you get a seg fault.  So, you need
both parts. You could even write if(head &amp;&amp; head-&gt;next),
since you may use pointer values directly as boolean tests: a
zero-valued NULL pointer is considered a logical false, and a
non-NULL pointer is a logical true.

Wait a minute.  Isn't the answer to Question 6
buggy since the second half of the &amp;&amp; will cause a segfault
anyway if head is NULL?

No, if head == NULL, then the first
half is false, and the protected &amp;&amp; will not even execute the
second half.




works, in external documentation like K&amp;R.  And answer the
following:


might be NULL, or might be pointing to a node we want to free.  The
natural code to write in this case is:
if
(p)



Simplify this code significantly based on your
research on free.

A careful reading of the
documentation shows that free will do nothing if you pass it a NULL
pointer.  It's not a bug to do this; just a “no-op”.  So free(p)
alone, without the test, will work fine.










	
	
	
	
	
	
In this lecture, we'll look at the variety of
different types of integer that C offers, including the different
sizes of integer, and the choice of signed vs unsigned integers. 
We'll also examine the numerical ranges of the different types.
This lecture assumes basic familiarity with base
two numbers.  If you need a refresher on that subject, consult the
review material, in particular the lecture on Data Representation.


	
	Signed vs unsigned
	integers


Integer numerical ranges, exactly for 1 and 2
bytes, approximately for 4 and 8 bytes.


As you know from prior study, the more bits we use
for an integer, the higher a binary value we can count to before
reaching the integer's limit.  C offers no fewer than four different
integer sizes, letting you trade between the memory used by an
integer variable and its numerical range.
Lines 5-8 show declarations of all four different
sizes of integer, by increasing size.  The smallest integer type is
the familiar char.
(Ignore that &ldquo;signed&rdquo; for the moment &ndash;
more on it later.)
If it seems odd to call this an integer type, recall
that char variables simply hold ASCII numbers, and that you may do
all manner of integer arithmetic on them.  C has no specialized char
type the way other languages do.  C's &ldquo;char&rdquo; is really a
synonym for &ldquo;very small int&rdquo;.
A char occupies just one byte, of course, and a
standard int typically occupies 4 bytes.  Halfway between is a ,
a two-byte int.  And, there is one more integer type that is
nominally even longer than an int, a 
So, does a long occupy 8 bytes, then?  Not
necessarily.  On almost all machines it occupies 4 bytes, and is thus
no bigger than an int.  This brings up an important point about C's
integer sizes.  A char is guaranteed to occupy 1 byte, but the only
guarantee of sizes for larger integer types is that each larger type
occupies at least as many bytes as the one before it.  So char &lt;=
short &lt;= int &lt;= long in size.  Technically they could all be
one byte long, or the latter three could all be four bytes long.  In
practice, however, it's 2 bytes for a short, and 4 for an int or a
long.  C99 offers a long
long type, by the way, that is guaranteed to be 8 bytes
long.
,
then, if it's always the same as ?
Because historically some machines had 2-byte 
while others had 4-byte ints.   
was a way of guaranteeing 4 bytes.  Those old 2-byte int machines are
rare these days, but you'll still see older code that uses either

or 
to ensure 2 or 4 bytes, and eschews all use of what was once a
size-unpredictable 
type.
All this ambivalence about integer sizes is
fortunately  one of the things that C has
passed on to other languages.  Java and C#, for instance, have 4
different integer sizes too, but they're very specific about the
number of bytes each occupies.

So, for all these tradeoffs of integer size, what
do you get in the way of numerical range?  The ranges, for each
integer size, are as follows.  Please regard these as assigned
&ldquo;vocabulary&rdquo;.  Any professional C developer knows them by
heart.
1
byte		-128		127 (covers all the ASCII codes)
2
bytes		-32768		32767
4
bytes		-2 billion	2 billion
8
bytes		-9 quintillion	9 quintillion  (covers even the national debt)


And this is probably a good time to add another
vocabulary requirement.  Any C programmer also knows the powers of 2
by heart, up to 2^16.  So, add these to your vocab list (and I'll do
them from memory here, without looking at the transcript, just to
show I'm not asking you to do anything I wouldn't :))
2, 4, 8 16, 32, 64, 128, 256,
512, 1024, 2048, 4096, 8192, 16384, 32768, 65536.
You should also know that each additional factor
of 2^10 is roughly another 10^3, since 1024 is close to 1000.  So:
2^10 is a
little over 1000
2^20 is a
little over 1,000,000
2^30 is a
little over 1,000,000,000, etc.


So, here's a little in-lecture question based on
that.  And, try to do this by first memorizing those powers of two,
and then reasoning it out mentally, without reference to the
transcript.  This is the sort of question that you might get as
&ldquo;vocabulary&rdquo; in one of our tests.  Memorizing
these powers of two and the integer size range limits will be assumed
in the LMQs and tests!

What's the square root of 4096?  Do this by
reasoning about powers of 2, and using your memorized values.  No
calculator.

, its
square root is half that power, 2
And, if you found that question hard, then
practice at this sort of reasoning with powers of 2.  C programmers,
especially any doing embedded software, OS software, compression
software, etc. all can reason like this in their head.  Here's one
more:

I have a struct type that occupies 32 bytes. 
Exactly how many of these structs can I fit into 1 Mbyte of memory? 
(Remember, 1 MByte is not 1,000,000 bytes; it's the power of 2 just
over 1,000,000.)  Again, do this in your head without reference
material, not even this transcript, and without a calculator.

32768 of them.  1M is 2^20 bytes of
memory, which you know by heart.  Divide that by 32, or 2^5, and you
are canceling out 5 powers of 2, leaving 2^15, which you know from
memorizing is 32768.


Once you get the idea, you can make questions like
this up all day long.  And you know that's what I'm gonna do for a
test, so beat me to the punch by making up some of your own until
you're comfortable with power-of-2 reasoning.

Returning to our integer declarations, let's look
at lines 10-13 of the example code.  These are again declarations of
four different integer sizes, but of unsigned form, obtained by
adding the keyword 
before each integer declaration.
Ordinary signed integers like those on lines 5-8
can represent negative and positive values.  But, a slight change in
integer format, which we'll look into in detail in an upcoming
lecture, provides an unsigned integer whose lowest possible value is
0, but whose maximum value is twice what an equivalently-sized signed
integer could contain.  So, here's yet another block of numerical
vocabulary, the numerical ranges of 
integers of various sizes:
1
byte		0	255
2
bytes		0	6553
4
bytes		0	over 4 billion
8
bytes		0	over 18 quintillion


n
unsigned,
this test is 


without reaching overflow (see next lecture segment) as we can in a
signed integer.  


keyword on line 5.  For most integer declarations, a signed integer
type is assumed unless you add ,
but oddly this is not so for 
declarations, where you may get a signed or unsigned char, depending
on the compiler.  Explictly using the 
keyword ensures a signed char.  This is the 
place you'll see that keyword in C, and it generally won't matter to
you if you only plan to put ASCII codes in the char, since those
codes only to up to 127, and thus fit in a signed or unsigned char.
In the next segment, we'll look closely at the
printfs on lines 15-19.  But for now at least note that there is a
special format specifer -- %u &ndash; for printing unsigned integers.

Do a bit of research in your favorite external C
references to answer this:


alone to declare a variable:  e.g. unsigned
myVar; ? 

Yes, you can.  It's equivalent to
unsigned int.




	
	
	
	
	
	
In this lecture, we'll continue our examination of
C's integer-type zoo, including a look at what happens when you count
too high or low.


	
	
	Scanf and printf for
	varying integer types
	Deeper look at scanf and
	printf


Memorizing the limits of the various integer types
is a good idea, but you don't want to stick those big values as naked
constants in your code.  C provides a standard header file limits.h.
Include this file, and you get defined constants for
the maxima and minima of all the integer types.  These take the form
&lt;type&gt;_MAX or
&lt;type&gt;_MIN, e.g. SHRT_MAX for the maximum short,
INT_MIN for the minimum signed int, etc.  The types are abbreviated,
and in particular the use of SHRT instead of SHORT is an irritating
example of the idiosyncratic naming conventions that prevailed in C's
day.  Evidently vowels were not trendy in the 1970's.  

And of course there is no ULONG_MIN, UINT_MIN,
USHRT_MIN, etc.


are those constants missing?  Are we supposed to memorize those
minimum values without use of a constant?

The smallest value storable in any
unsigned type of integer is simply 0.  No need to make a special
constant.


The code example has uses of the limits.h
constants scattered about it.  For instance, on line 6 we assign the
highest value for a short into ,
and on line 11, we double that and assign it into ,
to illustrate that an unsigned short can contain at least twice the
positive value tjat a signed short can.  We do the same for ints and
unsigned ints on lines 7 and 12.
s
on lines 15 and 16 print the results of our doubling experiments on
unsigned values, and illustrate that in fact the positive range of an
unsigned int is actually one more than twice that of a signed one. 
(The doubled values in 
and 
are one less than the maxima for their respective types.)  Also,
we're using the 
format specifier for unsigned values, as mentioned in the prior
segment.


on lines 18 and 19 does something interesting.  It adds 1 to the
maxima for signed and unsigned ints, and also subtracts 1 from their
minima, printing the result.  Going past the integer's range by
adding to the maximum, or subtracting from the minimum, is called
.  Technically the result
is undefined, but on almost all systems, adding 1 to a max value
results in a &ldquo;wrap around&rdquo;, back to the minimum value,
and subtracting 1 from the minimum results in a wrap around back to
the max.
To see what I mean, lmook at the output of that
printf and see that 
results in the minimum integer value, and 
results in 0 (the minimum for unsigned int).  Likewise INT_MIN-1
results in INT_MAX, and subtracting 1 from an unsigned 0 value
results in UINT_MAX.  (More on that 0U in a moment.)  It's as if the
integer number line had a wormhole jump from maximum back to minimum
and vice versa, which in fact is not far from the truth, as we'll see
in the next lecture.
The practical impact of this is that if you push
the value in an integer too high or too low, you get a sudden jump to
the opposite end of the number line.  There's no easy way to catch
this problem while a program runs; you just plan carefully to avoid
integer overflow.
And note that this applies even to intermediate
results.  The output of line 20 should, mathematically, be
1,000,000,000, which is well within the limits of an int.  But we get
a bizarre negative output because the 1000000 * 3000 intermediate
computation results in 3 billion, which overflows the integer range,
giving a large negative value, which we then divide by 3 to arrive at
a somewhat smaller negative value.  It's not enough for the final
result to be in range.  All intermediate results must be also.
But, C will help you out a bit on this.  Any
expression that works on &ldquo;small&rdquo; integers (shorts or
chars) automatically does all intermediate computations using the
full int size.  It's a rare CPU these days that does any math at all
on values less than 4 bytes long, anyhow.  So, if you write:


the multiplication will be done as an integer
operation, with 
and 
copied into temporary full sized ints.  In this example the size
promotion avoids what would be overflow if the multiplication were
only 2-byte, since 1,000,000 is past the range of a short.

INT_MAX
+ 5) &ndash; 6 on line 20, it would correctly have
printed 4294967294, which is one less than INT_MAX,
even though the intermediate value clearly overflows.  Why does this
work out OK?

It overflows to the negative side
when you add the 5, but then overflows back to the positive side when
you subtract the 6.  This is a case of two wrongs making a right. 
But it's still bad style, and qualifies as an &ldquo;unlucky&rdquo;
bug.

So, what's with the &ldquo;0U&rdquo; on line 19? 
We wanted an unsigned integer result for our experiment, but the
constant 0 is not unsigned.  Constants have types just like
variables, and unless you indicate otherwise, integer constants have
type signed int, and floating point ones have type double.  Had we
used just 0, our subtraction would have been a signed computation
(and thus simply equal to -1) instead of an overflowing unsigned
computation.  

To specify constants of other types than the
default, you add suffix letters to indicate that they are of some
type other than signed int.  A 
suffix indicates unsigned, an 
indicates long, and 
indicates unsigned long.  So the 0U in our code is an 
0, which causes the subtraction to be in unsigned mode, and thus to
cause overflow.  There are no suffixes for &ldquo;short&rdquo;,
because the automatic intermediate-computation promotion described
earlier makes such a constant moot.  Even if you could write &ldquo;42S&rdquo;,
it would get pumped up to an int as soon as you did any operations on
it anyway.


with different integer types.  
is very sensitive to integer type, and provides a different format
specifier for signed and unsigned shorts, ints, and longs.  As you
can see from the code, signed and unsigned shorts require 
and 
format specifiers, and signed and unsigned longs require 
and .
 Unsigned ints require the already-described 
specifier.  


and for
shorts deserve some explanation.  Somewhat laughably, the 'h' stands
for 'half-sized'.  (If you expected 
recall that that's already used for strings.)  This is yet another
example, along with the 
abbreviation and other C oddities, of what you get from a couple of
guys hacking out a language in 1970, which they never expected would
be used by millions of developers 40 years hence.  You never know
when you're building something that'll become an international
standard, so choose your abbreviations carefully.
Another little Kernighan&amp;Ritchie design
mistake is the absence of any format specifier for reading a char as
a numerical value
of course, but that reads one keyboard character and puts the
corresponding ASCII code into the char variable.   If you want to
enter '123' and put that into a char variable as a numerical value,
your only choice is to first read it into a larger integer, and copy
the larger int into the char.


and talk,
this seems a reasonable time to ask you to do a bit of research on
these functions.  For all it's awkward &ldquo;don't forget the
ampersand&rdquo; pickiness, 
is a remarkably powerful tool, and few C programmers understand its
abilities as well as they should.  The same goes for .
 So, look up the full set of format specifier rules for these
functions in K&amp;R or an online resource, and answer these
questions.

Write a scanf that reads lines comprising an
integer id, an intervening string of an unspecified number of dashes,
and a floating point value, e.g:
42
------ 3.1416

and the floating point value into a double named .
 And, read in the dash-string, but don't store it
in any variable since it's just garbage.  There is a way to tell
scanf to do all of these things in one call.  Look up how to do
specialized-content strings and &ldquo;assignment suppression&rdquo;
in particular.

So, we'll need three format
specifiers.  The first for the short is %hd, and the third for the
floating point is %lf (be sure you understand that %f is not OK here,
and why).  The middle one is the real challenge, though.  We need to
specify a string comprised only of dashes.  This is %[-].  And we
need to tell scanf to read it but ignore it &ndash; to &ldquo;suppress
assignment&rdquo;.  We don't even supply a variable into which to
read it.  That's %*[-], so the full scanf is scanf(&ldquo;%hd %*[-]
%lf&rdquo;, &amp;s, &amp;d);  

[Note: video error on this
scanf &ndash; transcript is correct.]

If you got most but not all of the format
specifiers for question 3, you still did well.  Now that we've seen a
little more of what 
can do, here's another problem.  I have a series of input words that
begin with non-digit sequences and end with digits, with no
intervening space, e.g. &ldquo;abc42&rdquo; or  &ldquo;d-f496&rdquo;.
 Write a scanf that reads one of these, skipping the alphabetic
string, but reading the number into an int.  Note that the lack of
space between the parts means a &ldquo;%s&rdquo; would simply read
the entire word up to the next blank, and thus won't work.

You need to read a string comprising
only non-digits, so it'll stop at the first digit, and you need to
suppress its assignment.  So, %*[^0123456789], and the full scanf is
scanf(&ldquo;%*[^0123456789]%d&rdquo;, &amp;i);



to death, let's turn our attention to .
 


Write a printf that prints an integer from
variable ,
but does so in a field width that is determined by another integer
.
 If you recall an earlier LMQ, you know this might be done by
hand-building a format string, but there's a much more direct way,
using just a single 
call with the right format specifier string.

In printf, you may use &ldquo;*&rdquo;
for field width, and supply an int parameter that gives the field
width, but is not itself printed out.  Quoting K&amp;R, p244 &ldquo;Width
or precision or both may be specified as *, in which case the value
is computed by converting the next argument..&rdquo;
So, for our case we'd use:
printf(&ldquo;%*d&rdquo;, width, val);
Width would be used to fill in the
missing field width, and val would actually be printed out.




	
	
	
	
	
	
In this lecture, we'll look at variadic functions,
a side topic that arises indirectly from our discussion of printf
formats for different integer sizes, and at integer truncation.


	Variadic functions (v) and
	parameter promotion
	


After hearing in the prior segment about all the
specialized format specifiers in ,
you'd reasonably expect the same ones to be used for ,
but.... no.  As lines 23-24 illustrate, you use 
and 
for all int sizes except longs, for which you do use 
and .
 What gives?
This is just the tip of a deeper iceberg, so let's
do another digression and talk a bit about variadic
functions.  Think for a bit about what the parameter
declarations must look like for 
 and .
 The first parameter for either is a char
* for the format string, as we discussed in an earlier
lecture.  But, what about the rest?  They change for each call,
depending on the number and types of the variables we print or scan. 

and 
are  – they permit varying
numbers and types of parameters.
How can one function header cover all those
possibilities?  How do you say in a function prototype “allow lots
of possibilities here”?  These are the full prototypes for 
and 
int
printf(char *format, ...);
int
scanf(char *format, ...);


That ... is not some shorthand on my part.  It's
literal C code, and is allowed as the final “parameter” in any
function header or prototype.  It's C's way of saying “Eh,
whatever”, and thus allowing any number and type of parameters for
the last part of the header.  So, we may pass whatever we merry well
please to 
and 
after we pass the format string.
This sounds great.  Maybe all our functions should
do this so we can pass whatever we like. But, on closer examination,
perhaps not.  For instance, how do 
and 
those unspecified parameters?  They
don't have any .  

The answer is part of a bigger discussion we'll
have later regarding the “run time stack”, but for a quick
overview, let's assume that parameters are all stored together in
memory, one after another.  So, if the format string is “%d”,

expects us to pass an int after the format string, e.g.
printf(“%d”,
i1);

would follow the pointer parameter 
in memory.

Decipher the code below, including drawing pointer
diagrams.  Explain what it does.  You may need to make a few
intelligent guesses, but when you see the answer, it should click
strongly with what we just discussed.
char
*temp;
int
value, *iPtr;


temp
= (char *)&amp;format;
temp
= temp + sizeof(format);
iPtr
= (int *)temp;
value
= *



It first gets the address of the
format pointer into temp, casting to char *, a generic pointer type
with a target size of 1.  Then it increases the address in temp by
four bytes (since sizeof(format) is 4).  Now it has the address of
whatever data is immediately after format, presumably an integer like
i1.  It copies that address into iPtr as an integer pointer, and
finally dereferences iPtr to get the integer that is presumably right
after the format parameter.


That is some nasty C code, and as you've probably
surmised, it's what 
and 
do to get the unnamed parameters that follow their format pointer
parameter.
From this you can see why the format specifiers
matter so much.  These are the only way that 
and 
know what data to expect.  There are no named, typed parameters to
tell them what's in memory after their 
parameter.  The format specifiers are all they have to go on.

In light of this, and assuming the code from
question 1 is used by 
or ,
what do the following lines do?  Explain exactly what happens.





They mindlessly follow the pointer
logic from question 1, and grab whatever four bytes follow their
format pointer.  In the case of printf, these four bytes provide an
interesting and random integer value to print.  In the case of scanf,
they form, rather more frighteningly, a random address value to
follow and into which to put an integer from the input.  If we're
lucky, it won't be divisible by 4, and we'll get a clean bus error. 
But it could be a very unlucky bug indeed.

OK, so what about this?  What subtle disaster
results from it?
short
s;
scanf(“%d”,
&amp;s);



There is at least a valid address
after format for scanf to grab, but it's the address of a 2-byte
short, while scanf will expect the address of a 4-byte int.  Scanf
will write 4 bytes at that short address, of which the first two will
go into s, and the next two will overwrite whatever follows s,
providing an interesting and probably unlucky bug.
So, in light of these questions, maybe named,
typed, parameters do have their advantages over the free-for-all
variadic approach.  But, sometimes the value of allowing any number
of parameters is worth the complexity and fragility of a variadic
function.
There is one thing C does to make variadic
functions a little less vulnerable to mixups in parameter types.  Any
“small” integer (char or short) is automatically expanded to a
full int size before being passed to a variadic function.  This
reduces the number of possible parameter types and makes a function
like 
both simpler and less buggy.  But, it interestingly means that you
cannot actually pass a char or short to printf.
It automatically gets promoted to int.  So, there is no
need for short-integer format specifiers like %hd

in printf.  Everything's a full sized int by the time 
sees it.
?
 Doesn't that require passing a char?  Nope.  Any char you pass to

gets pumped up to a full int containing the same ASCII value as the
char, and 
actually expects an int when it sees a 
format specifier.  You can pass full ints to printf to satisfy a 
specifier, as long as they contain an ASCII code.
But, two caveats.  First, this promotion doesn't
apply to longs (more of K&amp;R making it up as they go along).  So

does need the 
and 
specifiers if you pass longs or unsigned longs.  Second, this
promotion doesn't apply at all to pointers, only integer values. 
There's no reasonable way to “promote” a short pointer into an
int pointer – you'd have to somehow expand its 2-byte short target
into a 4-byte int target.  So scanf requires different specifiers for
each int type.

Earlier in this topic, we discussed the fact that
on all modern machines a long is actually the same size as an int. 
Assuming we're not concerned about our code running correctly on some
two-decade-old dinosaur, is there any harm in just using “%d” or
“%u” for a long and unsigned long, since there really is no size
difference between longs and ints?  This is more a software
engineering question than a purely technical one.

There may be several reasonable
responses, but the general answer is “No, it's not OK”. 
Following a standard, even if it's just a formality, results in
better design.  For a concrete example, note that nothing in the C
standard prevents a future 64-bit C compiler from making a long
occupy 8 bytes instead of 4.  On such a machine, printfs using %ld
and %lu would still work, but those sliding by with %d and %u for
longs would not.  This is an example of a larger phenomenon in
software engineering.  It's a common problem for a standard to start
to “drift” if some aspect of it becomes moot, like the
distinction between ints and longs is currently.  But, allowing such
drift automatically makes code broken if future implementations of
the same standard end up caring about the distinction that is
presently moot.

Finishing the example code, let's look at line 26,
which shows what happens when we assign values from a larger int into
a smaller one.  Variable 
contains a value a little in excess of 1 billion, which value we
assign into a char and a short on line 26, printing the result of the
assignments.  When you assign from  a larger int into into a smaller
one, only the bottommost bytes of the larger int are copied into the
smaller one.  If the larger int contains a small value that uses only
the bottom bytes and leaves the higher ones as all-0s, then the value
remains unchanged.  But if the value in the larger int uses the
higher bytes, the value is by
loss of those higher bytes.  As you can see from the output, 
and 
contain rather different values from .
 The value 1073750017 (in binary, 01000000 00000000 00100000
00000001) uses all four bytes of li.

retains just the bottommost 2 bytes, which have the value 00100000
00000001, or 8193.  Assignment into 
retains just the bottommost byte, which has the value 00000001, or 1.
In some languages, e.g. Java, assigning from a
larger to a smaller int requires an explicit typecast, e.g. s
= (short)li to indicate that the programmer is aware of
what s/he is doing.  C being the language it is, no such cast is
required, though a good C compiler will at least warn you.  And of
course, assigning from a smaller int into a larger one is always OK,
and results in no surprises.








	
	
	
	
	
	
In this lecture segment we'll look at how negative
values are represented in binary in a signed integer-type variable. 
If you are already familiar with “two's complement” notation, you
may find some of this review, but you may also get a new perspective
on the concept.  Many people are taught two's complement in a rather
rote way, but we'll be looking closely at the intuitive rationale for
the notation.


	
	
	Preservation of numerical
	meaning of shifts



Counting to 65535 

Before we discuss two's complement, let's first do
an overview of what it looks like to count in binary from 0 to 65535
in a 2 byte unsigned integer.  Lines 4-21 outline the pattern, with
ellipses to keep it from being 800 pages long.  Of note for our
conversation are the values 32767 and 32768, straddling the halfway
mark.  32767 is the highest value that still has a 0 for the most
significant bit (MSB), which bit has place value 32768.  

A side note on bit numbering.  The MSB has value
2least
significant bit (LSB),
not 2.  Indeed, in order to number bit positions
according to the power of 2 they represent, it's common practice to
number them right to left, from “bit 0” in the LSB position to
“bit 15” in the MSB.
And, be sure you see how the bit patterns in the
highest several values work, culminating with the all-1s pattern of
65535.  (We'll get to those negative values in a moment.)  For
instance, it should be clear that 65533, say, has a 0 bit in the 2's
place since it's 2 less than 65535.

Without using a calculator, or anything other than
your memorized powers of 2, write down the bit-pattern for 65502. 
This should be doable in under 30 seconds, and should not require
counting backward in base 2, either.  Think in terms of the
difference between 65535 and 65502, and what that means in terms of
0-bits that you should insert.

65502 has bit pattern 11111111
11011110 (with a gap between the bytes for readability).  This is
65535 with the 32's place and 1's place knocked out, to reduce its
value by 33, thus arriving at 65502.


The point here is to get you reasoning backwards
from the highest value of 65535, with the 0 bits indicating how much
you subtracted from 65535.  If that's obvious by now, great, but if
it took you more than a few seconds to do Question 1, here is another
set to practice with:

Please give bit patterns for 65519, 65518, and
65517.  


These are 16, 17, and 18 less than
65535, respectively, so 11111111 11101111, 11111111 11101110,
11111111 11101101.


And, note something about those values, which will
be important as we look at two's complement notation.  As we descend
in value, the 0-bit patterns are counting 
in binary since they show what we are 
from 65535. 

11111111 11101111  (65535 –
16 = 65519)
11111111 11101110  (65535 –
17 = 65518)
11111111 11101101  (65535 –
18 = 65517)



Now, what happens if we add 1 to 65535?  In
typical binary-counting fashion, all the 1's “flip back” to 0. 
If there were a17 bit (a “bit 16” given our
numbering system, right?) it would go to 1, and we'd have 1 00000000
00000000, or 65536.
But there is no bit 16.  So that final “carry”
at the top has no effect, and we're left with just the zeros.  This
is the way binary addition hardware works on almost every computer –
when you add 1 to the highest value, it “wraps back” to 0.
There's a familiar example of this phenomenon in
base 10 form.  Anyone who drives a car knows that the typical
odometer -- the counter that registers miles driven -- goes up to
99,999, and then flips back to 00,000.  (Those students in advanced
nations that use metric units may be more familiar with 6-digit
odometers that read in kilometers; please excuse the US bias here. 
The idea is the same either way).  So, after 100,000 miles, you get a
brand new start at 0.  Too bad the new car smell doesn't come along
with that.
Now, I'd like to suggest a different view of that
99,999 odometer figure.  I suggest that instead of a high mileage, it
actually signifies a mileage, in fact a
mileage of -1.  This seems reasonable because adding 1 to it produces
0.  And, of course, I'd suggest that 99,998 is in fact -2, since
adding 2 to it produces 0.  It's not an old car, it just has a few
miles to go before it's brand new.


For instance, what would happen if I started with,
say 100 on my odometer, and then drove 99,998 miles (which I'm
interpreting as -2 miles) ?  What would the odometer read after that,
and is that consistent with interpreting 99,998 as “-2”?

The odometer would read 98, since in
driving 99,998 miles, we'd wrap back around to 0, and make it almost
all the way back to 100, less 2 miles.  In this case the 99,998 works
just like a -2.  



This is a general pattern; you can try it out with
different examples.  99,998 can be viewed as -2 mathematically, and
any mechanical system that adds on an odometer-like meter will work,

OK, so just how far do we carry this?  Is 99,900
actually -100, then?  Is 60,000 actually -40,000?  Heck, is 1000
actually -99,000?
It's really a matter of convention, and the
standard rule in ten's complement (which is the name for this
concept) is that any value halfway up the range or higher (i.e.
50,000 or higher) is viewed as negative, and those less are viewed as
positive.

So now we have all the pieces in place to discuss
two's complement.  The concept is the same as the 10's complement
idea just discussed: repurpose the top half of the unsigned range to
serve as negative values, taking advantage of the fact that cyclic
arithmetic makes them act just like negative values.  The only
difference is that we work in base 2.  

So, looking again at lines 4-21, we see that we
can view the values from 32768 to 65535 (the analog of 50,000 to
99,999 in our odometer example) as negative.  Thus an all-1's value
is not 65535, but -1.  65534 is actually -2, and so on.  And, the
point at which we break from positive to negative, the halfway point
of the range, is where the MSB turns to 1:  32767 is still positive,
but 32768 becomes -32768.  All values with MSB 1 are considered
negative, and the MSB is sometimes called the “sign bit” for this
reason.
And, importantly, any hardware, like a CPU add
circuit, that works on unsigned values works just as well on two's
complement signed values, since the cyclic “wrap around at 0”
naturally lets us treat high positive values as though they were less
than 0.  This is why two's complement is so universal – it takes
virtually no hardware changes to implement it, just a “point of
view” change regarding the meaning of the top half of the number
range.
It's now easy to see why integer overflow works as
it does.  In an unsigned case, the overflow is from 65535 back to 0. 
But in the signed case, the jump is from 01111111 11111111, or 32767,
to 10000000 00000000 or -32768.  So overflow in the signed case
occurs halfway up the unsigned range, and jumps from the highest
positive value back to the lowest negative one.

One alternate way we might choose to represent
negative numbers is to designate the MSB as a sign bit (1 means
“negative”, 0 means “positive”), and have the rest of the
bits give the absolute value of the number.   Is this the same thing
as two's complement?  If so, explain how.  If not, give at least one
example of a number that would be represented differently under the
sign-bit-and-absolute-value scheme I just described, than under two's
complement.

They're not the same.  For instance,
in the sign-bit scheme, -1 would be 10000000 00000001, but under
two's complement it's 11111111 11111111


The formal name for the “sign-bit” concept
just discussed is 
representation, and it is actually used in parts of floating point
notation, but not in integer representation on most machines, because
the hardware to do it is more complex.

Translate the two's complement concept into a
1-byte signed char.  What bit pattern is the lowest negative number,
and what value does it represent?  What bit pattern and value are the
highest positive number?

Bit pattern 10000000, or -128, is
the lowest negative.  01111111, or 127, is the highest positive.  And
by the same reasoning, in a signed 4-byte integer, the lowest value
is -2 or -2,147,483,648, and the highest value is
2,147,483,647.

Now that we have the conceptual view of two's
complement, there's a convenient trick for converting from the bit
pattern for a positive value to the twos complement pattern for its
corresponding negative value – converting from 3 to -3, for
instance.  It's based on the earlier observation that if we look at
the 0 bits in the negative values, they represent how much was
subtracted from the all-1's value (65535 in the 16-bit case), and
thus they count upward in binary, as we go downward in value.
Look at lines 20-17 (in that order) to reinforce
this.  The 0-bits in the values from 65534 down to 65531 count from 1
up to 4 in binary as we descend, since they represent how much we're
subtracting from 65535.

This suggests that if we just flip the bits in the
negative values, changing 1's to 0's and vice versa, we'll get the
corresponding positive value.  Is that so?  Try it out on an example
or two.

No, not quite.  The bits for -2 flip
into the bits for +1, and those for -3 into the bits for +2, etc. 
And, of course, the bits for -1 flip to the bits for 0, not for +1.


So, we do need a small adjustment.  We can get the
right result by flipping the bits, and then adding
1.  Then the bits for -2 convert to those for +2, etc.  And it
works in the other direction too.  The bits for +2 flip into those
for -3, but adding 1 adjusts to the value -2.
In
two's complement, to convert from negative to positive, or vice
versa, flip all the bits and add 1.
Remarkably, this little trick is sometimes used as
the definition of two's complement, perhaps because it's easy to
state.  But it misses the entire intuitive reason for two's
complement notation, which is far more important.  Think of two's
complement as redefining half the range of values to be negative,
relying on wrapping back to 0 to make that work without special
hardware.  That's what it's really about; this
flip-the-bits-and-add-1 is just a math trick to let you do negation
in two's complement easily.

There are several ways to
represent negative values; two's complement is just by far the most
common.  We've seen sign-magnitude earlier in the segment.  Do some
external research on 
notation, and answer this question.



What is the representation for -1 in one's
complement?  (Assume 16 bits.) And, what odd thing occurs regarding
the value 0 in one's-complement?

-1 is 11111111 11111110, the result
of directly bit-flipping +1, which is how one's complement produces
negative values.  And, the odd thing about zero is that there are two
ways to represent it in one's complement: 00000000 00000000, or
11111111 11111111.  In effect one gets a +0 and an -0 value –
rather odd, which perhaps explains why you don't see one's complement
used much these days.


Second research question: Look
up how fractional values are represented with bits to the right of
the “binary point”.  (The review C lectures cover this in the
Data Representation segment.)   Reminding yourself how this works may
be useful in the LMQs



What is the binary representation of decimal 2.5? 
How about 3.75?  5.375?  And, once you've got those, extend that to
answer: what would be the binary representation under two's
complement for -1.75?

10.1,  11.11,  and 101.011,
respectively. And the -1.75 would be 11111111 11111110.01, since
adding 1.75 to that would result in 0.






	
	
	
	
	
	
	






Any integer value is represented by some binary
pattern of 1's and 0's.  But in the next few lecture segments we'll
look into C operators that manipulate the binary bits within an
integer directly.  For such operators, the content of an integer
variable is more interesting for the sake of its bit pattern, than of
its overall numerical value.  It's useful to have a way to rapidly
determine the numerical value that corresponds to some bit pattern. 
This segment covers two ways to do that: hexadecimal and octal
notation.


	Integer values important
	for their bits, not their numerical meaning
	
	Conversion to and from
	octal
	


Hexadecimal, octal, mask, arbitrary precision. 
Plus the 4-bit patterns for all 16 hex digits.


We're going to look shortly at conversions between
three different numerical bases: bases 2, 8, and 16.  But before we
do, it's useful to consider something we instinctively do with base
10 numbers that relates strongly to how we'll do those other base
conversions.
While we think that we count in base 10, in a
certain sense we actually think in To
see what I mean, try reading aloud the following number: 123,456,789.
 It's likely that what you said was “123 million, 456 thousand,
789”.  We even add commas (or periods in some nations) to separate
the digits into groups of 3.  

Importantly, you don't announce each place value
when you said the number, or even when you think about it.  No one
says (or thinks) “4 hundred-thousands, 5 ten-thousands, and 6
thousands”.   Instead, we break the number at what we might call
, such as the
thousands place, and we think of the digits to the left of each
benchmark place value relative to that place
value.  So, we see the 4 and the 5 in our sample value as being
in the 100's and 10's place, relative to 1000,
and the digits 456 collectively tell us how many thousands we
have.
If you think about it, we're actually describing
our decimal number in base 1000.   What would be the place values in
base 1000?  They'd be powers of 1000.  We'd have a 1's place, and
then a thousand's place, a million's place, etc.   These are exactly
the benchmark place values we use to break up a decimal number. 
Indeed, we have  in English, and in
most languages, for these benchmark place values (thousand, million,
billion, trillion), but not for most other place values.
What this shows is that you can convert between
certain bases by choosing benchmark place values in the smaller base,
and grouping digits around those place values, to arrive at the
larger base.  For this to work, the larger base has to be some power
of the smaller one.  1000 is 10, for instance, and we
convert from base 10 to base 1000 by grouping digits by 3's.   

As long as the larger base is some integer power
of the smaller one, the system will work.  If we chose to, we might
have grouped decimal digits by 4's, made up words for each 4 powers
of 10, and counted in base 10000.  (Indeed, one Chinese numbering
system does exactly this.). 


So, how does this apply to binary values? 
Consider the 9-bit binary value 101011110.  Let's write it with
commas grouping every three bits, just like we do for decimal values:
 101,011,110.  


What are the place values of the bits immediately
to the left of the two commas?  And, to which higher base do those
place values correspond?

64, and 8.  They're the place values
above the 1's place in a base 8 number.


So, we can view this 9-bit binary number as a
3-digit base-8 (or ) number, in a
fashion very much like what we did for base 10 and base 1000.  For
instance, bit 4 can be viewed as the 16's place, or as the 2's place,
relative to the 8's place, etc.  The diagram shows this
interpretation.
And, we can use a single digit for each grouping
(something we can't do in the base 1000 case) since the highest value
we can count with three bits is 111, or 7.  So, our sample binary
value translates to base 8 thus (using subscripts to denote base):

64's,  011

Translate this binary number into octal: 





So, why do we care?  As discussed earlier,
sometimes you want to put a particular pattern of bits into an
integer.  The numerical value is incidental, but you have to assign
some number into an int in order to get the bit pattern.  Assigning
an octal number is more convenient than assigning a decimal, because
once you get the hang of it, it's very easy to translate a desired
bit pattern into an octal value and vice versa.   

Most programming languages, including C, let you
express a constant in octal for this reason.  In C, you do so by
preceding the constant with a leading 0, as on line 4 of our sample
program, where we assign the octal value just computed in Question 2
(and its corresponding bit pattern) into .
 

We introduced octal first because of its natural
connection with the 3-digit groupings in base 10.   But octal has two
problems as a base.  First, it compresses only 3 bits into each octal
digit.  Second, integers come in sizes of 8, 16, 32, and perhaps 64
bits.  None of those sizes are divisible by 3, so the most
significant octal digit is always encoding only 1 or 2 bits –
somewhat inelegant.

What would be better, and what is more common
these days, is to use 4-bit groups, breaking the binary number up
thus:


What are the place values of the bits immediately
to the left of the commas (at least the lower ones) and what number
base do they correspond to?

Going right to left, 16, 256, 4096,
65536, etc.  These are powers of 16, and correspond to base 16 place
values.


So, we can also convert to base 16, or
, by reading each 4-bit group
as a base-16 number.  The diagram shows how we're interpreting the
bits.  Bits 4 through 7, for instance, are interpreted relative to
the 16's place, and show how many 1's, 2's, 4's, and 8's of
16's
Grouping by 4 bits crams more bits into each digit
in the larger base, and 4 divides evenly into every integer bit-size
in common use.  This is good.   What is bad, however, is that we have
to count up to 15 (the highest possible value in one place in
hexadecimal) using single symbols.  We only had to count up to 7 per
place value in octal.   

The decimal system we're used to only supplies
digits up to 9, so the universal convention is to use letters A-F for
the values 10-15.  Thus hexadecimal values are combinations of the
standard digits and these added “digits”.
So, the binary value from the diagram translates
to AC5
To convert 4-bit groups to hexadecimal, you need
to memorize all 16 4-bit patterns and their corresponding hexadecimal
digit – rather more tedious than the 8 3-bit patterns of octal,
especially since it is our instinct not to think of values higher
than 9 as single symbols.  The table in the diagram, and repeated
here, will help.  Consider these to be vocabulary:

Hex
Digits:




0
 0000   8 1000

1
 0001   9 1001

2
 0010   A 1010

3
 0011   B 1011

4
 0100   C 1100

5
 0101   D 1101

6
 0110   E 1110

7
 0111   F 1111




Translate these binary values to hexadecimal: 




3A9BEC7D and DEADBEEF.  The latter
is not just a joke; in some programs, it's deliberately copied into
memory blocks as invalid initial data, because it really stands out
in a hexadecimal dump of memory during debugging.


As with octal, C lets you write an integer
constant in hexadecimal.  You do this by preceding it with 0x (a
zero, not an oh), as we do on line 5 of the sample code, which
assigns the first value from Question 4 above into 
In modern code, prefer hexadecimal.  Octal is more
common in code from the 1970s, and you'll find it still crops up now
and then, especially in systems designed at that time, e.g. in the
representation of file permissions in Unix.

%o
%x

for printing hexadecimal (the former prints with lowercase a-f, the
latter with uppercase A-F).  These also work in scanf, if you want to
enter integers in octal or hexadecimal. 

These format specifiers are illustrated on lines 8
and 9 , and their output on lines 17 and 18, where we print 
and 
three different ways.  They're the same value each time, just in
different bases.
And, a further illustration, complete with field
widths and 0-padding, is on line 13.  (Recall from your earlier
research on printf formats what a field with with a leading zero
does).  The loop that drives that line computes a series of integer
values, each with a single 1-bit, since each value the loop assigns
into 
is a power of two.  Such 1-bit patterns are called masks.
 Masks will be useful in our upcoming discussions, and you
should know the hexadecimal and octal representations of the 1-bit
masks.  Be sure you understand the output of lines 21-36.


In what library applications might base-65536 be
used?  What does GMP stand for in the context of C?

In arbitrary precision number
libraries, of which GMP is one example.


Some computations require values of sizes larger
than C or other languages can supply.  In such cases one uses an
 numerical library that
stores large values in arrays, and provides functions to do all
common math operations on them.  One common design, for instance,
uses an array of ordinary ints to store a larger int, holding 16 bits
of the larger int per array element, so for instance a 1024-bit
integer would occupy an array of 1024/16 = 64 normal int elements. 
This is very much like the bit-grouping we've just examined, but by
16-bit groups, not 3-bit or 4-bit, so it is effectively a base-65536
system.




	
	
	
	
	
	






Now that we have bit level basics covered, this
topic covers C's  &ndash;
operators on integers that deal with the bit patterns in the
integers, rather than with their numerical values. 



	Uses for working with
	individual bits
	Bitwise operators &amp;,
	|, ^ an ~ (v)
	


It's often useful in hardware-oriented design, or
when memory efficiency is important, to work directly with the bits
within an integer.  For instance, one can use each individual bit of
an integer to represent a separate true/false value, and thus get
many booleans in one int.  Or each bit might be used for a
black/white pixel in an all black/white image.  

bit
fields &ndash; groups of bits within the larger integer, with
each bit field holding a small value in its own right.  A field of 6
bits, for instance, can hold unsigned values from 0 to 63. 
Configuring hardware tables, as in an MMU, often requires breaking an
integer into bit fields.
Compression algorithms, making use of every
possible bit of compressed storage, often take this a step further,
treating an array of of integers as a long sequence of bits to hold
compressed data, and storing compressed values in as few bits as
possible without even caring much where one integer ends and the next
begins &ndash; bridging a bit field across two ints by using
remaining bits from the first int, along with a few bits from the
next int, to store a value.  We'll have a lab and an LMQ that do this
sort of thing, in fact.

To address individual bits or groups of bits
within an integer, we use C's six bitwise operators, illustrated in
the code example.  To show how these work, the example code declares
ints 
and 
on lines 4 and 5, initializing them in hexadecimal to contain the bit
patterns shown in the comments after their declarations.
Then on line 9 we use four of the bitwise
operators in a printf, and we show the results (partially) in a table
on the right margin as well.  Don't look at the printf output until
you've done the questions below.
.
 This is distinct from the 
operator.  Rather than doing an &ldquo;and&rdquo; operation on the
entire values of 
and ,
it does an individual &ldquo;and&rdquo; on each pair of bits within 
and ,
producing an integer result from what is in effect 32 individual
bit-sized &ldquo;and&rdquo; operations.  The table shows the details.
 For each bit pair in 
and ,
the result has a 1 bit only if both the operand bits are 1s (and thus
their &ldquo;and&rdquo; would be a 1), but if either operand bit is
0, the result is 0.  


The diagram intentionally leaves off the last 12
bits of the 
result.  Fill in those last 12 bits to be sure you get the idea.


The next bitwise operator is |.  This,
predictably, does an &ldquo;or&rdquo; operation on each bitwise pair,
with the result having a 1 bit if either or both of the operand bits
is 1, and a 0 bit only if both operand bits are 0.  Again, trace the
example in the diagram to be sure you understand, and :


result.




The third bitwise operator is ^.  This does an
 on the bit pairs &ndash; producing a 1-bit only
if the two operand bits are  &ndash;
a 0 and a 1, or a 1 and a 0.  But, if the bits are 1 and 1, the
result is a 0.  Again, you can trace the result in the diagram, and..






And finally, the last bitwise operation is ~. 
This is unary; it takes only one integer operand.  The result is a
bit pattern with every bit flipped.

This one's pretty trivial, but fill in the last 12
bits just to be sure you're awake.




You can now check that the printf output reflects
the results of these four operations, in hexadecimal.  We could have
printed the results in decimal, too.  They do have a decimal
numerical value.  But, that value is usually uninteresting when we're
doing bitwise operations; it's the bit patterns we're after and
hexadecimal shows those more clearly.

There are integer-level boolean operators &amp;&amp;
and ||, corresponding to bitwise operators &amp; and |, but is there
a boolean operator for exclusive-or, to go with bitwise ^?  There is
no ^^, but there  an operator you already
know that does the same thing.

Fill in an operator in the space below, such that
the entire test will be true only if one subtest or the other is
true, but not if both are true or if both are false.


A != operator will accomplish this. 
Each subtest produces an integer 1 or 0 result reflecting its truth
or falsity, and a != comparison of those results will be true only if
one subtest is true but not the other.

One of the most common uses of bitwise operators
is to set or clear groups of bits within an integer &ndash; setting
entire parts of the integer to 1, or to 0
 Such use always involves integer
values with a group of 1 bits and 0 bits everywhere else.  Lines
11-12 give an example, using the mask 0x7F0, which has the bit
pattern:

with 7 1-bits in a group, and the rest 0-bits.  If
we &amp; integer 
with this mask:
i
= i &amp; 0x7F0;
the result bits will have to be 0 wherever the
mask has 0-bits, regardless of the bits in .
 Where the mask has 1-bits, the result will depend on i's

has a 0 bit, the result is still 0, but if 
has a 1-bit, then &amp;-ing it with a corresponding 1-bit in the mask
produces a 1.
We can think of the mask, then, as indicating
which bits to preserve, and which to set to 0, at least if we &amp;
it with another integer.

i:
i = i
| 0x7F0 ? What effect does that have?  Think it
through, and frame your answer in terms of what bits the operation
preserves in
, and what bits it changes.

The | operation will preserve the
bits in i where the mask has 0's and will set the bits to 1 where the
mask has 1's.  In this case, the mask indicates which bits to turn
on, and which to preserve unchanged.


So, with appropriate masks, we can now switch on
or off selected bits within an integer, producing a new bit-pattern,
which we can assign or print out.
But, what if I wanted to clear those 7 bits that
are 1's in the mask?  I could do so by creating another mask with 0's
in those 7 bits, and 1's elsewhere:

but writing all those F's is tedious, and there is
another choice.  I could clear those 7 bits by using my existing
mask, but first inverting it via the ~ operation:

This would have the effect of clearing those 7
bits.  It's common style to set up a mask with 1's for the &ldquo;bits
of interest&rdquo;, and then use an &ldquo;|
mask&rdquo; operation to turn those bits of interest
on, and an &ldquo;&rdquo;
operation to clear them.






	
	
	
	
	
	
This segment continues our discussion of bitwise
operators, looking at the shift operators and related concepts.


	
	


Our final two bitwise operators are “left shift”
(&lt;&lt;) and “right shift” (&gt;&gt;), which produce a result
by shifting the bits in their lefthand operand to the left, for &lt;&lt;,
or to the right, for &gt;&gt;.  The right hand operand tells how many
bits to shift.  


operation on line 15 produces a result by shifting 's
bits by 4 to the left, as shown in the table.  The top 4 bits of i
are simply lost, “shifted off the top end”, so to speak.  And on
the right end, 0-bits are added to fill in.  


So, given that, fill in the last 12 bits in the
table.

1001 0101 0000  (again, we put
0-bits in the space opened up on the right by the leftward shift)



operation produces a result by shifting 's
bits 6 to the right, filling in 0-bits on the left, and losing the
bottommost bits which are “shifted off the right end”.





Shift operations are used to move blocks of bits
around, to create dynamic masks (as we'll see in a bit) and for other
bitwise purposes.  But, unlike the &amp;, |, ^ and ~, they also have
a mathematical meaning.

What mathematical effect on an int's value results
from a left shift by 1 bit?  (Assume the int's value is relatively
small.)

It's the same as multiplying by 2. 
Each bit occupies a position twice as valuable as it did before the
shift, so the entire int value is doubled.


Now, if we end up losing 1-bits off the left end,
then the result is not so simple, so this applies only to
reasonably-sized int values.
What about right shifting?  Clearly a right shift
by 1 bit divides the value by 2 since each bit has half as much value
after the shift to the right.  (And it's a truncating division since
a 1 in the LSB gets lost.)  


It's a little more complex than that when it comes
to two's complement negative numbers.  If a right shift adds 0's onto
the left end of the integer to fill in, the result will be positive,
so right shift does not equate to division by 2 for negative numbers
unless we change the way it adds bits on the left.  The MSB must
remain 1 to keep the result negative, so instead of adding 0 bits,
the right shift adds 1 bits if the MSB is currently 1, to preserve
the negativity of the integer.  This is termed sign
extension since the right shift fills in on the left end by
“extending” the sign bit, whether it is 0 or 1.  Assembly
programmers will also recognize this as a “right arithmetic shift”.
C's right shift operator extends the sign if the
left operand is a signed integer, but always fills in with 0's if the
left operand is unsigned.  The k
&gt;&gt; 24
is negative and signed, so the right shift fills in with 1's, as you
can see by the 
result.
If you want the simple, fill-in-with-0s behavior,
work with unsigned ints.  If you want the mathematical effect of
divsion-by-2, work with signed ints.   For instance, on line 17 we
swap the two bytes of ,
by shifting it left 8 bits (filling the bottom with 0-bits and moving
the bottom byte to the top) and also right by 8 bits (filling the top
byte with 0-bits and moving the top byte to the bottom).  If we
bit-or these two subexpressions together, we'll get the two bytes in
swapped position.  You can see this in the output: 
has value 0xB5CD, but the byte-swapped output is CDB5.

What would have been the result of this operation
(give an actual hexadecimal value) had 
been a signed short?

0xFFB5.  The right shift would have
filled the top byte with 1-bits, since the original B5CD value is
negative.  These 1-bits then force a 1-bit result for the entire top
byte when the bit-or is done.

There are strict limits on the value of a shift's
right hand operand – the shift amount.  You may not shift by a
negative amount (use the opposite shift operator if you want this). 
And, you may not shift by more than the number of bits in the int,
So, you can't shift a 32-bit int by
more than 31 bits, for instance. 

This latter limit is rather irritating; there are
times when you'd like to shift by larger values, even if that means
you end up with the original bits all shifted off the end, leaving
only 0's (or 1's in the case of sign extension).
The underlying reason is that in many machine
languages, the shift amount is embedded as a bit field within the
machine language instruction for left or right shift, and for a
32-bit machine that bit field typically has just 5 bits, which is
enough to count to 31, but not 32.  Indeed, if you try to shift by 32
bits, the typical result is no shift at all, since the unsigned 5-bit
shift value in the machine instruction overflows back to 0.  The
result of the 
shift on line 15 illustrates the point.  As you can see in the
output, it prints the original, unchanged, value of .


A fixed mask is easy enough to set up with a
hexadecimal constant like we did earlier for 0x7F0, but at times we
must build a mask from user input rather than using a fixed one. 
Left shift operations are often the best way to do this.
Lines 20-21 ask the user to enter a bit number to
set, and a bit number to clear.  Line 22 then builds masks for each
specified bit number by shifting 1 by the bit number.  If 
is 6, as in our example input, then 
produces a mask with a 1-bit in the bit 6 position.

Using this idea and the earlier discussion on
clearing and setting bits using masks, figure out how the expression
on line 22 works, and why the output is as shown: a slightly changed
value of ,
with one bit set and another cleared.


with a mask having a 1-bit at position bit1, thus setting the bit at
that position.  On the result of this, it does a bit-and with an
inverted mask having 1's in all positions except position bit2, so
anding with that mask clears the bit at position bit2.

With a bit of clever subtraction, one can also
create a multibit masks via a left shift.  Consider the result of
subtracting 1 from a mask with a single 1-bit at, say bit position 7.




(1
&lt;&lt; bits)-1
1-bits at the bottom.  Lines 24-26 use this idea, asking the user to
specify a number of bits on the right end of 
to preserve, and creating a mask that has 
1-bits at the bottom.  Anding with this mask clears all but those
bottom bits.  The last output line shows the result, with just the
hexadecimal 49 at the bottom of 
remaining.

Q: Does an operation like i &lt;&lt; 8 actually
change the contents of variable i?
A: No.  We're all aware from our earliest
programming lessons that an expression like, i+8
,
but will not actually change s
content, unless we do an assignment like i
= i + 8.  But, for some reason, this is not as obvious
with expressions like 
 Many students fall into the trap of thinking that this will actually
change the contents of i.
 
computes a temporary result, comprising s
content shifted left 8 bits, but it does not change 
itself, any more than 
changes .
 An assignment into 
would be needed for 
to change, e.g. i =
i &lt;&lt; 8
i &lt;&lt;= 8.  





	
	
	
	
	
	
Neither of our prior segments in this topic
included an external research component.  We'll make up for that now,
and get fully up to speed on a central C concept &ndash; the operator
precedence table.


	



The issue of operator precedence comes up with a
vengeance in bitwise operators.  You may have noted some rather
intricate parentheses, as on line 22 of our example code.   It would
be easy to extend this lecture to cover the precedence of the bitwise
operators vis a vis the arithmetic operators, etc.  But, we've
reached a point where you should do external research on this
instead.
Every C programmer knows where to get their hands
on a C operator precedence table, and most of them have the majority
of the operator precedences memorized.  Knowing the precedence table
by heart is now official &ldquo;vocabulary&rdquo; in this course, and
is testable via questions like &ldquo;name an operator that has
precedence higher than X but lower than Y&rdquo;, or &ldquo;parenthesize
this expression redundantly, to show the order in which operations
would occur&rdquo;.  And this includes the rules for association of
same-precedence operators, which is usually left-to-right, but which
in two precedence groups is right-to-left: unary operators like &amp;,
++, etc,  and assignment operators.  We've covered them both in prior
lectures.
While we're at it, this is an excellent time for
you to do a full review of the entire C operator set.  You should now
know every operator in the precedence table, either because we've
covered them, or because they are obvious extensions on ones we've
covered (like the zoo of different shorthand assignment operators:
+=, -=, etc).
Go and look up a good web or text reference on the
C precedence table, and review 
operator in it to be sure you know what they do.  Research those
you're not certain of, and be ready to field the in-lecture questions
below from memory, without needing to consult the
precedence table.  You'll
be expected to have the precedences memorized for LMQs and tests.
And, to help speed you on your way and make a
point about how critical this stuff is, I'll tell you that in the
standard K&amp;R text, you'll find the operator precedence table on p
53.  And, get this, in the old version of that text, which was
replaced in the late 1980s when the ANSI C standard came out, and
which I have not personally used in nearly a quarter of a century...

Now, I don't love K&amp;R so much that I memorize
all its page numbers.  Those are the only ones I know, and obviously
I consulted &ldquo;page 49&rdquo; so many times in the 1980s that I
still remember it today.  Copies of those pages may be found pinned
up on cubicle walls in dev shops all over the world.  At one point,
there was even a geek tshirt you could get that had the C precedence
table on it &ndash; printed , so
that you could look down and consult your own shirt when you needed
to check an operator precedence.

So, with your possibly lengthy research all done,
how would this expression be evaluated?  Add parentheses to show the
order of evaluation implied by the precedence rules: 

x
&lt;&lt; i + 1 | j &amp; k

y = ((x &lt;&lt; (i + 1)) | (j &amp;
k))  All bitwise operators have lower precedence than all arithmetic
operators.  Shifts are just underneath the arithmetic operators,
perhaps because they have some arithmetic meaning.  Lower down are &amp;
and |, and the &amp; has higher precedence than the |, just like &amp;&amp;
has higher precedence than ||.  And, importantly, the entire right
hand side of the expression is grouped because the assignment
operator (and it IS an operator) has almost the lowest precedence in
the table, and is therefore done last.


This next question has to do with the () operator.
 This is  the standard grouping
parentheses &ndash; those don't count as operators.  If that's a
surprise, if you thought the () in the precedence tables indicated
grouping parentheses, then go back and complete your research on the
four operators in the top precedence group of the precedence table:
() [] -&gt;, and '.' .  They're among the most important, but are
also among the oddest ones to view as &ldquo;operators&rdquo;.

How may operators are there in this expression,
and in what order are they done?  (Don't parenthesize this one.)  



There are three operators.  First to
be done is the -&gt; dereference operator.  The next is the [5]
operator, since array-indexing is an operation along with -&gt; in
the topmost precedence group, and since association is left-to-right
in that group.  Finally there's the function-call () operator. 
Calling a function is an operation.  We'll shortly see cases where we
do function calls on things other than standard functions.



Despite having programmed in C for 30 years, I
still had a bug when writing line 22 of our example code, which I
originally wrote as 


printf(&quot;%08X\n\n&quot;,
i | 1 &lt;&lt; bit1 &amp; ~(1 &lt;&lt; bit2))

When


had values 6 and 8, respectively, this set the bit at position 
but didn't clear the bit at position 
That baffled me for a minute or two before I saw that I
needed parentheses around the | operation as they are in the example
code.




Explain exactly the order of operations that would occur
in my buggy version of the expression, and why the result would be as
I described.  Specifically, what is the result of the &amp;
operation?




The expression would create the two
masks first, since shifts have higher precedence, as does ~.  It
would then bit-and the masks, because &amp; has higher precedence
than |.  Only the 1-bit at position bit1 would survive that bit-and,
since that's the only position where both masks would have a 1-bit. 
The resultant mask with a single 1-bit would be bit-ored with i,
setting the bit at position bit1, but not clearing the one at
position bit2.



i,
j, 
have values 1, 2, and 3, respectively, then the following assigns 2
into Why?
 

val
= i +  j&lt;k
? j : k

Addition has highest precedence than
?:, so the implied order of operations is thus:
k
? j : k
equal
to k, so the value of the conditional expression is that of j,
or 2.




double
j;
if
(j=sqrt(9.0) &lt; 4.0)
printf(&ldquo;%f&rdquo;,
j);



Because assignment has lower
precedence than &lt;, the comparison is done first, returning a
&ldquo;true&rdquo; value of 1 since the square root of 9.0 is less
than 4.0.  The result of the comparison is then assigned into j as
1.0, and becomes the if-test, thus &ldquo;true&rdquo;.  But j ends up
containing 1.0, not 3.0 as might have been expected.

At this point, you might be inclined to throw in
the towel and parenthesize everything just to be sure.  Don't do
this.  First, it's a violation of the course style sheet.  Second,
the code complexity metric penalizes you for each pair of
parentheses.  Third, over-parenthesizing your code is like adding a
comment saying &ldquo;I never really could figure out precedence.&rdquo;
The very reason for the precedence table is to
avoid parentheses.  If we're going to parenthesize everything anyway,
there's no need for precedence at all.  Invest in knowing the
precedence table, and use your investment to simplify your code.  If
you want heavily parenthesized code, write in Lisp.
Now, to be fair, it's common
industrial practice to add a few redundant parentheses on
uncommon operators for which a reader
may have forgotten the precedence.  Some developers would take me to
task for the above two paragraphs, and argue that moderate
us of
redundant parentheses can clarify code. 
This sort of judgment call is what makes code
and
this other point of view is reasonable.  If you work in a team that
adds extra parentheses now and then for clarity, follow that rule. 
But in this class, especially since we want to motivate an
understanding of the precedence table, the rule is no

parentheses.










	
	
	
	
	
	
This topic covers an interesting oddity in
hardware design that often shows up when you work with integers at
the bit level, and which offers interesting lessons in historical
standards, and in C portability.


	Litle Endian/Big Endian
	(v)
	


,
diagrammed with its initial contents in 4 bytes (2 hexadecimal digits
per byte).  Line 6 sets up a char pointer 
to the beginning of ,
and the loop on lines 8-9 iterates through each byte of ,
advancing 
one byte at a time, and printing each byte's number and contents.
We'd expect values 12, 34, 56, and 78, in that
order, but the output on line 20 shows just the opposite, with the
byte contents appearing in the backward order, despite the fact that
we're advancing 
one byte at a time through the integer.   What's going on here?
The problem is not in the code; it's in our
diagram of .
The real picture of 
is as shown next to the output.  The bytes are not ordered in memory
from most to least signficant, from left to right as we'd expect
them, but rather from least to most significant, in backward order.
This is “little endian” order, because the
little end of the integer appears first in memory, and it's the way
the bytes of a multibyte integer are stored on a number of important
computers.  On other computers, though, the bytes appear in “big
endian” order, as the initial diagram of 
shows.  The order depends on the CPU architecture, and indeed one
could say that almost all CPUs use big endian order, except for one
particular CPU family.  That particular family, however, is the Intel
architecture, so little endian machines are probably more common than
big endian machines.
Does this issue have any effect on the various
integer operations, arithmetic, bitwise, logical, etc?  No, none that
you can perceive.  Once a multibyte integer is loaded into the CPU
for operations, it's effectively held in big endian order on any
architecture, and the order in which it was held in memory has no
bearing.  The big/little endian issue only affects the order of the
bytes in memory, and only shows up when you address bytes one at a
time, as we do in our loop, or when you store the binary memory
contents of an integer directly into a file or transmit them over a
network.

So, what possessed Intel to stick us with this odd
memory-storage order?  There's an interesting historical reason for
it, and a lesson to be learned about standards.  

Intel was the first company to develop a widely
successful microprocessor – an entire CPU on one chip: the Intel
8080.  And in the early 70's when they did it, you still couldn't put
more than a few thousand transistors on a chip, so every transistor
counted. 

If you think about the way you add two multibyte
integers, if you have to do it one byte at a time as that early
microprocessor did, you start with the least significant bytes (just
like you start with the least significant digits when adding two
decimal numbers).  You proceed from least to most significant byte,
adding byte pairs, possibly with a carry from the addition of the
prior pair.  (The need to determine “carry”s is the reason you
need to go from least to most significant.)
So, to add two big endian integers, you actually
have to start from their last bytes, in memory order, and work
backward through memory, while the byte order of little endian
integers lets you naturally advance forward through memory as you go
from least to most significant byte.  Moving foward requires a bit
less CPU circuitry, and has only the disadvantage of being odd from a
human point of view.  So of course early CPUs used little endian
order.
But, once you have a microprocessor that's one of
the most wildly successful products of the century, each new version
you build has to be backward compatible with the older versions,
since there are already millions or billions of lines of machine
language running on older versions.  So, through the entire evolution
of their processor line, up to the present day, Intel processors are
little endian.
This is a strong example of the persistence of a
standard that has long outlived its usefulness.  As I've said before,
be careful what you set as a standard; you never know if people will
be living with it (or suffering from it) decades later.
And, while we're doing historical asides, here's a
literary aside for you.

Where do the names little endian and big endian
come from in classic literature?  (You don't really have to answer,
but I'll be impressed if you do.)

They come from Swift's Gulliver's
Travels, where there is war between the Little Endians, who eat their
softboiled eggs by breaking the small end of the egg open, and the
Big Endians, who eat theirs by breaking the large end open.  It's a
metaphor for the foolish things people fight over.

So, what impact does this have on your code? 
Endianness shows up in two main contexts:
First, if you record or transmit, in raw byte
form, the contents of a multibyte integer between two machines with
different endianness, you must reorder the bytes.  This can happen in
binary internet transmissions, or when storing data in a file in
binary form, and then reading the file on a different machine.  In
these cases, it is common convention for the little endian machine to
reorder the bytes to big endian order before transmitting or storing
them.
Second, the endianness issue may cause “unlucky”
bugs.  A good illustration appears on lines 11-14 of our example
code.  We ask the user to enter a value for ,
a short.  But, note that we read the short using a %d specifier. 
Recall from earlier lecture in this module that this causes 
to fill 4 bytes in memory where there are only 2 available.
The result shows in the output on lines 21-22. 
The user enters 42, at which time 
has its original value.  Immediately after the ,
however, we print 
and ,
and find that while 
contains the expected 42, the  two bytes
of 
have been wiped out to zero.


contain the right value?  Didn't the 42 go into the two bytes after
,
since the 
expected a 4-byte integer?  Would the same outcome have occured on a
big endian machine?  If not, what value would you expect in 
on a big endian machine?

The 42 went into the first byte in
s, because the machine is little endian, and the least significant
byte goes first.  So, s contains exactly what it would have with a
%hd specifier.  The two bytes after s will hold the most significant
bytes of the “4 byte integer” that scanf assumes is there because
of the %d.  For the value 42, these bytes are all-0s.  On a
big-endian machine, those most significant bytes would go into s, and
we'd expect s to contain 0, and the 42 would be in the overrun bytes
after s.


porting
bug – one that only shows up when you move to a new machine. 
You might get by with this bug on a little endian machine as long as
those extra zeros didn't trash anything important, but when you move
it to a big endian machine, the code breaks.  You're inclined to
complain about the unreliability of the big endian machine (“But it
works on my home computer!”) but of course the bug is in your code.
 It was just hidden.  

(not if) you
encounter a porting bug, resist the temptation to think it's unfair,
or specific to the machine you ported to.  It's irritating to have a
bug show up in code you thought was working.  Nonetheless, debug it
like any other C bug; it will always be some standard error in your
code that was just hidden by the first machine you tested on.

So, it looks like those extra zeros wiped out the
last two bytes of .
 How could that be?  If 
is right after ,
wouldn't they have wiped out the first two bytes of ?


They DID wipe out the first two
bytes (in memory order) of i.  i is in little endian order, and the
78 and 56 bytes are first in memory.






	
	
	
	
	
	
In this segment we'll look more closely at how

manages dynamically allocated blocks, and we'll examine what happens
when you mess up the runtime heap.


	How to trash the runtime
	heap
	Headers for allocated
	blocks


Our sample code allocates two blocks of ints: one
with 5 ints and one with 10.   Using calloc ensures they initially
contain all zeros.
Let's start by printing the starting addresses of
the blocks, on line 13.  There are two sample runs shown at the
bottom, with different compilers, and right away there's something
interesting: the locations are different in the two runs.  Each
compiler comes with its own implementation of the allocation library
functions, so the exact organization of the runtime heap varies per
compiler.  From the programmer's perspective there's no difference
unless you examine the actual addresses, but this drives home the
point that a bug that might accidentally work under one compiler may
fail on another.


How big do you expect the first block (of 5 ints)
to be?  Do the addresses in pointers 
and 
differ by that much?

Assuming 4 bytes per int, a 5 int
block needs 20 bytes.  But, interestingly, the pointers differ by 24
bytes, suggesting there's some extra space in there.


So, what's the extra space?  It's a 4-byte value
that hangs out just before the start of the second block.  There's
another one like it just before the start of the first block, too. 
See the diagram.

– a few bytes that go before the address that you think of as the
start of the block.  When 
allocates a block, it boosts the requested size by 4 bytes, puts
header information at the start of the block, and hands you a pointer
to the byte just after the header, in effect lying to you about where
the block starts.  You don't realize there's extra data being carried
around before the start of your block.  But, why does malloc do this?
 


or to
. 
s
job is to mark all the space in the block as reusable, but how does
it know how much space there is, given only the block's starting
address?  We never passed any information as to the block's size.
 
knows the block's size because it's stored in the header.  
and 
are in cahoots; 
puts the block size into the header, and 
retrieves it.  Specifically, 
reduces the address you gave it by 4 bytes, to the start of the
header, reads the block size, and frees that many bytes.

So, what's going on on line 14?  What does
indexing by -1 accomplish?  (Recall the earlier lecture on pointer
indexing, and of course consult the output on line 32.)

It returns the 4-byte headers,
printing them as integers.  Indexing by -1 backs up by one target's
worth, (4 bytes for an int target), and dereferences.


Apparently the headers contain 25 and 49,
respectively.  That's about right, but still needs some explanation. 

malloc

always allocate block sizes in multiples of 8 bytes, at least on the
64-bit architecture the examples ran on.  This ensures that the
block, and data after it, fall on divisible-by-8 boundaries to avoid
bus errors.  And the block sizes include the
headers. 
(4 byte header and 20 bytes of ints), but a rounded-up 48 bytes for

rather than just 44
 A divisible-by-8 size also means that the bottom 3 bits of the size
value will always be 0s.  (Review a bit of binary math from prior
lectures to see this.)  So, never one to waste even a few bits,

and 
use those bottom 3 bits to set true/false flags about the block.  I'm
honestly not sure what setting the LSB (least significant bit) to 1
signifies to the Watcom C allocation routines, but it must mean
something because the size values of 24 and 48 that we'd expect have
been bumped to 25 and 49 by setting that bottommost 1's bit.  

So, do you need to know all this detail?  No, but
it is important to understand that the runtime heap is full of very
delicately designed header information, that the blocks you allocate
are near one another, interspersed with that information, and that
anything you do to mess it up will cause a catastrophe (if you're
lucky!)

So, let's cause a catastrophe.  Look at lines
16-17

What's wrong with those two lines, and what are
they going to mess up?

The loop limit should have been
DIM1, for blk1.  The loop will march right off the end of the first
block.  Note that's an easy kind of mistake to make.


's
header, and then its contents.  The output shows the result.

What happened to the 49 in the header?  And I
thought 
set blocks to 0's.  Why does the second block have nonzero content?

Should be pretty obvious.  That's
the data from the line 16-17 loop.  It overwrote data in the second
block, and even worse 


OK, so now let's free
the second block on line 24.  The result is the blowup on output
lines 34-37, or if you want to see it under the gcc compiler, line
43.  (Don't worry about what happened to the line 23 printf; we'll
discuss it shortly.)
Your first
reaction to such a bug might be “Why can't these compiler writers
get their allocation libraries debugged properly?  Why is 
blowing up?”, but the libraries get used so heavily that all the
bugs have long since been washed out of them.  If ,

or 
blow up when you call them, it's because you've corrupted the runtime
heap.  This is a really hard bug to find, involving lots of poring
over code, sometimes thousands of lines of it.  Best to be careful in
the first place.
So, before we discuss that missing printf output
from line 23, a few more questions to think about regarding runtime
heap blocks and headers:

Say I have a large array declared as a local
variable:
int
myArray[1000];
and I'd like to “contribute” it to the runtime
heap by freeing it:

Will this work?  Can I dump an extra 1000 bytes in
the runtime heap this way, and have a bit more memory to allocate
later on?  Be specific – what's likely to happen, and why?

The 4 bytes before the start of your
array, whatever they may contain, will be used by free as the header.
 So, free looks at that garbage data and says “Wow – 1487638
bytes!  That's a nice big block”, frees that space, wiping out god
knows what, and corrupting memory and the runtime heap.  You might
not even find out about it until you do another malloc or free much
later.



The classic Kernighan and Ritchie text famously
mentions specifically this bug.  With what dramatic adjective do they
describe it, and on what page?  (Look it up in your text, and find
where the text discusses freeing and allocation in general (the real
intent of this question)

They famously term it a “ghastly
error” on p. 167, near the bottom.  It's a well-known quote.among C
programmers.

So, the printf on line 23 never showed in the
output.  Why not? 

It did run.  But, writing output to a screen or
file is time consuming, so printf 
its output – stores it in a memory block held in the standard I/O
library – until the line of output is complete.  In our example,
the line 23 printf starts, but does not finish, an output line.  Line
25 finishes up the output line, and then the buffer from the line 23
printf, along with line 25's output, goes to the screen.
Normally you don't even notice this; it happens
too fast.  And, printf's buffer is always 
– sent to the screen – before a scanf, so that any prompts that
you print will show up even if they don't end the line.  The only
time you really notice the buffering is in cases like ours, where the
program blows up between the first and second printfs.  Printf's
buffer is part of the program's memory (it's often a dynamically
allocated block, in fact), so it vanishes with the rest of the
program when the program blows up, and thus the first printf's output
never makes it to the screen.
 like
the bug happened before line 23, and can be very misleading.  So, the
lesson is: when you do a debugging printf, add a \n at the end. 
Don't write:
printf(“Got
to this point, dammit”);

printf(“Got
to this point, dammit\n”);





	
	
	
	
	
	
In this lecture we'll look at pointers that point
to other pointers or . 
This is the next step in our progressive broadening of the types of
targets that pointers can point to.


	
	


Take a look at line 12 of the sample code.  The
first two variables, 
and set
up a standard int and a pointer to it, as shown in the diagram. 
We've even included the address of ,
85124, shown next to ,
and as the content of pointer .
 

,
is something new.   So far we've seen pointers to most of the basic
types, and pointers to structs.  But we may also have pointers to
more sophisticated targets, including other
pointers.  Putting two *'s before a variable's name in the
declaration makes it a pointer to another pointer,
. 

To see how this works, first note that pointers
have addresses like any other variable.  We haven't emphasized this
up to now, because the additional addresses might be confusing.  But
pointers do reside at some memory address, like any other variable. 
A double pointer contains the address of some other pointer, so in
our diagram we show an address for ,
and on line 15 we assign that address into pp.

becoming 's
target.  Trace the line 17 printf's output on line 
to see that 
contains the address of ,
and 
contains the address of 
We've seen before that pointers are very
particular as to the type of their target, since the target type
determines what we get when dereferencing the pointer, and how many
bytes we offset when adding to the pointer.  Double pointers are no
exception to this principle.  A given double pointer points only to
one particular type of single pointer.  
cannot point to a pointer to a float or a char, nor to another double
pointer of any type.  It points exclusively to a single pointer to an
int, like .
 So, if we dereference ,
we know the result is an int pointer.

once -- 
&ndash; results in ,
as the first part of the line 17 printf (whose output is on line 30)
shows.  But, we can immediately dereference this result again,
following 
to . 
The second part of that line 30 printf shows the result of
double-dereferencing .
 This &ldquo;double dereference&rdquo; is characteristic of double
pointers &ndash; it's what you have to do to follow the double
pointer all the way to the final target.  As we'll see in a later
lecture, this is why you use a double asterisk to declare a double
pointer.  In a sense, you're illustrating how you might use the
pointer, in its declaration.
So, in for a penny in for a pound &ndash; if we
can have double pointers that point to single pointers, can we have
triple pointers that point to double pointers?  Sure, as the
declaration of 
on line 12, and its assignment and use on lines 19-20, illustrate. 
Variable 
is at address 85132, and 

can hold the address of ,
as we show on line 19, and the subsequent printf on line 20.  And of
course, as with the other pointer types we've discussed, 
may only point to a double pointer to int, not to a single pointer,
another triple pointer, nor to a pointer to any type but int.  


thus produces a predictable type, as you can see in the line 20
printf
one asterisk to reach a double pointer ,
a second to reach a single pointer 
and a third to reach the int .
 


,
and initialize it to point to .


Predictably, this is done thus: 


Once you get the idea, you can use
any level of pointer indirection, though triple pointers are rare,
and in 40 years of coding I've had only one chance to use a
&ldquo;quadruple pointer&rdquo;, such as pppp.

So, aside from mind-bending levels of indirection,
why use double pointers or any other type of multi-level pointer? 
There are a number of practical uses for such pointers, including the
setup of dynamic multidimensional arrays, which we'll look at in a
later lecture (and which was the context in which I had need of that
quadruple pointer once).  But, a more immediate example is passing
pointers to a function , where
you seek to pass a pointer to a function in such a way that the
function may modify the original pointer in the caller.

and the call of it on line 22.  The hope is that this call will set 
to NULL, but as the line 23 printf illustrates, this doesn't happen. 


We've seen before that the way to modify a
variable in the main, from a function, is to pass a pointer, which
clearly we do for .
 So, why doesn't 
get set to NULL?  Answer by diagramming exactly what really does
happen, and in particular, if the assignment on line 4 doesn't set 
to null, what 

The problem is that toNull is a copy
of p, so both toNull and p will point to i.  The line 4 assignment
sets this copy to NULL.  This has no effect on p unless you believe
in sympathetic magic.  If we were trying to modify i from
BadMakeNull, then we could do so via *toNull.  We did get the address
of i passed.  But we did not get the address of p passed to
BadMakeNull, and thus cannot modify p from within the function.


If
you want a function to modify some actual variable, you must pass the
address of the actual variable to the function, which must have a
formal parameter to match,
we must pass , not p itself.
 But, this also means that the formal parameter must be a double
pointer, since it will contain the address of a single pointer.
GoodMakeNull,
and its call on line 24, is thus the right model and
works correctly, as the printf on line 25 illustrates.  In

will point directly to ,
and the code on line 8 deferences the double pointer 
to reach back to 
and set it to NULL.  


toNull
= NULL, would that also work?  Would it compile?  What
would it do?

Really a repeat of what we already
said earlier.  toNull = NULL would compile, but would only set the
formal parameter to NULL, so it no longer pointed to p.




passed on line 24.  Could that have been just p?


This would be a compile error: you'd
be passing a pointer to an int to a double pointer to an int; they're
not compatible types.

Look up &ldquo;double pointer&rdquo; online, and
peruse a few of the hits you get.

Did you find any language outside of the C family
(C, C++, Objective-C) for which double pointers were a relevant
concept?  How widespread does confusion on these pointers seem to be?

Your research may vary, but you're
unlikely to have found any reference to double pointers outside of
the context of C-family languages; they don't exist in Java, C#, etc.
 And, you probably found lots of baffled questions about them. 



A final note: comprehension of double pointers is
often used as a test of clear comprehension of pointers in job
interviews in shops using C-family languages.  This shows two things:
investing in getting this straight will help in some job interviews,
and evidently it's a pretty important concept, at least for software
built in C-family languages.






	
	
	
	
	
	
In this short lecture segment we'll apply the
concept of double pointers to revise the linked list code from
earlier discussions.  Go back and look at that prior code and review
it since this lecture is based on it.


	Linked lists using double
	pointers


In that earlier code that you just reviewed, we
returned a new head pointer from functions like 
that modified the list, because that was the only way to pass a
changed head pointer back to the caller.
This required assignment of the function's result
back into 
in the caller, however, which is a bit awkward.  Our example code
shows an alternative.  In every case where 
might be altered, we pass its address as a double pointer to ,
and we can modify 
from the function, via that double pointer when needed.   The diagram
next to 
(whose code we'll be writing later) illustrates the idea.  


function on lines 9-15, where we've put a diagram showing the
situation on the call of Add(40,
&amp;head).   There are already 2 nodes on the list
from earlier calls, and pHead
.
 The code uses 
everywhere it needs to access or modify 
in the main.  

Tracing the code fully, we see that line 10
creates the new node, line 12 fills in its data, and then line 13
copies the content of ,
aka 
from the main, into the node's 
pointer, and finally line points ,
(again, via ),
to the new node.

function also uses 
 But, it has an error.  Look it over carefully; it uses a standard
loop-traversal to find node to delete, with a 
pointer that is supposed to follow the 
pointer, and thus always point to the node before .
 


Under what circumstance might line 27 result in a
segmentation fault?  How would you fix this?

If the first node in the list
matches value, then prior will be NULL.  The fix is to add a test for
this, and modify *pHead instead:










,
right?  Nope.  There's still an important, one-line, step missing. 
What needs to be added?

We need to free the just-removed
node.  So, we need:









,
but 
is completely unwritten.  This is supposed to free all the nodes on
the list, leaving the 
pointer set to NULL. 


.


Several implementations are
possible, but the simplest is:
while
(*pHead) {
   temp =
*pHead;
   *pHead
= temp-&gt;next;
  
free(temp)



If you got something different, at least be sure
you understand the proposed answer code, and ..

*pHead
= temp-&gt;next,
replacing 
with an appropriate use of ?
  


We'd need *pHead = (*pHead)-&gt;next.
 The parentheses are needed because * has lower precedence than -&gt;.




Finally, what would happen if the loop test was
just ?
 How would the code behave?

The loop would never end, because
pHead always points to head in the caller, and nothing in the code
changes pHead itself, nor should it.  This is another instance of
keeping careful track of the difference between a pointer and its
target.








	
	
	
	
	
	
In this topic we'll look at how to pass
commandline arguments to a C program, and along the way we'll deal
with arrays of pointers.


	
	


When you run a compiled C program from the
commandline, you may include commandline
arguments: additional strings after the program name to
indicate options, filenames, etc.  So far, none of our C programs
have used such arguments, but most of the Unix commands you run are
actually compiled C programs, and they take various commandline
arguments, e.g. “ls -l”, “vi filename.c”.

There are various ways to attach these additional
strings of information to a command, depending on the context and OS.
 If you're using a Unix commandline interface, it's just a matter of
typing the additional arguments.  But, even if you're using an IDE
for C development, you'll find that it offers some way of setting
commandline arguments to be provided to your program when you run it.
 And, even in a modern GUI interface, programs use commandline
arguments behind the scenes to get options and additional information
needed as the program starts, so GUIs generally provide a way to
attach commandline arguments to the program that is run when you
click an icon.  

In our example, we'll just assume Unix commandline
execution and add arguments directly to the command line.  For
instance, as the sample run shows, assuming our executable is named
,
we can pass the commandline arguments 
and 
to our program by the command:
prog
-ab cd

Any commandline arguments passed to a C program
show up as parameters to .
 Thus far, we've written 
as though it were a parameterless function, and in fact a C program
may ignore any commandline parameters by simply omitting the
declaration of the parameters in 
But, whether we declare them or ignore them, 
is always passed two parameters that have to do with commandline
arguments, and which are by tradition named 
and ,
as you can see on line 19 of our sample code.

parameter is simple – it's an int indicating how many commandline
arguments there are.  Well, it's mostly simple.  The only complexity
is that the name of the program executable itself, 
in our example, counts as the first commandline argument, so you
always get at least one commandline argument, and 
is never less than 1.  In the line 32 sample run, there are thus 3
commandline arguments, and 
would be 3.

parameter, a double pointer, is rather more complex, and leads to 
the commandline arguments, in the form of a block of character
pointers, the first element of which is pointed to by .

This is the first example we've had of an array or
memory block of pointers.   C allows arrays or memory blocks of
almost any type, including pointer types.  Every element of the block
pointed to by    
is a character pointer, pointing to some string.  (The vertical
orientation is just for clarity; we could have drawn it horizontally,
too.)  Each commandline argument appears as a NUL-terminated string,
pointed to by one of the elements of the block, 


points to the first element of the block.  Just as a pointer to the
first element of an array of ints must be a pointer to int, so a
pointer to the first element of an array of char pointers must be a
pointer to a char pointer.
 

,
just as we did with simpler blocks in the earlier lectures on
pointers, arrays and dynamic block allocation.  Indexing 
results in offsetting from 
and doing a  dereference, thus
arriving at one of the char pointers in the block.  ,
for instance, is a char pointer, the second one in the block.  It's
neither a double pointer (since we did one dereference by virtue of
the []) nor a char (since we did only one dereference, not two).  As
you work with double and higher-order pointers, it's important to
keep careful track of what level of pointer you are at as you
dereference or index.   We'll do that in this discussion.
A couple of other details about that block of
pointers:  First, it is not dynamically allocated on the runtime
heap, but is instead created automatically in another area of memory
as part of the program startup.  So, you don't need to free it, and
in fact doing so would be a serious error.  Second, as you can see in
the diagram, it includes one extra NULL element (the fourth element
in our example).  This is sometimes convenient as an end marker when
you iterate through the block.

on lines 22-23 prints the three commandline arguments, with the first
being the command name itself, as promised.  The %s format specifier
is correct because we are passing char pointers to printf.  Per
usual, printf doesn't care where we get our pointers, as long as they
point to NUL-terminated char sequences.

function also prints all the commandline arguments, but more
flexibly, without assuming there are just 3 of them, and using pure
pointer notation rather than indexing.  It starts by printing the
argument count and the first argument.  Be sure you see why 
is the first argument.  It's a synonym for ,
of course.  And since it has only one asterisk, it's a char pointer,
not a char.

times, printing the rest of the arguments.

No, it doesn't.  What's incorrect in that
sentence?

It iterates argc-1 times, since
that's a predecrement operation in the test.



down the array of pointers, incrementing it to point to each element
in turn, and dereferencing it  to arrive
at the char pointer.  Since it uses a preincrement, the printf prints
the second, third, etc. arguments, skipping the first.  On the first
iteration of that while loop, parameter 
advances to the second pointer in the block, and is dereferenced to
get the second char pointer, which is passed to printf.  On the
second iteration, 
advances to the third pointer in the block, and we print the “cd”
argument.
,
look at the second 
call on line 25, where we pass the array 
which is declared and initialized on line 20.  This is an array of
char pointers, to show how you might declare such an array directly. 
Note the *arrayName[dim] syntax, suggesting that we would index the
array, and then dereference the result of the index, which is exactly
what we would do for an array of pointers.  This is the syntax you
must use to declare an array of pointers.

So, just a quick reality-check here.  How do I get
away with using quoted strings to initialize 
 Wouldn't I have to have addresses to initialize its elements?  Where
will the elements of 
point if I initialize it this way?

Yes, you need char addresses or char
pointers to initialize the array, which is exactly what string
constants ARE, so using quoted strings to initialize arrOfPtr is
fine: all its elements will point into the string table.



Another quick reality-check.  What type is

by itself, without any index?

It's a double pointer to char, or to be very
exact, the address of a char pointer, the first char pointer in the
array.  It's thus a double pointer constant.  In any event, it's
usable as the value to pass to a double pointer.

works on our pointer array too.




	
	
	
	
	
	
	






In this segment we'll continue examining
commandline arguments, and complex double-pointer arrangements, by
drilling down into the 
code with a series of in-lecture questions.


	
	Complex pointer and
	incrementation combinations.


Many Unix commands accept commandline arguments
that begin with a dash followed by letters indicating various
commandline options.  For instance ls
-al runs the ls command with the 'l' (long listing) and
'a' (show hidden dot-files) options. 

,
which does more sophisticated double-pointer dereferencing and
incrementing.  
mimics the design of code that is common to many Unix command
programs written in C (e.g. ls, cp, vi).  These programs traverse
their commandline arguments looking for arguments beginning with '-'.
 They then collect all the option-letters following the '-' and use
them as flags to turn on and off program execution options.  Our

just prints the letters that follow '-' in commandline arguments, but
it still has to examine each argument string for an initial '-' and
then walk through all the letters that follow the '-'.  And it uses
some rather intricate combinations of ++ and *, which are typical of
commandline processing, and a good exercise in tracking levels of
indirection.

with 
in its initial state as in the diagram, and walk through some
in-lecture questions.

down the array of pointers.  And one might expect that the NULL
comparison has something to do with that anchor NULL value mentioned
in the prior lecture segment and shown in the diagram.   We'll look
at the ++ operator in the next question, but first an easy warmup
question.  



is a pointer already, so why don't we just directly compare it to
NULL?  And if we do dereference it, why not twice, since it's a
double pointer?

Levels of indirection...  The NULL
is the last of the single char pointers in the array of pointers.  We
want to stop the loop if argv is pointing to that final single char
pointer, and a single dereference gets us to the single pointer that
argv points to.  Omitting the dereference would ask if argv itself
were NULL, which isn't going to happen, and a double dereference
would ask if the char at the start of the argument string were NULL,
which doesn't make sense since the char is not a pointer.  If this is
by now boringly obvious, *good*.  If not, then carefully review this
reasoning, and the earlier lectures on double pointers.



Another relatively easy one.  The loop test
preincrements .
 Doesn't that mean we'll skip over the first commandline argument? 
Is this a problem?

Yes, it skips the first argument,
but that's the command name itself, which won't have any dash-flagged
options to print, so we may as well jump over it.



A more interesting question is whether that ++
could just as well have been a postincrement instead of a
preincrement.  Turns out the answer is no, but why?  Specifically, if
I wrote that test as *argv++
!= NULL, then what runtime error happens, and on
exactly what line of code?

Most of the loop would operate
unchanged, but the final iteration would be messed up.  When argv is
pointing to the last non-NULL pointer (“cd”) in our example, the
postincrementing loop check advances it to the NULL pointer, but
dereferences the unincremented value, which does not result in NULL. 
So, on line 13 we'd dereference NULL, with a likely segmentation
fault or other runtime error.



is pointing to a pointer whose string we need to check for option
letters, for instance the pointer to “-ab”.


expression on line 13, and answer three subquestions.   What exactly
is being incremented?  What type is the final result of 
 Does it matter whether we use a preincrement or postincrement here?

The single pointer argv[1] is
incremented, since we apply the ++ to the result of *argv.  This
points it one past the '-' char.  But because it's a postincrement,
which does matter, the outer dereference applies to the unincremented
pointer value, and thus returns the first char of the command string
“-ab”, which is a char, and in this case a '-',  so the if is
true. 



So, we test that first char to see if it's a '-',
and do the inner loop if it is.  By the time we start that loop,

is already pointing at the 'a' after the '-' in our example case of
“-ab”.   So, the test is true.

More fun with dereferencing levels, etc.  Two
subquestions:  what would it take in the way of a commandline
argument for that line 14 test to have been false at this point, and
what would happen if we omitted one of the *s?  Are both needed?

If the commandline argument string
were just “-” with no trailing letters, then 
would be the terminating NUL, stopping the loop.  And both *'s are
needed because we want to test the character for non-NUL.  Testing
just 
would ask if the string pointer were not NULL, which would be true
even as the string pointer advanced well past the end of the string. 
We'd get an effective endless loop.


So, now let's look at the last intricate
expression, the second 
on line 15. 


As before, deconstruct that expression and answer
these questions: what is being incremented, what does the second
dereference apply to, and what, thus, is finally printed?  Use the
example case of “-ab”.

The expression dereferences argv to
get the single char pointer to 'a', and advances that pointer (*argv)
to point to 'b', but the outer dereference follows the unincremented
pointer, retrieving 'a', which character (not pointer) is finally
printed, using a %c format specifier.



So, just for fun, what if drop the parentheses
from the line 15 expression, leaving just ?
 What does that do?  And, while we're at it, what if we did the
parentheses thus: ?
 In each case, exactly what would be printed?

The first case, **argv++, increments
argv itself, so argv points one further down in the pointer block. 
But, it double-dereferences the current argv value, so we'd still get
the 'a', though we'll have surprises the next time through the loop
with argv having changed.  

The second case, (**argv)++, changes
no pointers at all, but instead double dereferences argv to reach the
'a' in “-ab”, and increments the 'a', increasing it to a 'b'. 
But, again, it's a post-increment so we'll still print 'a'.  But, the
successive iterations of the while loop will crank through all the
ASCII values above 'a' without changing any pointers at all.



clearly messes up the original commandline argument structure as it
hunts for option letters.  This is fairly typical of Unix commands. 
Once the commandline arguments are processed, they don't get used
again, so destructive examination of them is acceptable.




	
	
	
	
	
	
	






So far we've looked at pointers to various types
of data.  In this topic we'll look at a rather different type of
pointer: one that points to functions.   Code (as translated into
machine language) is a type of data.  The code for a given function
resides at some location in memory.  Function pointers hold the
address at which some function's code begins.


	
	Customizing behavior with
	function pointers



Line 27 of our sample code shows the declaration
of a 
The syntax is a little intricate: you put a * before the pointer
name, enclose both in parentheses, and then follow that with a
parenthesized list of parameter types for the target function.  As
with function prototypes, these parameter types may and generally do
omit the parameter name, since it is only the type that is of
interest in the declaration.  Finally, the 
that starts the declaration indicates the return type of the target
function, and thus has only indirectly to do with fp

This odd syntax will be more completely explained
and generalized in a later segment, but for now note that the
parenthesized asterisk implies that 
is first a pointer, and that after dereferencing it is then treated
as a function, and called.  This reflects the way 
will be used in code – dereferenced, and then called.  Declarations
of complex types always reflect the sequence of operations you would
perform on the variable in code.

And, this declaration also shows something
important about function pointers.  A given function pointer may not
point to just any function; it must point to a function with a
specific set of parameters, and a specific return type, as reflected
in the pointer declaration.  Thus, 
may point to any function that takes exactly two integer parameters
and returns an int (
and 
are examples).  It may not point to a function that takes different
parameters, nor may it point to one that takes two ints but returns a
non-int.  Function pointers are very particular beasts.  A major
reason for this is that when you call the pointer's target function,
you'll need to know what parameters to pass, and what return value to
expect.  If this is intrinsic to the pointer's type, then there's no
confusion.

Initializing a function pointer is simple. 
Function names follow a rule similar to that for unadorned array
names.  Using the function name alone gets you the memory address at
which the function's code commences, which is exactly what you would
assign into a function pointer (of the right type!) as we do on line
30.  Pointer 
now points to ,
whose code evidently starts at location 4198175 as the line 31 printf
indicates.

Do you think address alignment rules like
divisibility-by-4 apply to machine language instructions, at least on
the architecture used for the example?  Why or why not?  And, based
on earlier pointer printouts and on this example, what is the
relative position of machine language code and data in memory, again
at least on the example machine?

The address of IsGreater is
evidently odd – apparently there are no alignment rules for machine
language instructions.  And it's a good bit lower than the data
addresses we've encountered thus far, which suggests that the machine
language code resides earlier in memory than the data, at least on
the machine used for the example run.

,
which we'll be using as test data.  On line 35 we call 's
target function on the first two elements of 
We first dereference 
to get its target function (IsGreater in this case), and then call
the result of the deference, passing two integers and getting back an
integer/boolean result indicating whether the first is greater than
the second, which is 1/true, so we do the printf on line 36.

on line 35 are important.  Both the dereference and the function-call
are Per our earlier lecture
segment on the operator precedence table, the function-call has
higher precedence.  But we want to deference 
and then call the resultant target function, thus the parentheses
around the dereference.  And, again, note the parallel syntax of this
expression and the declaration of .


One of the most useful applications of function
pointers is as a way of specifying some fundamental behavior to
another block of code, by passing the other block a pointer to a
function that implements that behavior.  

For instance, in our example we have two
integer-comparison functions 
and .
 Either may be the target of 
since they have the same parameter types and return type.  In the
do-while loop on lines 38-51, we ask the user to enter &lt; or &gt;,
and based on the response we assign the address of one of those two
functions into 
on line 42.  Using 
on line 43 thus results in a different outcome depending on which
function it points to.  (In the first loop iteration, it points to
,
and the call returns 1 since the first element of 
is greater than the second.)
That's nice, but the real power of function
pointers shows on line 46.  Above 
is an implementation of insertion sort, an algorithm that should be
familiar from LMQs in earlier modules.   Recall from those LMQs that
the array is divided into sorted and unsorted areas, broken at index
,
and that the inner while loop on line 17 decides where to put

– a value we're inserting in the sorted area to the left of .
 

That line-17 loop moves the candidate insertion
location 
down the array, moving 
up (on line 18) to make room, as long as 
is less than 
and thus belongs below 
in sorted order.
The standard insertion sort code has the
comparison toInsert
&lt; vals[insNdx-1], so let's add that temporarily to
the example code.  But we want to generalize the algorithm so that
the comparison rule can be defined flexibly, instead of automatically
assuming &lt;.

What one-symbol change would be needed to the
standard insertion sort algorithm as currently edited to make it sort
in  order?  


Change the comparison to toInsert &gt;
vals[insNdx-1], so that insNdx moves down the array if toInsert is
larger, not smaller.



function to its original form, we can see that it generalizes the
comparison rule between 
and 
by accepting a function pointer 
as a parameter, and using its target function to determine whether

should be placed below 
in the sorted array.  The expression (*rule)(toInsert,
vals[insNdx-1])
should go before 
in the array.
As the output shows, after the user enters &gt;,
we pass 
(via )
to 
and get a decreasing-order sort.  Then on the next iteration, the
user enters &lt;, we assign IsLess
,
pass that to 
and we get increasing order.

or ,
we can customize the behavior of 
to sort in either increasing or decreasing order.  And of course, by
creating and passing some other function of the same type as 
and ,
we could make 
follow any other desired sorting rule.  Using function pointers to
customize behavior in this fashion is their most important
application.

Say I want to call
InsertSort to sort in ascending order, period.  How would I write
such a call, without using 
at all?  You'll need a value for the third parameter.  What would you
place there, if you simply want InsertSort to sort in ascending
order?

You'd pass
isLess: InsertSort(vals, DIM, isLess).  A function name by itself is
the address of the function, so it can be passed to a function
pointer directly.  You don't need to put it into a function pointer
first.  This is a little like passing, say &amp;i to an int pointer.


library function for C.  


?
  Why does 's
function pointer parameter point to a target function that takes void
*

You include stdlib.h.  And the
function pointer's target type takes void * parameters so that it can
be used to compare any type of element, not just an int.  This is
somewhat reminiscent of earlier LMQs where you wrote general scanning
and array manipulation routines using void * pointers so you could
have arrays of varying types.



idea carefully; you may be writing something similar for insertion
sort in the lab for this module.

In this second segment on function pointers we'll
look at an important type of behavior-customization using function
pointers: callbacks.


	
	


Especially when interacting with operating
systems, it's occasionally necessary to arrange for a component of
the operating system (e.g. a timer, or network interface) to notify
you when some event has occurred, or when some data has become
available.  You might do this by repeatedly calling an operating
system function to check on the event or data, a method termed
 But polling is time-wasteful,
requires a dedicated loop in your code, and makes it difficult for
your program to do anything else while polling.  The preferred
approach is to arrange for some function in your code to be “called
back” by the operating system when the event or data is ready. 
Your program may do other things while awaiting the callback.
Such a callback is almost always configured via a
function pointer to the function to be called.  This is a variation
on the theme of behavior-customizing, but in this case the behavior
being customized is the handling of the data or the event.
Our sample code for this segment offers a mockup
of the callback pattern.  The callback is done within a C program,
not interacting with the OS, but the principle is the same.

from ,
as you can see.  
simply scans DIM integers from the input, and then disposes of them
by calling a callback function supplied from 
via the first parameter fp
on line 12, which callback function it calls for each
integer in turn.  (More on that 
parameter, and the complex 
declaration, in a bit.)  
is thus a model of what in practice might be some operating system
component that makes a callback when data is available.
We also introduce a C shorthand for calling a
function pointer's target on line 17.  If you apply parenthesized
parameters directly to a function pointer, without explicitly
dereferencing the pointer, a dereference is provided for free, since
that's the only thing you could reasonably have intended.  So you can
call a function pointer as though it were a function.  This is more
concise, and you're encouraged to use it in the LMQs, but don't
forget the underlying truth: 
is a pointer, not a function itself.
As you can see from the output on lines 32-36, and
on line 38, our two 
calls behave very differently.  The first prints each integer out,
one line per integer, surrounded by dashes.  The second instead
totals the ints into 's
local variable ,
which 
then prints out.   Passing the callback functions 
and 
on the first and second PrintVals
calls, respectively, causes the two different
behaviors.


and 
look like?  Predictably, they each accept an integer as the first
parameter.  But, they each also have a second parameter, because they
each need more information than just the integer in order to do their
job.  
requires a format string to use when printing the integer, and

needs a pointer to the integer into which to accumulate the total. 
Oddly, these data are passed via void pointers in each case.  Why?
It's quite common for callback functions to need
more information than just the data supplied by the OS component or
program that is doing the callback.  The original creator of the
callback function often needs to supply additional configuration
data for the callback function to use.  But, the type of the
configuration data will differ per callback function (e.g a format
string vs an integer pointer).  The pointer type for the callback
function cannot vary: the parameters for any callback function must
always be the same in order to be compatible with the callback
function pointer .
 So, the usual solution is to arrange for callback functions to take
a void * parameter that might point to any configuration data, which
parameter they may cast to a pointer type of their liking within
their own code as do 
and .
 The supplier of the callback function (
in our case) provides, along with the callback function pointer, a
void * to this anonymous configuration data, which the user of the
callback function (
in our case) is expected to pass to the callback function, along with
the new data (the scanned int in our case).  It's as if the supplier
of the callback function is saying “While you're at it, pass this
void * to the callback function too, and don't ask questions about
what it points to – that's between me and my callback function.”

has a second parameter 
that it mindlessly passes to 
on line 17, and we can see why line 25 passes 
to satisfy this parameter, while line 26 passes the address of .
 The main is “in cahoots” with 
and ,
which it knows will respectively use the 
string for printf formatting, and the pointer to 
to accumulate a sum.  '
contribution to the process is just to supply the ints, and make the
callbacks as each int becomes available.

is declared as it is on line 12.  It's the same basic format as
earlier examples of function pointer declarations, but the parameter
types for its target function are more complex.  The first parameter
is the int, but there's a second one for the void * configuration
data.

,
when no cast was needed for 
in 

The void * fmt parameter can be
passed directly as printfs format parameter, because void * may be
copied into char * without cast.  But, we need to cast parameter sum
into an int pointer, so that the compiler will understand that the
target that we get by defererencing -- *(int *)sum – is an int, and
not a void.  You can't add val to a void.  Don't be surprised by the
cast and dereference on one line, by the way.  You can immediately
use the result of a pointer typecast, including dereferencing it in
the same expression.  If you're only going to use it once, there's no
reason to store the cast value in a temporary variable.



,
including creating a new callback function if needed, that puts the
maximum integer into a 
local variable .


You'll need three things:  First, a
new callback function thus:
void
TrackMax(int val, void *data) {
   int
*pMax = (int *)data;  // Worth saving this in a temp since we'll use
it several times
   *pMax
= *pMax &lt; val ? val : *pMax;



Third, a call of ProcessVals, and
subsequent print, thus:
ProcessVals(TrackMax,
&amp;max);
printf(“Max
is %d\n”, max);



What if I wanted to track both the max and the min
value, with call of ProcessVals?  What
type of configuration data would I need?  Assume you cannot change
the parameter structure of the callback, and must have only one
configuration data parameter, though it may point to any data you
like.

This would require some small
struct, with max and min int pointer fields, as the configuration
data.  The void * doesn't care what you point it to; any type works
as long as the callback function does the right pointer cast.  It's
not unusual to have configuration data that is a struct.  If you have
just one void * for your configuration, this is the only way to get
more than one piece of configuration data.




	
	
	
	
	
	
	






In this segment we'll introduce the LZW
compression algorithm.


	
	
	


Let's start with some basic compression concepts
and terms.  Compression algorithms generally view uncompressed data
as a series of  drawn from an
allowed .  The particulars may
vary: symbols might be alphabetic letters drawn from the standard
alphabet, or they might be pixel values drawn from an “alphabet”
of possible colors, or perhaps just general byte values, drawn from
the “alphabet” of the 256 different possible byte values.
In our examples, we'll use small alphabets, e.g.
just the letters a-c, but in the project the alphabet will be the 256
possible byte values.
Most compression algorithms produce a series of
 as their compressed data.  Each code
usually represents either an individual symbol, or a group of
symbols.  In the LZW algorithm, we'll have codes for individual
symbols, and also for commonly used sequences of symbols.
Codes are usually represented as numbers, often
starting from 0, which is the case for LZW.  So, for the alphabet
'a', 'b', and 'c', we'd have codes 0, 1, and 2 for those single
symbols respectively, and as the algorithm proceeds, we'd add higher
numbered codes representing symbol sequences.  Code 3 might represent
the sequence 'ab', for instance, and code 4 the sequence 'bc', etc.
Every compression algorithm tries to make the most
out of the bits in its compressed output, so the output is invariably
in binary form.  And, it's rare to see a compressed output where each
code occupies exactly one integer, or exactly one byte.  Instead, a
compression algorithm uses exactly as many bits as needed to
represent each code.  For instance, if all our codes fall in the
range 0-450, it should be clear from prior lectures that 9 bits are
sufficient to represent each code.  LZW would produce binary output
using exactly 9 bits per code in this case.
In practice, of course we must output binary data
one byte, or one int, at a time.  Assuming that we produce compressed
binary output as a series of 32-bit unsigned integers, how would we
cram 9-bit code values into those?  We treat the series of integers
as a long series of bits, that happen to be divided into 32 bit
groups, as the diagram shows.  For instance, we'd use the first 27
bits of one integer to hold three codes, and then the remaining 5
bits of that first integer, plus the first 4 of the next, for the
fourth 9-bit code.  (The pipe symbols in our diagram mark integer
boundaries.)  That leaves 28 bits in the next integer, enough for
three more 9-bit codes, plus a leftover bit that will be the first
bit of the eighth code, etc.  Keeping track of this is one of the
challenges in implementing LZW, or just about any compression
algorithm, and is the main reason you were asked to do a preliminary
version of this in one of our labs, compressing 7-bit ASCII codes
into a limited number of 16-bit shorts.

With the above basics in mind, let's look now at
how LZW works for a particular example.  In our diagram, we have an
uncompressed string using the alphabet 'a', 'b', and 'c'.  LZW
outputs a series of codes representing the content of this
uncompressed input.  To do this, it maintains a 
of codes, with the codes numbered or indexed from 0.
We start with a dictionary having one entry for
each symbol in the alphabet – three entries, with indexes 0-2, in
our example.  With this simple dictionary, we could encode the entire
input sequence as a series of codes, one code per uncompressed
symbol.  We'd need 2 bits per code.  That would work, but doesn't
offer sufficient compression to be useful.

Seems like 2 bits per symbol is pretty respectable
compression.  But, of course, a 3-symbol alphabet is not realistic. 
What would happen if we extended this example to the 256-symbol
alphabet comprising all possible byte values, with our uncompressed
data being any arbitrary sequence of bytes, instead of just 'a'
through 'c'?  How big would the initial dictionary be, how many bits
per code would we use, and how much compression would we get?

We'd need 256 codes, numbered 0-255,
and would use 8 bits or one byte per code.  We'd get no compression
at all.  Indeed, our output would be the same as the input, since the
“code numbers” are identical in this case to the byte values they
represent!


What we need is a way to express more than one
symbol per code.  In particular, we want to add codes to our
dictionary that stand for common symbol ,
so that we can compress such sequences into a single code.  

LZW notes each new symbol sequence it encounters
that isn't in the dictionary, and adds a code for that new symbol
sequence, so that if it sees the same sequence again, it can express
it with a single code.  Let's see how this works in our example.

In our concrete example, the compressed LZW output
starts with ,
for 'a'.  There is not initially a single code for 'ab', so we can't
express the first two letters with a single code.   But as shown in
the diagram, LZW does add a new code 3 (11) to the dictionary,
representing 'ab'.  If we see 'ab' again in the input, we'll be
prepared.
The next input symbol is 'b', which we express
with code 1 (01).  Here again, it would have been nice to have a
single code for 'ba', but we don't have one – yet.  LZW adds one
now, a code 4 (100) representing 'ba'.  If 'ba' crops up again, we'll
be ready with a single code for it.
And note that while we put spaces between each
code for clarity, in practice these compressed codes would all be run
together as a series of bits.  LZW, and most compression algorithms,
provide no “marker”, like our space, to show where one code ends
and another begins. Markers are too space-expensive.  Instead,
compression algorithms are simply designed so that it's always clear
where one code ends and another begins.  Up to now, we've assumed
that each code uses 2 bits since we had at most 4 codes in the
dictionary. 

But, there is an issue now that we've added code 4
(100), which requires 3 bits to represent it.   Once we've added a
3-bit code, from now on at least some of our codes may require 3 bits
in the compressed output.  But, if any code requires 3 bits, then 
codes require three bits from this point on, because we have to have
the same length for all codes, as there are no markers to show where
one code ends and another begins.  Consider the possibility that the
next uncompressed symbols were 'c' and 'a', and that we generated
2-bit codes 10 and 00 as a result.  How would this be distinguished
from the 3-bit code 100, followed by some new code that started with
a 0?  As soon as we have more than 4 codes, we need to shift entirely
to a 3-bit-per-code model.  So we adjust the dictionary, adding
leading 0's to all the 2-bit codes to convert them to 3-bit.
The next uncompressed symbols in the input are
'ab', and here our dictionary augmentation pays off.  We can express
both those symbols with the single code 3, which we added earlier. 
So, LZW encodes them both as 011.  Of course, it would have been even
better to have a single code for 'abc'.  LZW adds that, as code 5. 
If we hit 'abc' later in the input, we'll be ready.
Finishing out the current example, we would have
the following steps:
A. Next uncompressed symbol is 'c', and there's no
'ca' code, so we output 010 (3 bits, right?) and add the code 6 (110)
to the dictionary, representing 'ca'.  The dictionary now has 7
codes.
B. Next uncompressed symbol is 'a', but following
it is 'bc'.  Our code 5 represents 'abc', so we kill three symbols
with one code, and output 101.  And again, as always, we wish we
could have covered four symbols instead of three, so we add another
code for 'abcb': code 7 (111).
C. Next uncompressed symbol is 'b', and we don't
have a code for 'bb', so we settle for outputting code 1 (001)
representing 'b'.  But we add 'bb' as code 8 (1000).  And, from now
on we'll need 4 bits per code.  All existing dictionary entries
expand to 4 bits.
D. Finally, we have 'bb', and our just-added code
8 is perfect for the job.  We output (1000), and are done.  (Whether
we add a new code or not is moot since the compression is finished.)
In all, we've output 18 bits.  Had we stuck with
the simple approach of using our initial dictionary and outputting 2
bits per symbol, we'd have output 22 bits since our uncompressed
input has 11 symbols.  So, even in this small example we've gained
something by augmenting the dictionary, despite having to use
gradually more bits per code to do it.  In larger examples the
advantage is even clearer, and LZW typically reduces the size of its
input data by at least 50%.
In the next lecture segment we'll summarize the
LZW algorithm, and do a second example, via a series of in-lecture
questions.






	
	
	
	
	
	
	






In this segment we'll do some more examples of LZW
compression.


	
	LZW examples and
	applications


This example from the prior segment illustrated
the general LZW compression algorithm.  (We'll look at decompression
in a later segment.)  Summarizing that algorithm:
1. Start with a dictionary having one code per
original alphabet symbol.  Use as many bits per symbol as needed to
represent the entire alphabet.  Convert the input symbols into
equivalent output codes.
2. On each step, pick the code that represents as
many of the next input symbols as possible.  Initially, that will be
only one symbol per code, but as we add codes to the dictionary, we
may be able to represent two or more symbols with a single code.
3. After each code C is output, add a new code
that is C plus the next input symbol that C did not include.  The new
code presumes that (C + next symbol) is a pattern you'll see later in
the input. When you do, the new code will be able to represent the
pattern compactly.
4. When the number of codes passes a power-of-2
boundary, so that one more bit is needed to represent all the codes,
extend  code by a bit.  At any point in
the compression, all codes are the same length and can be
distinguished from one another in the continuous sequence of
compressed bits.
Point 3 is the hardest to remember.  It's easy to
figure out what code to use, output it, and then say “OK, we're
done with that step.”  But a given step in LZW is not done
until you add a new code to the dictionary!.  It's never “pick
the longest possible code and output it”.  It's always “pick the
longest code and output it and then immediately add a new code that
extends the one you just used.”

If LZW is given English text to compress, predict
some of the codes that may find their way into the dictionary after a
sufficiently long compression.  What if the text were some other
language instead?

In the case of English text, there
will be codes for common letter sequences, and even short words:
“ing”, “the”, “an”, “and”, etc.  For another
language, the dictionary would have common sequences and words for
that language instead.


This is a good example of why LZW is effective. 
It automatically builds a dictionary that reflects common patterns in
the input it's compressing.

Say we'd started our example with a different
input sequence, but the same initial 3-entry dictionary.  After we'd
output 15 codes, how many bits per code would we be using?  If you
think you'd need to know the actual input to answer this, think more
carefully about point 3 in the algorithm summary above.

We'd have 18 codes in the
dictionary, since we add a new code for every code we output,
regardless of what the codes represent.  Thus we'd need 5 bits per
code.

The second LZW example in our notes is there for
you to try, from scratch.  We'll do it in stages, via an in-lecture
question series.  As for the first example, we have an alphabet of
three symbols, and an initial dictionary with three codes.

What are the first three codes that will be
output?  How many bits will each occupy?  And, what does the
dictionary look like after the first three output codes?

Code 2, 1, and 0, respectively, for
the c b and a symbols.  The first two codes will be 2 bits each, but
the third will occupy 3 bits since when we output it there will be 5
codes from which to choose.   So, the output will be 10 01 000. 
Codes 3, 4, and 5 will be added to the dictionary, representing 'cb',
'ba', and 'ab'.

What about the next three codes?  Same questions:
what's the output, how many bits per code, and what gets added to the
dictionary?


a. Output code 4 ('ba') using 3
bits, and add code 6 ('bac')
b. Output code 3 ('cb'), using 3
bits, and add code 7 ('cbb')
c. Output code 6 ('bac'), using 3
bits, and add code 8 ('bacb')




One more output code, code 8
('bacb') using 4 bits, so 1000.


That last step is an interesting one.  It happened
in the earlier example also: we created a code on one step, and then
used the newly created code on the very next step.  That pattern will
be important when we look at decompressing these sequences, so please
remember it.

What sort of improvement did we get this time over
the simple alternative of using 2 bits per symbol throughout, without
adding to the dictionary?

We output 20 bits, vs the 28 bits
we'd have needed with the simpler approach.



It's interesting to consider cases where LZW works
especially well.  What would the output look like if I started with
our 3 symbol dictionary, and compressed a sequence of, say, 15 a's:
aaaaaaaaaaaaaaa?  How many bits long would it be, and what content
would it have?

This would take 5 codes, and 13
bits:  codes 0 (00, representing 'a'), 3(11, representing 'aa;'), 4
(100, representing 'aaa'), 5 (101, representing 'aaaa'), 6 (110,
representing 'aaaaa').  This is the extreme example of LZW at work,
as each new code extends the prior one, and then is immediately used.



One more just for fun.  Assuming we start with the
standard initial 3-symbol dictionary, the following bit output is not
possible.  At which bit can we be sure of that?  0110100110101

Breaking into codes, that would be
01 10 100 110 &lt;--- And this is not possible.  We don't have a code
6 by this point, only a code 5.  We can tell something is amiss on
that second 1-bit in 110.

Find at least one major compression standard that
uses LZW, and look up the history of LZW, especially regarding
software patents.

What do the letters LZW stand for?  What major
software compression standard was subject to patent litigation
regarding its use of LZW?  When did the patent expire?

LZW stands for Lempel Ziv Welch –
the algorithm's creators.  Welch's improvement, in particular, made
LZW widely successful, and was the subject of a notorious early
software patent that prevented free use of the GIF compression
standard, which is built on LZW.  The patent expired, thankfully, in
2003.
















	
	
	
	
	
	
	






In this segment we'll look at decompressing
LZW-compressed data, undoing the compression that we did in the prior
lecture segments.  In principle, LZW decompression is just a matter
of reversing the compression process, but there are a few
complexities to discuss.  We'll look at those, and walk through two
example decompressions.


	
	Special “just-in-time”
	codes.


The first question to ask when decompressing LZW
data is whether the decompressor needs the dictionary along with the
compressed data.  Importantly, the answer is “no” --
“importantly” because the extra data to store the dictionary
would add so much space that it would defeat the compression.
Instead, the decompressor assumes the same
alphabet as the compressor (this much they must agree on) and thus
the same initial dictionary.  From there, the decompressor
reconstructs the dictionary ,
using the same algorithm the compressor used to create the dictionary
in the first place.  Since the decompressor knows exactly the
algorithm that the compressor used to create the dictionary and the
alphabet that formed the initial dictionary, the decompressor can
produce an exact copy of what the compressor had in the dictionary at
each stage of the compression.
Let's see how this works by decompressing the
result of our second example from the lecture on compression.  We'll
start with the compressed output from that example, and with no gaps
between codes, since we need to show that the decompressor can
differentiate one code from the next solely by the current dictionary
content and the LZW algorithm.
The dictionary starts in “2-bit” mode, having
only 3 entries, since we know the alphabet was 'abc'.  The dictionary
stays in 2-bit mode for the first two codes, before going to 3-bit
mode.  So, the first code is clearly ,
for 'c'.  So the decompressed output starts with 'c'.  And, the
decompressor now adds code 
to the dictionary, to mimic what the compressor would have done.
And here we see an important issue in
decompression.  Code 
will represent 'c_' where _ is the second symbol in the uncompressed
data (you may recall it was a 'b').  But the decompressor doesn't
know that symbol yet; it must at least start decompressing the next
code in order to learn it.  So, while the compressor has the
uncompressed data sitting right in front of it, and can readily
determine the “extension symbol” to add to each new code, the
decompressor has to wait for the next code before it can know the
final symbol of the just-added code.  It's always a half-step behind.
 As we trace the decompression, we'll end the most recent new code
with '_', and fill that in once we know the first symbol in the next
code.
With that in mind, then, the next code, still 2
bits long, is ,
for 'b'. So we know the second uncompressed symbol, and also the full
meaning of code :
'cb'.  But, we also add code ,
now, which will stand for 'b_', with the _ remaining a mystery until
we decompress the next code. 

With 5 entries in the dictionary, we're now in
3-bit mode, so...

What's the next code?  What's the third symbol in
the uncompressed data, and the missing _ for code ?
 And what new code do we add to the dictionary?

Next code is 000, representing 'a'. 
So code 100 is 'ba', and we have a new code 101, representing 'a_'
with the _ again a mystery.


And so the pattern goes.  Summarizing the
decompression process:
1. Start with the same original dictionary as the
compressor.  Add new codes to it just as the compressor did.
2. Obtain the next code C from the compressed
bits.  You can tell how many bits it has based on the current
dictionary size.
3. Add to the uncompressed data the symbols that C
represents.   If you are on the second or later code, then also use
C's first symbol to fill in the missing final symbol from the 
iteration's new code.
4. Add another new code to the dictionary,
representing C extended by one more unknown symbol -- the first
symbol of the Leave a
placeholder in the new code until you learn that symbol on the next
iteration.
5. Increase the bits-per-code if the dictionary
size has crossed a power-of-two boundary.


Use this process to decode the next 3 codes,
leaving the final one for later, since it requires a bit more
discussion.  Show the new dictionary contents, and the uncompressed
symbols.


a. Decompress code 100 to get 'ba'. 
Fill in code 101 from answer 1 to represent 'ab'.  Add code 110
representing 'ba_'.
b. Decompress code 011 to get 'cb'. 
Fill in code 110 to represent 'bac'.  Add code 111, representing
'cb_'.
c. Decompress code 110 to get 'bac'.
 Fill in code 111 to represent 'cbb'.  Add code 1000, representing
'bac_'.  Go to 4-bit mode.


And now we get to the most clever part of the
decompression algorithm.  The dictionary stands at 9 codes, and is
thus in 4 bit mode.  And our next and final code is 1000, code 8.

is the one we just added, and its final symbol is unknown.  The next
code's first symbol was supposed to fill that in, but the next code

This seems like a catch-22, but it's not.  To know
the final symbol of code ,
we need only to know the  symbol of the
next code, even if that code is 
itself.  We  know the first symbol of code
;
it's 'b'.  So logically code 's
missing final symbol must be 'b'.  We fill that in, so code 
represents 'bacb', and we then use the now-complete code 
to provide the final four uncompressed symbols.  The final
decompressed result (with gaps added to show the code breaks) is 'c b
a ba bc bac bacb'.
If that little stunt bothers you, try looking at
it this way.  When the compressor created code 1000, it 
that the next uncompressed symbol after the 'bac' was a 'b'.  So it
immediately made code 1000 stand for bacb.  Then it discovered on the
next step that it could use that code immediately, which of course
could only be so if the code started with a 'b' as well as ending
with a 'b'.  We're just reconstructing what the compressor must have
done.  And any time a code is immediately used after creation, it
must be that its last letter and first letter are the same.

Now that we've done one walkthrough, let's
decompress the second example case shown in the diagram, including
deducing all uncompressed symbols, and the full dictionary content. 
You'll find at least one case like the 'bacb' code just discussed.  




a. Decompress code 01 to get 'b'. 
Add code 11, representing 'b_'.  Still in 2-bit mode
b. Decompress code 01 to again get
'b'.  Fill in code 11 to represent 'bb'.  Add code 100 representing
'b_'.  Go to 3-bit mode.
c. Decompress code 010, to get 'c'. 
Fill in code 100 to represent 'bc'.  Add code 101 representing 'c_'.
So, after these three steps, we've decompressed
'bbc', and our dictionary now has 6 codes.

Be sure you understand any errors you might have
made in the prior question, and then do the next two codes.

a. Decompress code 011 to get 'bb'. 
Fill in code 101 to represent 'cb'.  Add code 110 representing 'bb_'.
b. Decompress code 110 to get 'bb_'.
 Fill in code 110 to represent 'bbb', following the “just in time”
reasoning we covered earlier.  Add code 111 representing 'bbb_'.
So, this time we had a case where a new code was
immediately used, and thus its first symbol was also its last
filled-in symbol.  Our decompression stands at 'bbcbbbbb', with 8
codes in the dictionary.



a. Decompress code 101 to get 'cb'. 
Fill in code 111 to represent 'bbbc'.  Add code 1000, representing
'cb_'.  Go to 4-bit mode.
b. Decompress code 1000 to get 'cb_.
 Here's another case of just-in-time code completion: fill in code
1000 to represent 'cbc'.  Add code 1001 representing 'cbc_'.
c. Decompress code 0101 to get 'cb'.
 Compression is done.  (No need to add a new code; that would just
increase space and waste time.)

















	
	
	
	
	
	






In this lecture we'll do a walkthrough of the LZW
algorithm as it will be applied in our coding project.  In
particular, we'll start with a much larger alphabet, and we'll look
at how to jam codes of odd bit sizes into 32-bit integers, as the
project does.


	
	


Our project LZW implementation adds several
details to the general LZW algorithm covered in earlier lectures.  


Since we'll be encoding arbitrary data, either
text or binary, we'll assume only that our data is some series of
bytes, and we'll use as our alphabet all of the 256 possible byte
values, plus one more special symbol for end of data, or EOD.
 This last symbol appears only once, added automatically to the
end of our compressed output.  We'll talk more about the reason for
an EOD symbol later on.

The initial dictionary has 257 codes, one for each
symbol in the alphabet &ndash; the 256 byte values and the EOD.  

This is typical for real-life LZW, but it does
invite a confusion.  Because of our alphabet choice, the code numbers
for the symbols 0-255 inclusive are identical to the symbols
themselves.  Symbol 0, a byte value, is represented by code 0. 
Symbol 1, a different byte value, is represented by code 1, and so
on.  (EOD has code 256, and is not really a byte value, so it's a
little different.)  This tends to make students assume that &ldquo;codes
are the same as symbols&rdquo;.  This is 
so, as is obvious once we start adding codes 257 and higher, which of
course will represent symbol sequences.  Keep a clean line in your
mind between codes and symbols in this project, especially for the
initial dictionary.

If you run an LZW compression long enough, the
dictionary becomes very large, and you need progressively more bits
per code, and more space for the dictionary.  Also, since LZW in
effect &ldquo;samples&rdquo; the uncompressed input for likely
sequences of symbols and adds them to the dictionary, if the
distribution of sequences changes during the input (e.g. shifting
from one topic and set of vocabulary to a different one in a lengthy
text) then the codes developed earlier in the compression may not be
as useful later.  

A common solution to this, and one we'll use in
our project, is to start the dictionary over again from scratch after
it reaches a certain size.  We'll call this dictionary
recycling

What is the relationship between maximum
symbol-sequence length and dictionary size?  If a dictionary starts
with 257 codes, like ours, and increases to 4096 codes, how long can
the symbol sequences in it be?

Since it's possible for each
sequence to extend the one prior (e.g. if our input is a long repeat
of the same symbol) then we might have a symbol sequence of length 2
for code 258, length 3 for code 259, and ultimately of length (4096 &ndash;
257 + 1) or 3840.  


important in the project, depending on the
implementation of CodeSet.  Knowing the maximum length of a symbol
sequence is important.

The output of the compressor, and the input to the
decompressor, will be a series of 32-bit ints.  The LZW codes will
vary in length, per the algorithm, but we'll embed the codes into the
ints in the manner already discussed in an earlier lecture on LZW,
and which we'll review in the exercise below.  This means that the
last bits of the final int may be unneeded; we'll just set them to 0
if so.

Say we only need 4 bits of the final int to store
the last few bits of our final code.  We'll set the 28 bits that are
left over in that final int to all-0s.  Assuming we have no EOD code,
what ambiguity would result from doing this?  What two or more
different ways might we interpret the compressed data in that final
int?

We might view those final 28 bits as
one or more 0-codes, implying that there are extra 0 symbols at the
end of our data that were not actually in the original uncompressed
input.

	
	This is an inherent problem in dealing with the
	final leftover bits if you insist on having a round number of 32-bit
	integers as your output.  We have to fill those unneeded bits with
	, and when we do, there's no way
	to distinguish between what we meant as simple dummy filler for
	unneeded bits, and actual codes at the end of the compressed data. 
	The solution is our EOD code, which we add as a final code to the
	compressed output (the actual input doesn't include any such symbol,
	and we drop the EOD when decompressing).  This unambiguously
	indicates that any remaining bits after that EOD are to be ignored. 
	 So, the final output code from our compressor will be the EOD (256)
	code, and after it all leftover bits are set to 0, and should be
	ignored.


With all this prolog, let's do a final walkthrough
of LZW with the configuration that will apply for our project.  The
diagram shows the input we'll compress, and the initial dictionary,
with the first 256 codes summarized with one line.  As you can see,
our first output code will be 97, which is the code (and ASCII value)
of the byte containing 'a'.  And we add code 257 representing 'ab'. 
The next output code is 98 for 'b', and we add code 258 representing
'ba'.  


How many bits per code are needed at this point? 
How soon is that going to increase?

9 bits, since our dictionary has
more than 256 codes.  It won't increase till we hit code 512, which
is well past the range of this example.  So in this case study all
our codes will be 9 bits.


We'll worry about embedding these 9-bit codes into
32-bit integers a little later.  For now, knowing the codes and that
they are 9 bits each suffices.

Do the next three steps of the compression,
showing what codes will be output and what will be added to the
dictionary.

Output 97 for 'a', adding 259 for
'ac'.
Output 99 for 'c' , adding 260 for
'ca'.
Output 97 for 'a', adding 261 for
'aa'.


So far we've had no luck with multi-symbol codes,
but that's about to change.



Output 261 for 'aa', adding code 262
for 'aaa'.
Output 262 immediately for 'aaa',
adding code 263 for 'aaae'.
Output 101, adding code 264 for
'ea'.
Output 261, adding code 265 for
'aab'.



Finish out the final 7 output codes.  Be sure you
see why there are 7 needed.  


Output 258 for 'ba', adding code 266
for 'baa'.
Output 263 for 'aaae', adding code
267 for 'aaaea'
Output 262 for 'aaa', adding code
268 for 'aaaa'
Output 268 for 'aaaa', adding code
269 for 'aaaaa'
Output 269 for 'aaaaa', adding code
270 for 'aaaaa\n'  (Note that \n is a 1-byte symbol like any other.)
Output 10 for '\n'.  Don't add a new
code.  Remember EOD is not really part of the input.


And that's it for our sample compression, except
that now we need to embed these 9 bit codes into 32-bit ints.  We'll
do that now, and will translate the 32-bit patterns that result into
hexadecimal, since the project code will output compressed data in
this form, and enabling you to debug project compressed data is a
major goal of this segment.
The diagram shows how the first four codes 97, 98,
97, and 99, comprising 36 bits collectively, form the first int, and
the first 4 bits of the second int.  The bits are grouped into codes,
not ints.  To delineate the ints, we embed '*' symbols at the mark
between each group of 32 bits, and you need to bridge the spaces
between code bit-groups to assemble the hex interpretation of the
integer bits.  Doing this, you can see the first output int would be
hex 30988C26.  This is the output you'll actually see from your
project.

Add the next 4 codes to finish the second int and
generate the first 8 bits of the third.

As the diagram indicates, the second
int will be 330C160C, with the first 8 bits of the third int being
hex 65.



And finish up the task now, remembering to fill in
the leftover bits of the final int (of which you should have 1)
with 0s,

You should get, as the diagram
shows, 6582C0A0, F0686434, and 15000000.




	
	
	
	
	
	
	







10/30
Improved description of CodeSink
11/1
Some hints on tree traversal state

This lecture segment goes over the LZW
Compress/LZWCmp project.  Note that this lecture is an .
 The formal project specification and LZWCmp.h header file comments
should be your main resource.  Also, this lecture assumes you've
already done the lecture on LZWExp.


	Progressively-traversed
	BST



typedef.  First, note that 
is a 
of 
is a variable of this type.   
points to a callback function, of the type inplied by 
 This callback function, supplied from outside of LZWCmp, accepts
compressed data in the form of a 32-bit unsigned int.  (The type 
is defined as such in )
 It also takes a configuration parameter, as in the lectures on
function pointers.  This is pointed to by sinkState,
and may be NULL if no configuration is needed.  And the
callback function takes one extra parameter, a boolean 
indicating that the end of compressed data has been reached.  After
all compressed data has been sent, LZWCmp makes one more callback
with garbage 
value and set
to true.

LZWCmp uses a binary tree to hold the symbol
sequences for known codes, starting with the initial alphabet, and
adding new sequences/codes as the algorithm progresses.  LZW
decompression gets code numbers from the compressed data and uses the
code number to get the corresponding symbol sequence.  By contrast,
LZW compression gets symbol sequences from the uncompressed data, and
must look up their corresponding code numbers alphabetically.  In
decompression the &quot;key&quot; for lookup is the code number, but
in compression, the &quot;key&quot; for lookup is the symbol
sequence.
code
hunting as the term for looking up a code number based
on a symbol sequence.

Consider what code hunting takes.  If, for
instance, we see 'a' in the input, should we output the one-symbol
code 97 for it?  That depends on the next symbol, and on whether we
have a code for the two-symbol sequence.  If the next symbol is 'b',
and we have a code 'ab' (say code 260), then we should not output
code 97; we should wait and output a multisymbol code.

So, if we see 'ab' in the input, and if we do have
a code 260 representing 'ab', does that mean we 
output code 260?  Why or why not?

It still depends.  If the next
symbol after 'ab' is 'c', and if we have a code for 'abc', we should
output that, or perhaps some even longer code.  If instead the next
symbol is, say, 'd', and we don't have a code for 'abd', then we
would output code 260.



possible code, by starting with a one-symbol code, and then picking
longer and longer codes as we get new symbols, until we finally get a
symbol S that cannot be fit into any code we have.   Then we output
the longest code C that we found, and also add a new code D by adding
symbol S to C.  And we start a new code hunt, starting with S.
Doing code hunts in a CodeSet-type dictionary
could be very tedious.  Codes aren't in sorted order (except the
initial codes) and so we'd need to do repeated iterations through the
dictionary as we look for longer and longer codes.  

What we need is a different data structure, that
lets us rapidly find the code for a symbol sequence.  A binary search
tree is just such a data structure.

The upcoming discussion assumes you know how a
binary search tree (BST) works.  Now's a good time to look up BST
concepts from prior coursework if you need to.  The good news is that
you need only to know BST basics, including adding and searching, but
not deletion.   Here are some concepts to be sure you have from your
review:

	BSTs have nodes. Each node has a key and a
	left and right pointer to other nodes, termed its 
	nodes.  It is their 
	node. 
	
	
	is at the top of the tree &ndash; the ultimate parent.  You
	diagram/visualize the tree as &quot;hanging&quot; from that root
	node, growing downward from it.
	A parent node P's child nodes may in turn
	point to other child nodes (unsurprisingly called P's grandchildren
	)
	which in turn may point to further child nodes, etc. in a
	potentially infinitely branching pattern.
	One or both of a node's child pointers may be
	null, which is how the BST reaches its bottom.  If both pointers are
	null, the node is a 
	In a BST, all descendant nodes reached from a
	parent P's left pointer have key values 
	than P's, and all 
	nodes to P's right have larger key values.   In effect, the left
	pointer from P points to a mini-BST of children, called a ,
	all of which have keys less than P's, and its right pointer points
	to a mini-BST of children having keys greater than P's.  P's left
	and right children are the 
	of their own small BSTs.
	Each subtree is similarly organized, with
	nodes having keys less than its subroot's key falling to the left of
	the subroot, and those with keys greater falling to the right of the
	subroot.  The BST thus divides the key values more and more finely
	at each level, in a recursive
	pattern
	
	You search for a key K in the BST by starting
	at the root.  If K matches the root's key, you're done.  If not,
	then if K is less than the root's key, any node holding K must be to
	the root's left, and if K is greater than the root's key, any node
	holding K must be to the root's right.  So you go to the  left or
	right child, and repeat the process.  At each node, you either find
	K, or are guided to the left or right.  This process guarantees
	finding K, if it's in the BST at all. 
	
	If K is not in the tree, then you ultimately
	reach a node N whose left/right pointer that should have led to K is
	instead NULL.  (Note this doesn't necessarily mean N is a leaf,
	since N's 
	You can correctly add a new node containing K by
	hanging a new leaf node containing K off of that pointer.  Doing
	this ensures you'll find K by the process in point 7, should you
	search for it again.
	The search process in point 7 is fast if the
	tree doesn't have too many generations, or levels
	,
	with most nodes having both left and right children, this wil be so.
	 Indeed, a tree of L levels may have 2 nodes in it &ndash;
	one of 20 levels may have over a million nodes, meaning such a
	balanced tree lets you find one key out of a million with 20 steps.


Assume the initial dictionary for an LZW compress
is 'a', 'b', 'c', 'd' &ndash; four keys.  Insert them into an empty
BST, in that order.  How many levels does the BST have?

Four levels.  Each key falls to the
right of the prior key, so the tree has no two-child nodes.





         
\
         
  d


If you're up on your BST terminology, you'll know
that a BST with no two-child nodes is called a degenerate
BST &ndash; in effect a linked list with extra unused
pointers.  This not a good shape for a BST since it's inefficient,
but we'll change it quickly.

Now add keys 'ab', 'bc', 'aa', and 'aba'.  How
many levels does the tree have now?  Remember that by lexicographic
order, 'ab' is greater than 'a'.

Still four.  'ab' is greater than
'a', but less than 'b', so it goes to 'b's left.  'bc' goes to 'c's
left, 'aa' goes to 'ab's left, and 'aba' to its right

        


         
 
        

ab
    c
/
 \    / \
aa
 aba bc  d


Again, this is not a BST introduction.  If these
concepts aren't clear in review, you need to consult other resources
and prior coursework until you see how we arrived at the two trees
here.

The BST for LZW compression starts with one node
for each 1-symbol code in the initial dictionary.  It then adds new
symbol sequences to the BST as the LZW algorithm adds them to the
dictionary, so it can find any prior symbol sequence by searching the
BST.  But, there are two special issues to consider:

First, you don't get an entire key at once; keys
arrive one symbol at a time.  For instance, say the key (symbol
sequence) 'a' is in the BST (in the LZW dictionary).  If we see the
letter 'a' in the uncompressed input, we might search the BST for
that key and find it, outputting the corresponding code.  But, how do
we know that 'ab', or even 'abc' is not also in the BST?  If they
are, then stopping with just 'a' violates the LZW algorithm.  And we
wouldn't get the letters all at once.  Each one arrives in a
different call of LZWCmpEncode.
Indeed, in extreme case it might take hundreds of calls
to get all the symbols for one key!
So, one of the biggest challenges in this data
structure, and one you must figure out with just a few hints from
this overview, is how to take ,
and traverse the BST .  Here are the
hints:
partial
key, comprised of the symbols thus far seen, that
matches at least the prefix of some BST node.
2. You need to track what node in the BST you're
currently at, and how much is matched.

need to go left or right in the BST.  But you might stay with the
present node, too.
4. When you reach a
null pointer, you can deduce both what key should be used, and what
key should be added.
ere
are 4 fields in LZWCmp to track this process.  Read their comments.


Holding all the keys in open form is too space
intensive
Especially if LZW codes become long, the obvious
choice of representing each code as an allocated block of symbols
becomes too slow and memory expensive.  Fortunately, we have a very
compact way to represent a dictionary of LZW codes &ndash; a .
 So, each BST node will hold a code number, and the LZW compression
algorithm will include a 
with contents just like those for the expansion algorithm.  

So, for instance, node X in the tree might have
code number 260 as its data, representing symbol sequence &quot;aa&quot;
if expanded, while node Y might have code 259 as its data,
representing symbol sequence &quot;bb&quot;.  Node Y would still be
greater than node X in the tree, despite having a smaller code
number, because we sort by symbol sequences.  But except when
actually comparing symbol sequences, we'd hold just the code numbers
in the nodes to save space.
As you traverse the BST, you get each symbol
sequence from this ,
using the code number in each node.  But, be sure to  each
sequence once you move past its node, or you'll break the memory
usage requirements.  At any time, at most one or two codes should be
expanded, and the rest are in the .
 


The need to allocate and free many tree nodes is
the biggest weakness of the BST data structure.  
and 
look like quick operations since they entail only one line of code
each, but in fact they can be so time consuming that in extreme cases
50% of your program's execution time may be spent in these functions
alone.   In our project, we'll fix that by maintaining a freelist of

structs.  (We assume you understand freelists from other lectures at
this point.)

s
are designed to be in tree structures.  How would we make a simple
linked list of them?  What would we use for a next pointer?  (Feel
free to repurpose any part of the 
for this; if a 
is on the freelist, we don't care about its contents any more.)

We need some sort of a &ldquo;next&rdquo;
pointer to link nodes on the freelist.  Might as well use, either the
right or left child pointer for this.  We can create a linked list of
TreeNodes, then, by linking them through their right pointers.





	
	
	
	
	
	
	






This lecture segment goes over the compression
phase of the LZW project.  Note that this lecture is an .
 The formal project specification and LZWCmp.h header file comments
should be your main resource.  Also, this lecture assumes you've
already done the lecture on LZWExp.


	



typedef.  You already recall from the LZWExp lecture that 
is a not a variable.  It's the field

of 
that's the pointer.  
is the counterpart to 
from the LZWExp lecture – it accepts compressed data in the form of
a 32-bit unsigned int.  (The type 
is defined as such in )
 It also takes a configuration parameter, as did 

LZWCmp does not use a CodeSet dictionary the way
LZWExp did.  The CodeSet is well suited for looking up symbol
sequences given a code number, but it's not as good at finding the
best code number given a symbol sequence – not as good at what
we'll call 

Consider what code hunting takes.  If, for
instance, we see 'a' in the input, should we output the one-symbol
code 97 for it?  That depends on the next symbol, and on whether we
have a code for the two-symbol sequence.  If the next symbol is 'b',
and we have a code 'ab' (say code 260), then we should not output
code 97.

So, if we see 'ab' in the input, and if we do have
a code 260 representing 'ab', does that mean we 
output code 260?  Why or why not?

It still depends.  If the next
symbol after 'ab' is 'c', and if we have a code for 'abc', we should
output that, or perhaps some even longer code.  If instead the next
symbol is, say, 'd', and we don't have a code for 'abd', then we
would output code 260.



possible code, by starting with a one-symbol code, and then picking
longer and longer codes as we get new symbols, until we finally get a
symbol S that cannot be fit into any code we have.   Then we output
the longest code C that we found, and also add a new code D by adding
symbol S to C.  And we start a new code hunt, starting with S.
Doing code hunts in a CodeSet-type dictionary
could be very tedious.  Codes aren't in sorted order (except the
initial codes) and so we'd need to do repeated iterations through the
dictionary as we look for longer and longer codes.  

What we need is a very different data structure,
one that rapidly lets us find the code for a symbol, and then all
codes that extend that code to a second symbol, and for each such
2-symbol code, all codes that extend to a third symbol, etc.  Some
sort of tree structure seems warranted.

But, it's not going to be the binary tree with
which you may be familiar from prior coursework.  Instead, we're
going to use a  (pronounced “try”)
data structure, which is a tree specifically designed for looking up
strings of symbols rapidly.  In the discussion that follows we'll
assume you're familiar with the basics of binary trees.  Please look
these up in the myriad web resources that discuss them if you need a
refresher.
A trie has a root node, child nodes, and multiple
levels, just like a binary tree, but unlike a binary tree, each node
may have more than 2 children.  Indeed, each node in a trie has as
many possible children as there are symbols in the alphabet that
makes up the strings stored in the trie.
,
on line 17 of the slide.  This has two fields: an array codes

of 
pointers.   The latter holds the pointers to potential children, so a

may have multiple children, as advertised.   The arrays have
dimension equal to our symbol count, so there will be one code, and
one potential child node, for  symbol in
the alphabet.
Now, this means that for our project we'll have
trie nodes that could have 256 children.  It's rather hard to draw
that, so for illustration purposes let's look at what a trie would be
like for the 3-symbol 'abc' alphabet we've used in prior LZW
examples.  You can generalize this to the 256 symbol case for the
project.
I've drawn such a trie node on the slide.  And, in
the drawing, I've assumed that the two 3-element arrays may be
indexed , so that we can talk
about 
or 
for instance.  This is a bit abstract, but note that since our real
alphabet 
a set of numerical values from 0 to 255, we'll be able to do such
indexing naturally in the project.  The critical point is that for a
trie node the symbols are used as ,
and the node data does not store symbols per se.
With that background, let's look at the root trie
node, which we'll always have – our trie will always comprise at
least one root node, containing the initial 1-symbol codes in its

array, one code per symbol.  All code hunts start here at the root,
looking up the 1-symbol code for the next symbol.  So, as you can see
in our diagram, the code for 'a' is 0, for 'b' is 1, etc.
But, the code hunt must always seek a longer code
if possible, and this is where the 
array comes in.  Many of the 
elements may be NULL (marked by –
in our diagram), but if there are any 2-letter codes that
start with the initial symbol, then the link for that symbol is not
NULL, and points to a child trie node.   


symbols.  For instance, as in the diagram, if there is a code for
'ab', then the link for symbol 'a' points to a child trie node whose
'b' 
element gives the code for 'ab', say code 3.  The other elements of

may also have code values for other codes representing 2-letter
sequences starting with 'a', for instance code 4 for 'ac'.  But, they
may instead contain -1 (which was not an option in the root node)
indicating “no such code”.  So, in our diagram, there is no code
for 'aa'.
Similar child nodes may exist for any of the other
symbols in the root node.  For instance, we can add a link from
symbol 'c', pointing to a child node that gives the code for 'ca',
say code 5.

Modify the diagram to show that code 6 represents
'cc'.

Simply put a 6 in the third element
of the 'c' child node's 
array.
What if there are codes with more than 2 symbols? 
In this case the pattern for 2-symbol codes extends naturally to
further levels.  If, for instance, there are 3-symbol codes starting
with 'ab', then a link from the 'ab' entry at the second level leads
to a child trie node at the third level, which gives codes for
3-symbol sequences starting with 'ab'.

Based on the diagram, what symbol sequences do
codes 7 and 8 represent?

They represent 'abb' and 'abc',
respectively.

Modify the trie so that it shows code 9
representing 'cca'.

Add a new trie child node from the
link for 'cc'.  Set it's 'a' 
entry to 9.
And, finally, the pattern continues for arbitrary
lengths of symbol sequences.  For length-4 symbol sequences, we add
level 4 child nodes, for length-5 sequences, level 5 child nodes,
etc.

Modify the trie to show code 10 representing
'ccab', code 11 representing 'ccaa', and code 12 representing 'abca'.

Add a child trie node off the link
for 'cca', and set its 'b' and 'a' 
elements to 10 and 11 respectively.  Likewise add a new child trie
node off of the link for 'abc', and set its 'a' 
entry to 12.
The trie data structure is admittedly rather
space-inefficient, with many -1 and NULL entries, especially in leaf
nodes.  But, it's extremely fast, permitting code hunts with only one
array index and pointer dereference per symbol.

The LZWCmp type is the analog of the LZWExp type,
and has similar fields, including 
and ,
numBits, nextCode,
etc. Instead of a code dictionary, however, it has a

pointer to the root of a trie data structure.
Probably the most sophisticated fields in LZWCmp
are ,
and .
 Figuring out how to use these is part of the challenge, but look
closely at the reasoning earlier in the lecture on code hunting, and
note that you only get one symbol at a time via .
 This means that the average call of 
will  find a code, but will only advance
some ongoing code hunt by one symbol, stepping down more more level
in the trie.  You need to keep track of the state of a partially
complete code hunt, and advance that state one 
call at a time.

The need to allocate and free many trie nodes is
the biggest weakness of the trie data structure.  
and 
look like quick operations since they entail only one line of code
each, but in fact they can be so time consuming that in extreme cases
50% of your program's execution time may be spent in these functions
alone.   In our project, we'll fix that by maintaining a freelist of

structs.  (We assume you understand freelists from other lectures at
this point.)

s
are designed to be in tree structures.  How would we make a simple
linked list of them?  What would we use for a next pointer?  (Feel
free to repurpose any part of the 
for this; if a 
is on the freelist, we don't care about its contents any more.)

We need some sort of a “next”
pointer to link nodes on the freelist.  Might as well use, say,

for this.  We can create a linked list of TrieNodes, then, by linking
them through their links[0] pointers.  We could have used any of the
other links elements too; the TrieNode really has a surplus of
pointers if all we want to do is create a singly linked list.





	
	
	
	
	
	
	






This lecture segment goes over the decompression
or “expansion” phase of the LZW project, which you will implement
first, since it's a little simpler than the compression phase.  Note
that this lecture is an .  The
formal project specification and LZWExp.h header file comments should
be your main resource.

Do what the header says: Read The Spec and Header
Comments.  This discussion starts by assuming you've at least read
over the specification for LZWExp/TestExp and the comments in
LZWExp.h.  We'll do some value-added discussion on top of it.

Based on your reading of the spec, how many times
will the DataSink function be called for a given compressed input
that we are decompressing?  No need to get into deep details on the
declaration of DataSink, etc.  Just tell what will determine the
number of calls.  Is it, for instance, the same as the number of
characters of the uncompressed output – one call per character of
output?

It's not the number of output
characters; it's the number of codes in the compressed data.  There
will be one DataSink function call for each code.


parameter of the DataSink function a string?

No, because the data block it points
to may include any number of NUL bytes, so a NUL doesn't mean the
data is over.  Instead, the 
parameter determines how long the data block is.


for DataSink deserves a bit of clarification.  Note that it follows
the function pointer syntax described in our lectures: a
parenthesized pointer notation ,
followed by a list of parameter types.  This would, absent the
declare
a function pointer suitable to point to a callback function that took
a configuration, per our lecture on callbacks, plus a block of byte
values and its size.

changes this from a variable declaration to a type declaration, so

is a , not a variable.  This type may be
used to declare actual function pointers, as we do on line 29 in the
LZWExp struct declaration.  It is 
that is the pointer, not 

As the spec says, the LZWExp type is the heart of
the decompression process.  To do a decompression, you create and
initialize a struct of this type, and pass it to the various
functions described in the spec to perform the steps of the
decompression.  Let's look more closely at its fields via a few
in-lecture questions.
dict
field, and consider how we would use the CodeSet from a
prior lab as our code dictionary for decompression.  The somewhat odd
design of CodeSet's functions is actually directly intended for use
as an LZW decompressor's code dictionary.  


For instance, at what point would you call 

and 
from the CodeSet.h/c files you wrote for that lab. What steps in the
decompression process do they serve?


would be used to set up initial dictionary codes, with one symbol
each.  
is used to make new, one-symbol extensions on prior codes, as we
decompress each new code from the input and add a new code that
extends it.  



about?  When would we need that in the LZW decompress process?

Recall that we must leave the final
symbol of each new code undetermined, until we know the first symbol
of the next code.  Then we can go back and “fill in” that final
symbol.  This is exactly what setSuffix is for.  It fills in the last
symbol of a previously extended code.


You can work out the rest of how CodeSet is
integrated into the LZW decompression process, but these questions
and answers at least give you a start.

You may think of the LZWExp type as a sort of
“class”, in the spirit of object-oriented programming, and may
view an LZWExp struct as an object.  In an OO language like Java, one
declares a class with member data, and also with methods.  C doesn't
permit adding methods to a struct (though its OO cousin C++ does),
but you can fake it by the kind of functions provided in LZWExp.h,
each of which takes an LZWExp * as its first parameter.  These
functions in effect treat the LZWExp struct that you pass via that
pointer as the “object” of their operations, and they update its
fields (“member data”) to reflect changes resulting from the
operation (e.g. modifying the dictionary to add a new code). 

This type of design is how one does “object
oriented” programming in C: with a struct type “class” that has
only member data, and with function “methods” that accept, as
their first parameter, a pointer to the struct (“object”) they
operate on.  

(This is, in fact, how things work under the hood
even in an OO language like Java or C++.  Methods in those languages
have an extra first parameter silently and invisibly added to them to
point to the object that they are supposed to “belong to” under
the OO model.)

prefixes for the function names is an old-fashioned way to do what in
a modern OO language would be done with scope, nesting the function
names into the class that owns them.  No such name scoping is allowed
in C, but we can approximate it by consistently prefixing function
names with the name of their “class” so that they will not
conflict with any other function names, even in a very large program
with many other functions.
This is more than an academic comparison.  You
will encounter well-organized C programs that follow the design
patterns just described, dating as far back as the 1970s.  These were
the forerunners of OO design, and modern OO languages evolved to
support design patterns like these that proved useful in earlier
languages.

You have enough information at this point to start
figuring out the details of most of the functions for LZWExp, but we
might spend a bit more time on LZWExpDecode, the most sophisticated
of them, before closing this lecture.
This function is called once for each 32 bits of
compressed data.  Reread the header comment for it, and review how
codes are embedded into ints in the LZW example from a prior lecture.
 Then answer these in-lecture questions:

Why does the header comment say that “one or
more codes” may result from a single LZWExpDecode call?

Because 32 bits of data may include
several codes.  Indeed, unless the codes have gotten pretty long,
there are almost certainly several per 32 bit integer.



OK, but won't there usually be some leftover bits
from each integer, that represent the start of an unfinished code? 
How do we “save” these as the comment indicates?  (Since 
state between function calls is held in the LZWExp struct, this
really amounts to asking which fields of the LZWExp type do the
saving.)

The fields bitsLeft and leftover do
this.


How they're used exactly is something you must
figure out, but here's one final question worth considering:

What relationship must exist between bitsLeft and
numBits, at all times during the decompression?  Name at least one
example of a pair of values for these two that would be impossible if
the code is working correctly.

Since bitsLeft tells the number of
bits left over after a 32-bit int is processed, this must be some
part of a full code, and thus must be strictly less than numBits.  We
could not, for instance, have numBits == 10, and bitsleft == 10.  If
we had 10 leftover bits, with codes currently taking 10 bits, we'd
have just used them up as a new code and been left with 0 leftover
bits.







	
	
	
	
	
	
	






In large projects,  the process of compilation
becomes so signficant that it's referred to as 
the project, rather than merely compiling it.  Software to track and
manage the build process exists in many forms on many different
platforms.  The main tool for Unix build management is 
the subject of this lecture segment


	
	
	
	


You need to understand the compiling and linking
process in order to understand what make does.  If you're not sure
what an object (a “.o”) file is, what the linker does, what types
of errors might occur during linking vs compiling, or why you don't
need to recompile every .c file in order to recompile the whole
program, then review the prior lectures on multifile C compilation
(Lander 9, for example).

Any complex C project comprises many C source
files and header files.  Recompiling all the source files any time a
change occurs to just one of them is prohibitively time consuming. 
Selective recompilation of source files is essential, and keeping
track of which files need recompilation due to a change, and which do
not, can be very complex. 

Different C source files include different
headers, and of course headers may include other headers, so a source
file can include headers both directly and indirectly.  Any change to
a .c file, or to its headers, means the .c must be recompiled (and
the entire application relinked from object files).  

In a typical large project with 1000 C source
files, a minor change to one header might require recompilation of
500 of those files, while changing a different header might require
recompilation of only 1 file.  Determining by hand which files are
affected by a change is practically impossible, and of course
error-prone.  Missing even one needed recompilation would leave an
object file that was compiled using an old version of a header or
source.  The bugs that result from this can be very subtle.  

So, every large software project uses some program
to track  such as the
dependency of a .c file on the headers it includes, or that of an
executable on the .o files that link together to make the executable.
  On Windows or Mac, projects often use IDE's like Visual Studio or
XCode.  On Unix, the tool of choice is make.


make
&lt;executable&gt; 


is the name of the program you want to build or rebuild.   The
makefile in our example manages two executables, 
and .
 To rebuild the former, we'd type
make
TestExp
But, make is complex to configure.  You must
describe to it all the build dependencies in your project: all cases
where file X must be rebuilt if file Y is changed.  And you must tell
it  to rebuild X.  All this is done via a
, a textual configuration file
describing dependencies and rebuild commands.


or Make
automatically looks for either filename.  (The capitalized version is
convenient because it usually appears before other noncapitalized
files in an “ls” listing.)
very
1970's.  It's textual, and has elaborate indentation and line
continuation rules.  There's a good example in the diagram.

The example starts with a comment line, marked
with initial #.  Any line or rightmost end of a line may be so marked
as a comment.

Certain strings, such as lists of file names or
command options, are often repeated throughout a makefile, so a
makefile allows string variables.  You don't declare these, you
simply just a value into them,  via simple assignment statements as
on lines 3-7, which create and assign variables CPP,
CPPFLAGS, etc.  (Variable names are capitalized by
convention.)  The value assigned is always a string, and there are no
quotes; the entire rest of the line is assigned into the variable,
spaces and all. The assignments must fall on a single line, though
you may escape returns with a backslash in a fashion similar to that
for multiline C macros (and with the same caveat regarding escaping
the return, not a space just before the return).  

In our example file, we set up a variable CPP
containing the command for C compilation, so that this may be easily
changed, another variable CPPFLAGS for the flags to apply to the C
compilation, and two for the lists of .o files that must be linked
for the two executables LZWExp and LZWCmp that the makefile is
configured to manage and build.
To use the value of a variable in the makefile,
you put the variable name in $( ..), e.g. $(CPP).  This seems really
awkward if you're used to using a variable name directly in a
programming language.  The reason for the notation is that makefiles
refer to many filenames, command names, etc. all of which might
coincide with variable names.  Since the number of non-variable words
is so large, it makes sense to require special notation to get a
variable's value.  (And, remember, make was designed in 1977.)


dependency rules, such as those on lines 9-16.  These rules
take the form:





is a file that might need rebuilding,  
is a list of files on which the target
build
commands is a list of commands that must be run (e.g.
compilations or linking) to bring the 
up to date, if any of the 
have changed.


And an
important note: the build commands must be indented, and must
be indented using a single tab, not spaces.  This
little quirk of makefile syntax is notorious, since it's hard to see
the difference between three spaces and a tab when reading the file. 
Watch out for this.


Make uses the last modification
dates of the files in question to determine if a rebuild is needed. 
If any of the 
files were more recently modified than the ,
or if the 
doesn't yet exist at all, then make does the build commands.


Lines 9-10, for instance,
indicate that executable 
is dependent on all of the object files in .
 If any of those object files have been more recently modified than
,
or if we don't yet even have a 
executable, then make runs the line 10 command, which relinks all the
object files to create a new executable.   (Replace all the various
variables with their values to see what command is actually being
run.)



Since we're running gcc, doesn't that mean we're
recompiling as well as linking?  And, what does the gcc -o option do?
 (This question is mostly a reality check to be sure you recall, or
have reviewed, multifile compilation basics.)

gcc is actually a “master program”
that runs the preprocessor, C compiler, and/or C linker, depending on
the argument files.  If you give it all .o files, it just links them.
 And if you want the executable to be other than “a.out”, you
give the desired executable name via the -o option.

So, when do the .o files get updated?  The
dependency rule on lines 15-16 controls the rebuilding of one of
them: LZWExp.o.  As you can see, this rule rebuilds LZWExp.o if
LZWExp.c has changed.  The command to do so is another gcc run, but
this time to compile the LZWExp.c file.

'Nother reality check.  What's the -c option for? 
(And, if you're having to look these up, do the
review lectures

The -c option compiles a .c file to
a .o file, without expecting a full program or trying to link
anything.


To complete the makefile, we'd need dependency
rules like the one for LZWExp.o, for each of the other .o files. 
But, in the next segment we'll see several ways to generate these
automatically, so let's let lines 15-16 be our one hand-built
example.

Each .c file is dependent on any header files that
it includes, in the sense that a change to the header amounts to a
change to the .c file.  So, a makefile should have dependency rules
showing this, as in the example for LZWExp.c on lines 18-19.
The build command for this rule, however, is a
little odd.  If a .h file changes, the .c file including it
automatically “changes”, and there's no action needed for that to
happen.  But, we do want to show the .c file as having been modified
so that it in turn triggers other dependency rules, like that on
lines 15-16.  The solution is the Unix 
command, which updates the modification times of any files given as
commandline arguments, showing them as modified at the current time,
as if they had been “rebuilt”, even though their content doesn't
change.  This command is suprisingly useful in Unix operations in
general, and is a good one to add to your repertoire if you haven't
seen it before.


make
&lt;target&gt;
must be one of the targets in a dependency rule,
e.g. 
 Make checks each dependency in &lt;target&gt;'s rule, and rebuilds
&lt;target&gt; if any dependency has changed more recently than
&lt;target&gt;
But – a critical point – make also checks each
dependency to see if it is a target of another rule, and rebuilds the
dependency if needed.  And this applies recursively, as deeply as
necessary.  So, if TestExp depends on LZWExp.o, and LZWExp.o depends
on LZWExp.c, and LZWExp.c depends on CodeSet.h, then if CodeSet.h has
changed, this triggers a  
on LZWExp.c, whose changed modification time then triggers a rebuild
of LZWExp.o, which thus changes, and in turn triggers a rebuild of
TestExp.  

In general if executable E is dependent on object
file O, and O is dependent on source file C, and C is dependent on
header H, then even if only H has been updated, this triggers a
cascade of rebuilds from H, to C, to O, and ultimately triggering a
rebuild of E.  

The dependency rules don't have to appear in any
particular order for this all to work; make figures it out regardless
of their order.  Visualize a make run as starting at some target, and
then branching out through all the target's dependencies, and all of
their subdependencies, and all subsubdependencies, etc., making a
tree of dependencies.  The make run then works back from the “leaves”
of this tree, doing rebuilds any time dependencies have changed more
recently than their target.  Any rebuild of a target A causes A's
modification date to change, which in turn triggers a rebuild of any
target B that depends on A, etc.

In some cases, a dependency rule is designed
without the intent to actually rebuild the target.  In this case, the
target is usually nonexistent, and remains that way.  The rule on
lines 22-23 is a good example.  There is no 
file, so the target always automatically needs rebuilding, even
though there are no dependencies.  The 
build command cleans up temporary files that result from other
compilations or links, and thus make
clean is a way to clear any existing object or
executable files.  Following it with a make
Test,
for instance, would cause a complete recompilation since all object
files are gone.  Since the build command doesn't update the file
“clean”, you get the same effect every time you run make
clean

The makefile example has two executable targets
TestExp and TestCmp.  I can trigger  a rebuild of either with make
TestExpmake
TestCmp.  I'd like, however, to be able to remake both
with the command make
all.  Add a dependency rule that would do this.  Don't
be surprised if it's really short.

This can be done with a rule all:
TestExp TestCmp  with no build commands.  Since “all” doesn't
exist, the dependencies are checked for being up to date.  Doing this
causes any needed rebuilds to TestExp and TestCmp. And since there
will still be no “all” file when we're done, the command will
work the same way every time I run it.



command, it makes the first target in the makefile, and a target like
this “all” target is often put first for that reason.
In the next segment we'll look at ways to set up
dependency rules without having to hand write them for each source
and header file.




	
	
	
	
	
	






Creating a full set of dependency rules for a
large project is both tedious and error prone.  Messing up even one
dependency, especially wrt a header file, invites occasional missed
recompilations of the affected source file, with attendant subtle
bugs.  In this segment we'll briefly review wildcard makefile
dependency rules, and automatic generation of makefile dependency
rules.


	
	


Listing a dependency rule like that on lines
15-16, for every .o file in a large project, can be pretty tedious. 
One simple way around this, at least for simple cases like making X.o
depend on X.c, is to use pattern-basedwildcard
, like that on lines
26-27 of our sample makefile.  The 
is a wildcard, so the rule makes any file X.o dependent on a
corresponding file X.c, where X may be any string.  In the build
command, you can use the awkwardly-named 
for the matched dependency file, and $@ for the matched target file.
Another good wildcard rule would be to show each
.c file as dependent on its corresponding .h file, as on lines 29-30.
 The build command for this rule uses ,
as discussed in the prior lecture.
Of course, C files are often dependent on more
than just their corresponding .h file, so we will still need rules
like that on lines 18-19, which enforces the dependency of  LZWExp.c
on all the other .h files it includes.  (System files like ,
by the way, are assumed unchanging and thus rarely included as
dependencies in a makefile.)  To automatically get more complex rules
like this, we need rule-generating software.

Any tedious, error-prone task, like makefile rule
dependency generation, is best done by automation.  It should be
possible to scan a C source file for 
statements and deduce from these the header files on which the C
source file depends, creating a dependency rule from them.
I could tell you that there is a well-accepted
standard tool for generating dependency rules from C source files,
but I'd be lying if I did.  Instead, there is a profusion of
different tools, from a very primitive 
utility in Unix, up to sophisticated hand-crafted scripts often
written for larger projects.  Generating makefile dependency rules
seems to be the sort of task that everyone thinks they can do a bit
better than the existing tools.  In keeping with this tradition,
we'll build a small example script of our own, to show how such tools
work.

Making our own script will be greatly simplified
by the fact that the 
compiler we use in our examples can help with this task.  Given that
the preprocessor is already checking for 
directives, it makes sense that a C compiler might offer some
assistance in generating makefile dependencies, and most dependency
rule generators rely on compilers to do much of their work.  The
command:
gcc
-MM &lt;file&gt;
prints out the first line of a dependency rule for
,
based on the s
in 
Here's an example, for instance, on the file LZWExp.c.  The generated
rule is actually for the .o file that would be created by compiling
LZWExp.c, with LZWExp.c and all header files shown as dependencies. 
This is an alternative to showing the .o/.c and .c/.h dependencies
separately.
All we need is the right build commands, and the
gcc output will be a complete dependency rule.  The small shell
script in the diagram adds these.  This is not a lecture on shell
scripts, but here's a brief summary:
i,
setting it to each commandline argument in succession. 
We'll run the script with .c files as commandline arguments.
 Run gcc with the -MM option on each
.c file ($i is shell-script notation for the value of variable i). 
Concatenate (&gt;&gt; operation) the gcc output to the end of
.
 And note, that's a tab, not spaces, before the ,
per the required syntax for indenting build commands.
 Run the echo utility, which simply
prints its commandline arguments, to output literally “ $(CPP)
$(CFLAGS) -c” preceded by a tab, and followed by the current file
name, concatenating all that to the end of .
 

Running this, as you can see, on a set of .c
files, adds appropriate dependency rules for each .c file to the end
of .
 I'll add those to the diagram, and then let's comment out all the
older rules in favor of these, and ask:

What commands will make run, assuming TestExp is
currently up to date, if we run touch
.h,


Recall that make without an argument
builds the first target, in this case TestExp.  And touching LZWExp.h
results in rebuild of LZWExp.o per line 37, and TestExp.o per line
43, but not of CodeSet.o nor SmartAlloc.o, which don't depend on
LZWExp.h.  So the commands are:

gcc  -w -DLITTLE_ENDIAN -c 
TestExp.c
gcc LZWExp.o TestExp.o SmartAlloc.o
CodeSet.o -o TestExp

Anyone accustomed to an IDE like Eclipse or Visual
Studio will no doubt find the awkward textual format of makefiles,
the need for handcrafted dependency rule generators, etc quite
“old-school” and outdated by comparison with the highly automated
build management of a modern IDE. 

At one level, this is a fair judgment.  But, it is
remarkable how many large complex projects eschew the simplicity of
using an IDE, in favor of creating their own build management tools,
often using the tedious but highly flexible 
command as a starting point, augmenting it with scripts to generate
dependency rules, etc.  

The reason for this is not attachment to old
tools, but rather the fact that a sufficiently complex project almost
always has subtle build requirements not accommodated by standard
IDEs.  These might include special compile flags needed only by
certain targets, complex dependencies requiring script logic, or
code-generation steps performed via script.  Also, very large
projects can overwhelm an IDE tool, making it run unacceptably
slowly.
So, using an IDE is fine, and even preferred, for
midsized projects with standard build requirements.  But knowing how
to use less-automated but more powerful tools like make and scripts
is sometimes indispensible.




	
	
	
	
	
	
	






There are a number of debugging tools that will
help you detect the most common “unlucky” C bugs.  Valgrind is
among the most popular of these, and this lecture segment will walk
you through a simple use of it.  



	
	


We'll be using valgrind to find errors in the
example code MallocMess.c.  This program has four major errors.  


,


On line 9 we copy a string of 17
characters (remember the '\0') into a block of 16 bytes.  On line 13
we abandon an unfreed block pointed to by block1, on line 15 we use
an uninitialized variable test, and on lines 15-16 we use a
just-freed block.


In typical C fashion, a run of the MallocMess
executable shows no problems at all; these four bugs are all
“unlucky”, assuming we expected 
to be zero.

So, let's see what valgrind has to say.  And note
the pronunciation, by the way, with a short i.  It's not some
contraction of “value grinder”.   The name comes from Norse
mythology; it's the term for the gateway to Valhalla – typical tech
intellectual whimsy.)

valgrind
MallocMess
You give the valgrind command followed by the name
of the executable you want to check.  Valgrind temporarily adds, to
the executable, code that checks for allocation errors, memory
overruns, and uninitialized values.  Then it runs the executable and
reports any errors detected by its added code.  There are many
additional commandline options you can give valgrind to do deeper
checks, but the default execution is sufficient for most cases.
As you can see from the run on MallocMess,
valgrind's pretty chatty.   It's not generally necessary to
understand everything it outputs, and it often outputs multiple
complaints stemming from the same error.  We'll look at how to
interpret the errors in MallocMess.c, in the diagram, where I show
them as a comment.

But, first let's fix an immediate problem.  If you
look at the error messages, the locations in our source at which they
occur are given in terms of binary offsets into the executable.  This
is not very useful.  We can get locations in terms of C source lines
if we add debugging information to our executable thus:

and then rerun valgrind.  The -g option causes gcc
to add, to the executable, information about the original source
code.  Such information is used by various debuggers, including
valgrind.

Our valgrind output now shows original source
locations, for instance in the first two errors regarding an invalid
write and an invalid read on lines 9 and 10 of MallocMess.c.  These
involve, again as valgrind output shows, the block allocated on line
8.  That's our 17 byte being first written past the end
in the strcpy, and then read by 
on line 10.


on line 15.  Getting reports on uninitialized data use is especially
valuable, as this is the sort of thing often missed in test.  It's
almost as good as coding in Java.


on lines 16-17 results in slightly different invalid read/write
errors, complaining about “free'd” data.  And these are repeated
for each offending read or write, all the way through the block (the
diagram drops those repeats).  As noted earlier, valgrind's not good
at recognizing when the same basic bug is being uncovered repeatedly;
you have to read through the repeat errors yourself.

And, finally, the unfreed block that was the
original target of 
is reported at the end of the valgrind output.  Valgrind waits till
program end to report leaked storage, since it can't be sure you
won't free the storage until the program is done.






	
	
	
	
	
	
	






In this lecture we'll go over the use of gdb, the
standard Unix debugger.


	Compilation with debugger
	information
	
	


We'll use the attached program Bad.c as a test
case for a gdb debugging session.  Note that it has three bugs: a
potential divide-by-zero error in ,
a failure to return a value from ,
(line 4 should read return
fb(b, a) 
 We'll imagine those bugs aren't obvious, and will use gdb to find
and diagnose them.


	It lets you run
	the program, under control of the debugger, including allowing
	commandline arguments and optional input and output file
	redirection.
	It reports the
	source code location of any faults, and lets you display the source
	at that point.
	It lets you print
	the value of variables or expressions at the point of the fault.
	It shows you the
	series of calls that led up to the fault.
	It lets you set
	breakpoints to stop execution at any point.
	It lets you
	automatically print the value of variables, without stopping the
	code, at any point in the execution, in the way you might do by hand
	with debugging printfs.



This topic will cover only items 1-4.  Items 5 and
6 are up to you to figure out if you like, but for reasons discussed
below, we discourage their use.
As with any lecture that walks you through an
application, it's very helpful for you to personally run the commands
we're showing, so please grab a copy of Bad.c, start up a Unix
session, and follow along as we go through gdb commands, by running a
gdb session of your own

The executable file produced by the C compiler
normally contains just machine language, but to track the source code
location of faults, to display the source lines in question, and to
print memory contents based on variable names, Gdb requires
additional debugging
information in the executable.  You add such
information to your executable by compiling with the 
flag, thus:

The resulting executable has debugging information
for gdb to use, and is also runnable just like an ordinary
executable, although as we already know, it has a few problems.

Try compiling Bad.c both normally, and with
debugging information added.  Roughly how big is the debugging
information, compared to just the machine language?  (Compare
executable file sizes.)

Trying it out on a local Unix
instance, it looks like the -g option increases file size by around
1/3.  Your results may vary.
$ gcc
Bad.c
$ ls -l
a.out
-rwx------.
1 grade_cstaley users 4990 Jan  3 15:24 a.out
$ gcc -g
Bad.c
$ ls -l
a.out
-rwx------.
1 grade_cstaley users 6538 Jan  3 15:24 a.out



Once the executable is compiled with debugging
information, you run gdb thus (the $ is a shell prompt):
$
gdb a.out
giving the executable as a commandline argument. 
This results in some initial banner lines, and a &quot;(gdb)&quot;
prompt.  At this point gdb is running, and has your executable
loaded, but hasn't started the executable yet.  You run the
executable with the 
command thus:
(gdb)
run
Your program now runs, as you can see, and the
behavior is the same as if you had run the program independently of
gdb, unless there is a fault. 

So, let's cause a fault.  I'll enter a 0 5, which
you can see will cause a division-by-0 on line 8.   What would have
been a simple fault without gdb instead becomes a gdb announcement of
the fault, including a listing of the offending line.

We can list the surrounding source lines via the
gdb command ,
which shows the lines surrounding the point of failure.

We can't cover
every gdb command in detail in this lecture, so I'd like you to do a
bit of external research, and determine how you might list other
lines of code
from gdb.  What parameters does 
take?  (A hint: gdb has a reasonably useful 
command.)

Gdb's &quot;help list&quot; command
indicates that you can add line numbers to the list command:  list
10, 40 would list lines 10-40.  Repeated list commands also give you
10 lines at a time in succession, which forms a sort of crude
scrolling capability.

To get the value of a variable or expression, use

followed by the variable or expression.  For instance print

gives 5, and print
c+
gives 47.  If a bug isn't clear, getting the value of related
variables or expressions often helps.   In particular, printing c/d
shows my division by zero error pretty clearly, as you can see...

command also saves each expression you print in a numbered set of
registers, so you can fetch the values back again, or use them in
further expressions.  As you can see, our first two print
results are save in $1 and $2.  We can reprint those,
or use them in other expressions via print
$
or 
+ 42

It's also useful to know what series of function
calls led up to a bug, and what the parameters of the calls were.  To
get a complete stack trace of all calls leading to the failure point,
use .
 This lists, in top-down order, each current function call, with
parameter values and the source line making the call.  Let's try that
here, and we can see that 
called ,
which in turn called 

Try it yourself now.  Restart the terminated
executable with another 
call (say yes when it asks if you want to restart the program).  Exit
the scanf loop in Run.c by immediately giving an EOF.  Diagnose the
fault that now occurs.  In particular, what line does it happen on,
what value got passed to ,
and what happens if you try to show the value of  p.

*p?

Doing a run, and then ending input
with an immediate control-D results in a different fault, this time
on line 14 in fc.  The where command shows that a large random value
was passed to fc since x is uninitialized in the main.  And printing
p shows it has a content of address 3, while printing *p results in
an error because that address is not accessible, thus the seg fault.


help
run to find out to run the program under GDB with
commandline arguments, or with redirection ofquit input and output.

You do the same things to the run
command that you would in a shell command, e.g.:  




lets you exit gdb at any time.

Let's close with a bit of discussion on the best
use of debuggers.  

Proper use of debuggers will save you a lot of
time.  A debugger is much faster than using debugging printfs in many
cases, and being able to quickly get the values of a few variables
surrounding a fault, and the chain of calls that led to the fault, is
useful.
But..  It's easy to become dependent on a
debugger, and suffer what we might term &quot;debugger hypnosis&quot;.
 The hallmark symptom of this is that you spend more time communing
with the debugger, setting up elaborate breakpoints, poring over
dumps of traces, etc. than you do .  This
can happen with debugging printfs, too, of course, but debuggers make
it a lot easier to fall into this trap.  You'll find bugs more
quickly, and get better at bug finding, if you get just a modest
amount of help from the debugger, and do the rest by reading and
thinking about your code
There are two other important reasons for not
becoming dependent on a debugger.  

First, in practice, some bugs happen only after
significant runtime.  While you can get stack traces and a few
variables of interest at the point of failure, you cannot tracepoint
your way into the failure when it takes minutes of runtime to reach
it.  And even worse, some bugs happen only intermittently under load.
 Websites in particular are famous for this.  You can't use a
debugger to find those.
Second, especially in C, some bugs do not even
show up under testing, at least on the system in question, and only
show up after porting or after code modifications.  Did you notice
that the missing return statement in 
never caused a problem?  That's because it accidentally happened that
the return value from 
wound up in the same stack location as 
missing return would have gone in, so it's as if line 4 had said
.
 But that will break as soon as you move the code to another machine.
 (Indeed, it may have done so on yours already.)  The debugger can't
help you find that one; you'll find it only by reading your code.
So, use gdb to about the extent we have in this
example, but don't become more dependent on it than that.




	
	
	
	
	
	
	






In this lecture we'll look at global variables in
C, in both general and static form.  General global variables are
heavily frowned upon in modern design, and forbidden by many style
sheets, but they still exist in legacy code.  Static globals, and
their close cousin static locals, are still acceptable design and
thus fairly common.


	
	


 is a
variable declared outside of any function, and shared by many
functions in common.  Line 5 of File1.c in our diagram gives an
example.  You simply declare a variable on an independent line of
code outside of any function, and the variable becomes the common
property of all the code in the program, and may be written to or
read by any function. As you can see on line 9 of File1.c and line 15
of File2.c, different functions in different files may access the
same global variable.  So a general global variable is a sort of
common blackboard for communication between any parts of the code.  

There are two forms of global: general and static.
 General globals like 
are accessible to all functions in the program.  But a static global
is available only to those functions in the file in which it's
declared.  Line 6 in File1.c shows a static global declaration, which
is just like a general global declaration, with the addition of the

keyword at the beginning. 


At first glance, a general global variable seems
highly convenient.  Instead of the tedium of declaring and passing
parameters between functions in order to communicate information, we
could simply declare some suitable general global variables, and copy
data to and from them in the caller and in the called function in
order to communicate information between the two.  The current state
of the program would be embodied in several dozen, or in larger code,
perhaps several thousand, general global variables, and all the
functions would manage this state together.
This design was in fact quite common in the 1960's
and 1970's, but it has fallen so far out of favor today that many
modern languages forbid general global variables altogether.  
Although the “shared pool of variables” model sounds attractive
at first, allowing  code in the program
to modify  general global variable proves
to be a recipe for chaos.  The different patterns of modification
that may occur when functions are called in various sequences becomes
too unpredictable.  

And, there is the added concern of accidental
modification.  A global variable may have the same name as a
function's local variable.  In this case, the local variable is used
instead of the global within that function.  But, imagine this
scenario:
You're working on a part of a million line
codebase, and you decide you need a global variable.  You give it a
suitable name:  say .
 (Seems like a good name for a global.).  Somewhere else in the
company is someone you've never met, working on an error handling
function that is only called once in a blue moon.  He's too
disciplined to use a global, but he does use a local variable called
, in
his function.  

.
 This is a perfectly common error, normally caught by the compiler. 
But, in this case, his use of 
defaults to your global, and compiles just fine.   And code he meant
to modify his local variable 
instead modifies your global .
 So, once in a blue moon, due to an unpredictable call of an error
handling function written by someone you've never met, your global
variable gets trashed.  This is a small example of the danger of
global variables, and of why they've been discredited.  In truth, you
could prevent this particular error by giving unusual, or
specially-prefixed, names to globals: global_x.
But this still doesn't eliminate the case where someone
deliberately modifies the global because they thought they knew what
they were doing, without consulting everyone else affected by it. 
“You mean I wasn't supposed to set 
to NULL in my error handler?  It sure seemed like the right thing to
do!”
You can think of a general global variable as
having a bullseye on its forehead, walking around saying “Please
modify me, anyone, any time!”  So, don't create them, and do try to
phase them out of old code you deal with.  Still, you will encounter
them when dealing with old code, and perhaps with old programmers.
A static global variable, by contrast, presents
much less danger since the only way to access or modify it is from
within the .c file in which it resides, and that's usually under 1000
lines of code.  Static globals can be safely used as a common data
item by a collection of closely related functions that reside in the
same file, and are worked on by an individual or a small team.  And
static global variables in different files may have the same name
without conflict, since which static global variable you get is
determined by what file you're in.

If we created a general global variable for each
100 lines of code, then in a 1,000,000 line codebase how many general
globals might we create?  How does this compare with the number of
commonly used English words?  What does this imply regarding unique
naming of globals?

We'd have around 10,000 globals if
we create one per 100 lines of a 1,000,000 line codebase.  This is
well above the number of commonly used English words, and suggests
that it might be hard to ensure that each global gets a unique name. 


Of course, a modern program avoids this by
eschewing globals.  But we'd also have 33,000 functions in a
1,000,000 line codebase, assuming 30 lines per function on average,
and they need unique names too.  Modern languages solve this issue
via “namespaces” or “packages”, in which function names are
grouped under larger names.  C lacks this feature, but it's common
practice to get a similar effect by standardizing on prefixes for
groups of related functions or groups of related globals.  For
instance, the user interface function names in a large project might
all have prefix ,
while the database functions would all have prefix .
 Different teams within the larger organization reserve prefixes for
their functions, and have free reign to choose the function names
after the prefix, without fear of conflict with other teams'
differently-prefixed names.

We've seen sample declarations of general and
static globals in File1.c.  For the static global, that's pretty much
the whole story; once declared as shown, it may be accessed by all
functions in the file.  But, the general global is more complex.  


examine other .c files.  This is a general principle of C compilation
– only one .c file at a time is considered.   So, a variable is
usable in a C source file only if it is declared in that file (or in
a header file #included by it).  If we want to use a general global
variable throughout a multifile C program, it must be present in
every .c file, either directly or by header file inclusion.  But, we
cannot simply repeat the global definition in every .c file; this
would imply multiple copies of the global, a different copy for each
file, which would result in a linker error.
Instead, a general global variable is defined in
only one file, for instance 
in File1.c.  In our discussion, let's call this the variable's home
file.  (That term applies only in our course; there's no
general term for the concept.)  In every other .c file that uses the
general global, there appears (usually via including a header file
with the needed line) an 
declaration of the global, e.g. extern
int file1Global, as on line 1 of File1.h, which is
included in both of the other two .c files in our example.  An extern
declaration does not create a new global variable; it simply
announces the presence of the variable in some other .c file, so that
we may use it.  The machine-language translations of such uses from
other files, as on line 15 of File2.c are left partially complete, to
be filled in by the linker when all the object files compiled from
various source files, including the variable's home file, are merged
into a single executable file.
In C and other programming languages, it's useful
to differentiate between a  of a
global variable or a function, which is the line that actually
creates the variable, or provides the function code, in the home
file, vs the  of a global
variable or function, which simply announces the existence of the
variable or function in some other file.  A declaration allows uses
of the variable or function to be checked, and partially compiled,
with the partial compilation filled in finally by the linker when the
home file is linked in.  Extern globals, and function prototypes, are
declarations, not definitions.
And, by the way, it's OK to have both an extern
declaration  a definition of a global in
the same file, as we do for 
in File1.c.  The compiler will forgive you, and ignore the extern in
this case.


in File1.c?

In the included File1.h.  The reason
for this “forgiveness” rule is that it allows a .c file to
include its own .h, as is often useful.


keyword fits naturally into this discussion.  Local variables, such
as 
on line 9 of File2.c, may be declared as static.  This changes their
behavior significantly.  A normal local variable loses its content
between two different calls of the same function.  It is, in effect,
uninitialized at the start of every function call.  But, a static
local retains its content between function calls.  If you put a value
into it in one call, that value will still be there on the next
function call.  In a very real sense (as we'll see in more detail
later) a static local is a like a global variable that can be
accessed only within the function that declares it.  So, it's
persistent in value like a general global, or a static global, but is
even more restricted in its use.
And, one side effect of this restriction is that
you must initialize a static local in its declaration, as shown on
line 9 of File2.c.  The initialization occurs just once, not every
time the function is called. (Indeed, the initialization takes place
before the program even runs.)  By contrast, using an ordinary
assignment to initialize the static local would reset its value on
each function call, eliminating the advantage of being able to retain
values from earlier function calls.

Now that we have all the basics in place, let's
trace the behavior of the main program in our example slide,
following the changes made to the two general globals 
and ,
the two (not one) static globals 
in File1.c and in File2.c, and the one static local 

First, note the initial values of all 5 variables.
 Then, check the first line of output.  
has incremented both 
and its 
The result shows in the output, and also shows that File1 has access
to ,
via the extern declaration it included from File2.h.

on line 8, showing that main has access to it as well, due to
inclusion of an extern declaration.  


illustrates that File2 code has access to file1Global
file2Global
has value 101 (after incrementation) because of main's
modification.  And 
has value 1, incremented from its initial value 0.  


Just to be sure you were listening earlier :), why
does 
now have value 21?  How did that get changed from the 11 on the
earlier call?

It didin't get changed.  This is a
different staticGlobal, the one confined to File2, which was
initialized to 20 and just incremented to 21.

and ,
we can see that the two general global variables continue to get
updated and used in common between the two functions, while the two

variables remain independent of each other.  And 
does indeed retain its value between function calls, as advertised.

We've seen in earlier lectures that functions may
return pointers to variables.  If 
returned an int pointer, do you think it would it be OK to return the
address of ?
What about returning the address of a nonstatic local variable?  Make
your best estimate of the answer, based on what we've said about
these two types of locals.

The fact that a nonstatic local
loses its content between function calls suggests that it “ceases
to exist” between calls, and this is true in essence.  (The exact
fact is that the memory area for a nonstatic local will be used for
other purposes between function calls.)  Thus, returning a pointer to
it is a bad idea, since the pointer's target would be obsolete upon
return.  But, returning a pointer to a static local is fine, since it
continues to exist between function calls.
You might have answered instead that returning the
address of a static local should be forbidden because it permits
modification of the static local from outside the function.  This
would be a reasonable surmise, but in fact C makes no such
restriction, so you can “get around” the restriction on access to
a static local by returning a pointer to it.  Indeed, it's not
uncommon for a function to configure some static local variable, and
then return a pointer to it for general use by other code.




	
	
	
	
	
	
	






This topic shows how to organize components of a
large C program in a way that reflects modern object-oriented (OO)
design.  This organization is often used in well-designed C programs,
and it also provides a vehicle to introduce several C language
concepts related to larger code.


	“Object” pointer
	parameter
	
	Mock constructor and
	destructor
	


The notes for this lecture show a program that
uses a linked list to store integers.  We have a List.h and List.c
file, following the design you've seen before for C programs.  The
header file 
gives the prototypes for the list functions, the 
struct type, and other supporting declarations needed by anyone who
calls the List functions.  List.c gives the function definitions.
But there's more going on here than just the
header/source file pairing.


pointer, but also a 
of nodes and an 
pointer used by  methods we'll
discuss later.  These are all in the 
struct, which illustrates a general pattern: declaration of a struct
to hold all information relevant to some data structure like our
list, possibly with supporting types like 
(more on 
below).  Be clear about the difference between the 
struct and the Node, by the way.  For each list, no matter how many
nodes it has, there will be just one 
struct.

In
an OO language like Java or C++, one declares a “class”, which is
a sort of augmented struct type, having fields (“member data”),
but also functions (“methods”) that work on the member data, and
are declared within the class.  C doesn't permit declaring functions
in a struct, but you can get a similar effect via the kind of
functions provided in List.h, each of which takes a 
* as its first parameter. These functions use the 
that you pass via that pointer as the “object” of their
operations, and they update its fields to reflect changes resulting
from the operation (e.g. ListAdd

the 
pointer to point to a new node).

This
type of design is how one does “object oriented” programming in
C: declare a struct type that has all the fields needed for the data
structure, and functions that accept, as their first parameter, a
pointer to the struct that they operate on.   Translating into
OO-speak:  the C struct type is a “class with only member data”,
and the functions are “methods that are explicitly passed their
object”.  


(This
is actually how things work under the hood even in an OO language
like Java or C++. Methods in those languages have an extra first
parameter silently and invisibly added to them to point to the object
that they are supposed to work on.)

You
will encounter well-organized C programs that follow the design
patterns just described, dating as far back as the 1970s. These were
the forerunners of OO design.  Modern OO languages evolved to support
these design patterns that proved useful in earlier languages.

Several of the functions in List.h have obvious
purposes.  
returns the number of integers presently in a List.  
adds 
to a List (we'll explain that third parameter in the next segment). 

removes 
from a List, returning true/false depending on whether 
was on the list. 

But the rest aren't so obvious. We'll discuss the
iterator functions (ListStart,
ListHasNext, ListCurrent 
ListAdvance) in the next segment.  For now, let's look
at 
and 
 

A complex data structure usually requires
initialization.  For ,
we need to set both the pointers to NULL, and the 
to 0.  We do this in ListCreate
on lines 10-13 of List.c.  And in ListMain.c, the
driver program to test our List  code, we declare an array of 3
,
and then on lines 13-14 we call 
on each of them to initialize them.
In OO parlance, a function that is specifically
devoted to initializing a data structure is a .
 OO languages let you declare constructors that are called
automatically, so you never forget to initialize, but the best we can
get in C is an initialization function like 
that we run by hand.
A complex data structure also sometimes needs to
be “cleaned up” when we no longer need it.  For instance, we need
to free all the nodes on a 
when we're done with the .
 
does this, as you can see in List.c lines 15-23.  On ListMain.c lines
33-34, we call 
on our 3 
before we end the program.
Again in OO parlance, a function specifically
devoted to cleaning up a data structure is called a .
 OO languages let you declare destructors that are called
automatically, so you never forget to clean up your data structure,
but the best we can get in C is a cleanup function like 
that we run by hand.

Scoping by Prefix

The
consistent use of&nbsp;&nbsp;prefixes
for the function names is an old-fashioned way to do what in a modern
OO language would be done with a language feature called namespacing,
or scoping.   

In
a big program, it's easy for functions to accidentally get the same
name, especially when there are many different developers, or when
code is included from many different organizations.  Function names
like Add,
Create,
invite such situations since they are names that multiple developers
might come up with independently.   Modern languages solve this by
grouping function names under “scopes”, such as the scope of the
class that declares them, or a “namespace” (C++) or “package”
(Java).
 Two functions in different scopes or namespaces may have the same
name without ambiguity, in the same way that two fields in different
C structs may have the same name without ambiguity.
No
such name scoping is allowed in C.  But, we can approximate it by
consistently prefixing function names with the name of the struct to
which they apply, so that they will not conflict with any other
function names.  Even in a very large program with many other
functions, it's a lot less likely that someone else will come up with

or 

ListMain declares and initializes an array of 3
s,
as already discussed.  It then does a loop that permits commands of
the form:
a &lt;list#&gt; &lt;numberToAdd&gt;
&lt;whereToAdd&gt;
where list# is 0-2, the index
for ,
numberToAdd is the value to add to that list, and whereToAdd is 0 for
the front of the list and 1 for the back.  (We'll discuss this last
parameter in the next segment.)



where list# is 0-2, and
numberToDrop is the value to remove from that list.



where list# is 0-2, and the
command prints out the number of items on the list, and the items
themselves.  (Again, more details on that for-loop in the next
segment.)



lists
+ list as the first parameter for every function call
except the 
calls.  That's odd-looking; explain exactly what is passed to the
function, and what type it is.

lists is the address of the first
list in the lists array, and lists + list offsets to the address of
the array element specified by “list”.  This is the address of a
list object, which is just the type needed to pass to a List *
parameter.


which gives a 
typedef without providing any fields at all for .
 This is a a
declaration that announces the existence of a type, but provides no
further details.  They most often occur for structs, and one creates
them simply by omitting the {}-enclosed field list.  The C compiler
reads this as “I'm going to have a struct Node, and a typedef Node
as well.  More details on that struct later...”.  The compiler
accepts this, but only allows limited use of the type in question.  

A forward declaration lets you declare pointers to
the type, like we do for fields 
and 
in 
but that's all.  Any use of the type's fields, calls of ,
declarations of variables of the type, etc. are not allowed with only
a forward declaration.  These would all require details on the
forward-declared type, while a pointer declaration does not.  Since
all we need in List.h is to declare 
pointers, the forward declaration is sufficient.  

If you want to do more with the type, then you
must repeat the 
portion, with full fields (though not the typedef), as you can see on
lines 5-8 of List.c.  Once this is done, then the 
type may be used without restriction in List.c.
Why would we do this?  Because it's a good idea to
minimize the amount of detail you put into a header file.  Users of a

don't need to know the details of the 
type; only the functions in List.c that work on the list need that
information.  Indeed, the only reason to mention 
at all in the header file is to declare 
pointers in the 
What's wrong with putting details in the header
file?  Two things.  

First, anytime a header changes, you must
recompile all the .c files that include it, since in effect those .c
files have “changed” as well.  As you know from earlier study
it's common in large multifile C programs to recompile only .c files
that have changed since the last compilation.  This makes builds much
faster.  Modifications to widely used headers, however, slow the
build process down by forcing recompilation of most .c files.  The
less detail you put in the header, the less likely it is to need
modification.  List.h, for instance, won't change even if we change
the details of Node.

Second, everything in a header file is publicly
available, since the file must be readable in order to be included.  
By contrast, the content of .c files is less public, and can even be
hidden entirely by supplying only the compiled version of the .c
file.  Decades of experience in software design has proven the value
of minimizing the amount of public information available about a data
structure.  This is not a matter of secrecy, so much as a matter of
reducing the amount that another programmer must understand about a
data structure, and reducing the temptation to rely on a particular
implementation which may change in the future.  If the user of our

class doesn't even see the content of our 
struct, s/he will not feel any need to understand it, nor be tempted
to rely on a particular 
implementation that might change in the future.
In more modern languages, one may declare fields
of a struct (or class) to be “private”, preventing their use
outside of the code for the class.  The closest one gets to this in C
is removing the details of a struct from the header, via a forward
declaration.


type a forward declaration, increasing the “privacy” of the data
structure.  The reason we need the full 
struct in 

in ListMain.c requires full information on the 
fields, since this determines the size of the 
elements.  Pointers to 
by contrast, could be declared with only a forward declaration.

,
apparently we need to use only 
pointers in ListMain.c.  Describe, generally, how you'd change 
to do this, and how you'd adjust the parameters to the List function
calls.  For now, assume there is a way to get 
objects dynamically allocated.  (That's the subject of the next
question.)

You'd need to make lists an array of
List pointers, not direct list objects.  And you'd pass the actual
elements of lists, e.g. lists[list], to the functions, instead of the
addresses of the elements, since they're already pointers.



objects to point to?  We adjust 
to allocate a 
object, and initialize it.


look like if we relied on it both for allocating and initializing the

object?  We'd no longer pass it a 
object to initialize, for one thing.  Rewrite the header as you think
it should look in this case.

There are two equally acceptable
choices.  We might simply return a pointer to the allocated and
initialized List object:

Or, we could pass a pointer to
ListCreate, for it to change, thus a double pointer:

Either way would provide a means of
getting a pointer to an allocated List returned from ListCreate.



Lists

call in main?

One good solution would be to adjust
ListDestroy so that it not only freed the Nodes of a List, but also
freed the List itself.






	
	
	
	
	
	
	






In this segment we'll continue our look at the
example 
struct, and introduce several other C language concepts related to
larger code.


	
	
	



declaration on line 12 of List.h.  It's often useful to use integer
values to represent one of several choices from a set.  Examples
might include the days of the week, or one of a set of possible
colors.  If we need to store, say, a day of the week in a C variable,
the standard approach is to assign a number to each day, usually
starting with 0.  So, perhaps Monday is 0, Tuesday is 1, etc.  Then
an int (or even a char) is sufficient to store which “day” it is,
in numerical form.  Likewise, if we must store one of a choice of,
say, 10 colors, we can assign numbers 0-9 to the colors, and store
the choice in an int.  When you think about it, the ASCII or Unicode
systems are doing the same thing: associating a series of integer
values with a set (characters) that is not inherently numerical, and
using a number code to represent each item in the set.
enumeration.
 In a well-written enumeration, you declare a series of
#defines or constants rather than just using raw integers, e.g. 






or 








You can do it this way in C,
but C, like many other languages, offers shorthands for setting up a
series of integer constants as an enumeration.   One may write
instead:


enum {MONDAY, TUESDAY, WEDNESDAY, THURSDAY,
FRIDAY, SATURDAY, SUNDAY};
and this will create 7 integer constants, with
values starting with 0 (for MONDAY), that you may then use in the
program.

declaration is more than just a constant-creator.  It's also a type
declaration, somewhat the same way that 
is a type.  Line 12 of List.h declares an enum with just two options,
for which end of the list to add a new item to.  But, it also uses
the enum to create a typedef ,
which we use to declare parameter 
of 
Technically, a variable of enum type, may only be
assigned values from the enum list, e.g. 
would be assigned only values 
or .
 In some languages this rule is strictly enforced, but C, in typical
fashion, will admit that a variable that stores an enum value is
really just an int, and you may treat 
as an ordinary int if you like.  The type 
should be read as “This is really an int, but I plan to use it to
hold values from a particular enum list.”
And, the “this is really an int” bit shows
most clearly in input and output.  As you can see on line 18 of
ListMain.c, we use a %d format specifier to read ,
a variable of ,
and we must enter 0 or 1, not “LIST_AT_START” or “LIST_AT_END”.
 The same goes for printing enum-type variables: you use %d and you
get the raw numerical value as output.  While the enum concept
extends across dozens of languages, it's usually a very thinly
disguised int, especially on input and output.  (Java is a notable
exception.  It boasts a highly sophisticated object-oriented enum
system.)
All this said, it's still good style to use enums
when you have a set of related integer constant values, and to set up
an enum typedef to declare integers that store one of those
constants.

Another common concept in modern design, and
doable also in C, is that of an . 
In earlier lectures on linked lists, we had functions that looped
through the list, for instance printing all the items in the list. 
But these were one-purpose functions.  It would be useful to have
some general way to loop through all the items in a list under the
control of the caller, so that the caller can do to each item
whatever it would like, perhaps printing them with a particular
format, or totalling them, or some other operation.  

To do this with proper abstraction, we need
functions that the caller can use to start an iteration, to test to
see if the iteration is done yet, to retrieve each item in turn, and
to advance to the next item.  In our example, these are respectively
ListStart,
ListHasNext, ListCurrent.
 These functions use and update the 
field of the List. 
ListStart
to the first node (if there is one).  
returns true if 
is non-NULL, so we haven't run off the end of the list yet. 

returns the data in 's
target, and 
moves 
to the next node.  The field 
thus becomes a sort of loop pointer, which we can initialize and
advance via the function calls, as we do in the for-loop on lines
27-29 in ListMain.c.  Review the code for that loop, and the four
functions (ignore those “assert” calls for now), to be sure you
see what's going on, and then answer these two questions.

Do this loop and the four functions work even on
an empty list?  What exactly happens if we run the loop on an empty
list?

Yes, they work.  ListStart will set
“at” to NULL immediately.  ListHasNext will return false, and the
for-loop will exit without iterating.



Can I run two different iterations at once with
this system, with the two iterations at different points in the same
list?

No, there's only one “at”
pointer, so you can only be at one place in the list at a time. 



This second question shows a weakness of tracking
an iteration via a field internal to the data structure, like .
 The specific term for such a design is an internal
iterator.external
iterator design that provides a separate struct type, say
,
that has the 
pointer.  You can create and use as many ListIterators
simultaneously as you like, each representing a
different point in the List.  Details of external iterators are
beyond this design discussion, so that's as much as we'll say here.


calls on lines 74 and 80 of List.c illustrate one of the most
critical reliability tools in the C language libraries.  Including
file ,
as on line 2 of List.c, gives you access to the 
function (technically a macro, but we'll call it a function).  You
call this function, passing it a boolean test, of any form that would
be usable in an if-statement.  If the test is true, the function
returns without action, and the program goes on.  If the test is
false, then 
immediately ends the program, with an error message reporting the
file name and line number on which 
was called, and the test that failed.  This is far more useful than
C's usual “Segmentation fault”.

to check conditions that should always be true, and which represent a
bug if they are false.  Don't use it to check user input, for
instance.  The rule of thumb is: “If this assert fails, I'll be
modifying my code to fix a bug.”  But, a “bug” can include
misuse of a function.  The contract for 
and 
requires that 
be true – that 
is not NULL.  So, it's a good use of 
to verify this assumption, and to report a useful error if the
assumption is violated.  That would count as a bug in the code.
Learn to use asserts, frequently.  They will save
your life when debugging C code.  Any time you get a queasy feeling
after some long sequence of logic, and you're thinking “This is
gonna break...”, it's time for an assert, verifying any condition
you think should hold at the end of your logic.

,
and write an assert regarding the state of 
and 
just after the end of that loop.  The test should be in two parts,
||'ed together.

A good assert here would be
assert(prior == NULL || prior-&gt;next == temp).  If toDrop is the
first item on the list, or if the list is empty, then prior will
never be changed from NULL.  Otherwise, prior should be pointing to
the node before temp, and thus prior-&gt;next should equal temp.




	
	
	
	
	
	
	






In this segment we'll finish our look at the
example 
struct, and introduce several more C language concepts related to
larger code.


	
	


Allocating and freeing nodes is very
time-expensive, because the management of the runtime heap is
complex.  To reduce this expense, some programs maintain their own
private recycling system for commonly allocated types, like our .
 Whenever we would free a ,
we might instead keep track of the unused 
ourselves, without releasing it, and later when we need a ,
we could first use one of our tracked unused s
if we have any, resorting to an actual 
call only if there are no recycled s
available.
?
 The simplest way is to chain them all together in a list.  This is
not a list of actual data; it's a list of unused 
awaiting reuse, and it's called a .
We don't care about the data in the 
on the freelist; it's just a parking lot for unused 
– a string of empty bottles, figuratively speaking.  

When we no longer need a node, we add it to the
freelist instead of freeing it.  If the freelist has nodes on it,
then when we would allocate a node, we instead take one from the
freelist and use it.  If the freelist is empty, we malloc the node in
the usual way.   Once we get a freelist going, if we are freeing
about as many nodes as we allocate, we'll get all the 
we need from the freelist, and rarely do an malloc call. 

Taking nodes on and off the freelist is much
faster than 
and 
because those functions must deal with any size of allocated block,
and must maintain the elaborate headers and other runtime heap data
structures for doing so.  If we're allocating and freeing many
instances of exactly the same type, then a freelist is much faster.

Let's modify our List.c file to use a freelist,
and illustrate some design ideas along the way. 

A freelist, like any list, needs a head pointer. 
At first glance, we might add such a head pointer -- call it 
– to our 
struct as a fourth field.  This would work, but it would mean that
each 
variable would keep its own freeList, and that if one 
had 
to spare, another 
would not be able to take advantage of them.  Better to arrange a
“community recycling system” with just one 
head pointer, pointing to a single freelist that is shared by all
,
and can be drawn from by any 
when it needs a 

If we want such a shared list, where and how would
we declare ,
its head pointer?  


We'd make freeList a static global
variable, in the List.c file.  All the ListXXX functions would thus
have access to it in common, and there'd be just one freelist.


So, we add such a static to our List.c file, and
set it to NULL for an initially empty freelist.
Now we need to modify any point where we malloc or
free a 
to instead use the freelist if possible.  We could hand-modify each
case, but it's better to create functions we'll call 
and 
to replace the 
and 
calls.  All the freelist logic can go in those functions.
.
 It's passed an unneeded ,
and adds it to the front of the freelist.  This is the simplest
option, since it doesn't matter what order the unused 
appear on the list – one empty bottle is as good as another. 
Everywhere we called ,
we now call 

Write the code for freeNode, so that it adds the
node passed to it to the beginning of the freelist pointed to by


void
freeNode(Node *toFree) {
  
toFree
  
freeList = toFree;




is a little more complex.  If the freelist has nodes, we want to
remove the first one from it and return that .
 But if the freelist is empty, we want to do a standard 
call and return the result of that call instead.



Here's
one possibility:


Node
*newNode() {
   Node
*temp;
   

   if
(freeList) {   // Remove first Node from freeList
     
temp = freeList;
     
freeList = temp-&gt;next;

   else  
              // No freelist nodes.  Allocate one for real.
     
temp = malloc(sizeof(Node));
	  

   return
temp;




calls with 
calls.

How big would the freelist be after this series of
input commands?  How many real calls of malloc would have been done?
(Note the different list numbers; we're working with all 3 lists in
ListMain.c here.)











We'd end up with 1 on the freelist,
and only 3 malloc calls, despite doing 5 adds. The first two 'a'
commands allocate Nodes for real, since the freelist is empty.  Then
the first 'd' command adds a node to the freelist (from list 0), and
the 'a' that follows it uses that node to add to list 2, with no
malloc.  The fourth 'a' command does a real malloc, but that's the
last one we'll need.  The two 'd' commands that follow put two Nodes
on the freelist, and the final 'a' command uses one of those nodes. 
(Note that it will actually use the Node that came from the 'd' on
list 0 just before, but a Node is a Node, and the whole point is that
the lists are sharing the recycling system.)
And let's make one more tweak to our freelist
functions.  These two functions are only needed within List.c; they
should not be called nor relied upon outside of that file.  We can
thus omit their prototypes from List.h.  But, even this doesn't
prevent someone from noticing them and declaring their own prototype
in order to use them from some other place in the code.  To strictly
limit 
and 
to List.c use alone, we add 
to their declarations.  The 
keyword is getting a lot of usage, but if you think about all the
cases: static global variables, static local variables, and now
static functions, the 
modifier always means “global, but limited to the current file or
function”.  Perhaps “limited”, or “restricted” would have
been better keywords for this, but “static” is what we're stuck
with, and like so many other C features, this one appears in many
other languages, with that same keyword.
And, by the way, you may have noticed we didn't
add the “List” prefix to 
and .
 We don't need to because a static function's name will not clash
with same-named functions from other files.  Its name is only known
within the .c file in which it appears.

In certain cases, a freelist can accumulate a lot
of nodes, and we may want to clear it of all its nodes, actually
freeing them.  This is also useful at the end of a program, if we
want to ensure all storage is freed.  We might make a function that
does this, and call it at the end of main
for instance.  Consider what it would take to add a
function to List.c to do this.  Don't write the code just yet, but
start with this question:

What parameters and return type would a
freelist-clearing function have?  In particular, would we pass it a

like all the other 
functions?  Would its prototype go in the .h file?  Would it be
static?  Would its name need a “List” prefix?

The header would be void
ListClearFreelist(), with no parameters.  The freelist isn't the
particular property of any List, so we don't need to tell
ListClearFreelist which list to “operate on”.  And its prototype
does appear in the .h file, since we call it from main.  And, that's
also why it needs that List prefix; it's not static.



Just to be complete, fill in the code for


It looks very much like the code for
ListDestroy, in fact, but it works on the freeList pointer instead of
some List's head pointer.


ListClearFreelist is different from the other
ListXXX functions in an important respect.  It “belongs” to the

family and thus deserves its prefix, but it works on static global
data that is the common property of all 
variables, and thus is not passed a specific List
*.
and 
are the same way, though the static modifier makes them private to
List.c, while 
is included in List.h, and called from outside List.c.
Here again we have an OO concept that we can
imitate with C.  (If you're not familiar with OO languages, it's OK
to just get the general impression here; this last paragraph is
optional material.) OO languages let  you declare member functions
“static”.  (That keyword  get
around, and in this case it has a somewhat different meaning.)  These
are functions that work with data, like our ,
that is shared by all objects of the type, and they do not work on
any particular object.  Such shared data is also termed “static”
in OO languages.  So, if you know about static methods and static
data in Java or other OO languages, you can mimic them in C using the
patterns we discussed in this lecture: make the static data into
static globals in the .c file, and the static methods into functions
that don't take a specific object pointer to work on.







	
	
	
	
	
	
	






runtime
stack – the area of memory that stores local variables and
parameters for active function calls.


	
	Stack Frame or Activation
	Record (v)
	


We've looked at the runtime heap, from which
dynamic storage is allocated, and we've discussed global variables.
Now let's look at where function parameters, local variables and
return values reside in memory.

The simple approach might be to reserve a fixed
memory location for each local variable and parameter, like we do for
each global variable, each string constant in the string table, etc. 
This was even implied in earlier lectures, where we showed local
variables residing at a particular memory location.  Such an approach
was in fact used in early programming languages, but it has two
distinct problems.
First, it's wasteful.  A big program might have
10,000 functions, but at any given time during the program, we are
running just one function, and there is a sequence of function calls,
starting at ,
that arrived at the currently running function, with all the calls in
that sequence waiting for a subcall to return.  These functions are
the only ones whose local variables and parameters need storing,
since locals and parameters only last as long as the current function
call.  Let's call these running or waiting functions the active
functions.   Even in a 10,000 function program there are
typically only a dozen active functions at any time.  The storage
space for the locals and parameters of the 9,988 inactive functions
would lie idle and unused.

Only a dozen active functions out of 10,000?  Why
so few?  Think about this, and answer the question: what kind of
function calling pattern would be needed to have, say, 1,000 active
functions?

You'd need to have main call
function A, which calls function B, etc. -- a series of calls 1,000
functions deep!  Possible, but unlikely except if you're calling
recursively, which we'll discuss in the next segment.
(The alert reader at this point may ask “What
about static locals?  Don't they have to be stored even when the
function that owns them is inactive?”.  Good question: they're an
exception that we'll get back to in a bit; for now, let's assume
we're talking about just standard local variables.)
The second problem with the fixed-location model
for locals/parameters is that a recursive function will have several
active instances  at the
same time, each calling the next.   And each active call needs an
independent copy of the local variables and parameters.  A
fixed-location model can't accommodate that.

Instead of fixed locations for each local and
parameter, almost every modern language reserves an area of memory
called the )
that stores all local variables and parameters for active functions. 
Each active function gets space in the RTS for its parameters and
locals.  The RTS starts with just the locals and parameters for ,
as diagrammed.  The layout of a function's memory area in the RTS
varies per compiler and language, but typically the parameters are
grouped together, as are the local variables, along with other
content we'll discuss in the next segment.

Look at the output from lines 39 and 40 in our
sample code, and answer: Are the parameters adjacent to each other,
and are the local variables adjacent?  Which is “above” (earlier
in memory than) which, and is there any space between them?

The addresses for argc and argv,
each a 4-byte value, are adjacent, as are the addresses for local1
and local2. The parameters are below the locals.  And it looks like a
16 byte gap between the end of local1 and the start of argc.  



The area of memory on the RTS for one active
function is called a , or
alternatively an .  (The
latter is a very academic term.  Using “activation record” in an
industrial software development shop will mark you as fresh out of
school – prefer “stack frame”).
Look also at the output from line 42.  Variable

is clearly in a very different area of memory from the RTS.  Globals
don't reside on the RTS; they're at fixed memory locations, in a
separate memory area reserved for them.

fa,

parameters and locals, while still retaining the space for 
data, which will be needed upon return from .
  So we add a new stack frame for the call of ,
putting it above the frame for 
on the RTS.  This stack frame exists for as long as the 
call runs, and it “goes away” after the call of 
returns.
(In our example, as we add stack frames going
upward in the RTS diagram, we are actually using lower memory
addresses.  This is fairly common in RTS layouts -- the RTS “grows”
from higher to lower memory addresses.  We'll use the terms “above”
and “below” relative to the RTS diagram, with the understanding
that “above” means “at lower addresses”.)

Use the output of line 9 to tell how we should
draw 's
locals and parameters within fa's


It's rather like those for main. 
The parameters are together, lower in the stack frame than the local,
with some space between them.


returns?  The RTS returns to its original configuration with just

stack frame, and main resumes its execution after the 
call.  


returns a value.  The 
statement on line 12 must put the return value somewhere in memory. 
In most RTS systems, the called function puts its return value at the
bottom of its stack frame just before returning, and the calling
function expects to see it there upon return from the called
function.   So, between the return from the call of 
on line 44, and the assignment of the return value into 
on that same line, 4 bytes of 
stack frame remain as a sort of residue above 
stack frame, holding the return value.  After line 44, the return
value is no longer available, and 
stack frame is totally removed.
Second, what do we mean by “removed”?  Clearly
the memory above 
stack frame still exists, and it's not overwritten with zeros or
anything like that.   How was it “removed”?
The running program keeps track of the location of
the current stack frame, generally in a CPU register that's not held
in memory at all.   Let's call this the top of stack or
TOS
the TOS points to the first byte in 
stack frame.  After the call, it points to the first byte in .
 All local variable and parameter memory accesses are made relative
to the TOS pointer.  So, for instance, the machine language to get
variable 
looks at some offset relative to TOS, rather than at a fixed
memory location.  We “remove” a stack frame simply by changing
the TOS pointer.  The memory content of the old stack frame is still
there, but is just garbage data above the TOS pointer.  This matters
in later discussion, because it can be the source of interesting
bugs.
(An aside here for those who may be familiar with
the standard “stack” data structure, which has very strict access
rules, in particular allowing one only to examine the very top item
on the stack.  The RTS is a sort of sloppy stack.  It grows and
shrinks by adding to the top and removing from the top, like any
other stack, but you are allowed to “reach down” into the RTS as
needed to get to any data in the topmost stack frame it at any time.)

.
 Look at the addresses output from line 19, which dumps the local
variables' addresses.  Two things stand out:


relative to the addresses of data in the prior stack frame for ?
 (Ignore fbLocal2
for now; that's the next question.) What does this
suggest about the location of fb's


It's in the same area as fa's locals
were, which indicates that fb's stack frame overlaps the area where
fa's stack frame was.

just adds a new stack frame above ,
using the same area as the old 
stack frame.  (The two stack frames don't overlap perfectly since
they aren't the same size: 
has no parameters for instance.)

?
 You can see in the output that it's at a very different address from
?
Is it even on the RTS?  What other variable is it
closest to?  


It's not on the RTS; it's about 2
million bytes below it, and in fact is right next to variable global.
 It's a static local, a very different thing from a standard local.  

In earlier lectures we said that a static local is
in essence a global variable that is accessible only within one
function.  The memory layout we see here reinforces that: static
locals are stored with the global variables, and they thus can
continue to exist even when the stack frame goes away, so their
values persist between function calls.

The printf on line 20 shows 42 as its output, but

is uninitialized.  Where did that 42 come from, and what does this
suggest about the origin of the uninitialized data in local
variables?

Look at the addresses for faLocal
and fbLocal1. They're at the same memory location, because of the
stack frame overlapping just discussed.  The old garbage data from
faLocal shows up as uninitialized data in fbLocal1.
So, the old garbage from a prior call can show up
in uninitialized locals in a later call.  And of course just which
garbage you get depends on what was called just before you – highly
unpredictable.

from 
on line 21.  This adds a third stack frame, for 
on top of that for .
 Check the addresses for 
parameters and locals now.  They're lower in memory than on the first

call, and thus “higher” on the RTS.


needs to go to a different memory address on each call of 
depending on the stack frame's location, which depends on what
functions were called on the way to .
 How does it do that?  How can it know what prior calls were made
each time?  This is an “are you listening” question: the answer
was just discussed earlier.

All nonstatic locals and parameters
are accessed relative to the TOS pointer which always points to the
top of the current stack frame, no matter where that stack frame is. 
So fa's machine code doesn't use a fixed address for faLocal, it
instead uses something like “4 bytes below the current TOS”.

returns, we go back to just the stack frames for 
and ,
and when 
returns we go back to just the stack frame for main.
In general, during a long program run, the RTS
constantly grows and shrinks, adding new frames as functions are
called, and dropping them as functions return. 


fb

statement, even though has 
return type, and line 46 prints its returned value – apparently 43.
 Where did that 43 come from?  What does this suggest in general
about omitted 
statements?

Recall that the area just above the
current stack frame holds the return value from a just-finished call.
 Line 45 is looking in that area for fb's return value.  But fb never
put anything there, so the 43 from fa's return is still sitting there
as garbage.
If you turn on the right warning flags, a good C
compiler will let you know you omitted a ,
but it's only a warning, not an error, and it's an easy mistake to
make.  The result is that you return garbage, probably a leftover
return value from a prior function call.
OK 





	
	
	
	
	
	






In this segment we'll finish our overview of the
RTS, looking at recursion, register storage, and other details.


	
	Three
	
	
	Buffer overflow attacks
	(v)



function on lines 24-33.  (We assume that you understand the basics
of recursion from prior study.)  This function computes the factorial
of its parameter, e.g. 4*3*2*1 = 24 for the example call of
.
 For any val greater than 1, it does this by calling itself on line
31, with a smaller number.  Let's trace the example call:

calls ,
which calls ,
which calls factorial(1).
This last call finally stops passing the buck,
returning 1 to factorial(2),
which multiplies the 1 by 2, returning 2 to
,
which multiplies in its 3, returning 6 to ,
which finally multiplies in the 4, returning 24 to .
 So we get a chain of factorial calls, each returning its respective
factorial value, ultimately returning to 
It's critical that each call act independently,
with its own 
and .
 In particular, one should not think of a recursive function call as
jumping back to the top of the  call,
like some half-baked loop.  Each recursive call begins an entirely
different instance of the function.  This isn't to say that the code
is duplicated, of course: all the instances have the same code.
But they have different stack frames.  And this is
what makes them distinct calls.   As you can see in our diagram, the
call of 
results in a 
stack frame with 
containing 4, and ultimately with 
that will contain 24.  This in turn calls ,
creating a new stack frame, with 
holding 3, etc.  When we get to factorial(1),

stack frame.  From there they return as we traced, reducing the RTS
back to just the stack frame for .
 Be sure you see that recursion generates a cascade of stack frames.

base
case )
and just do the recursive case.  If we dropped the if, and reduced

to just lines 31-32, the result would be a long quiet silence when we
ran ,
followed by a runtime fault.  What would be happening during the long
quiet silence?

The RTS would be filling up with
stack frames, since each factorial call would result in another, with
progressively lower (even negative) val parameters.  The RTS isn't
infinite.  A typical RTS might be able to hold 1,000,000 frames. It
takes a bit of time to fill it up with that many frames, at which
point you get a fault.


factorial
base case for which it simply returns an answer without further
recursion, and each recursive call reduces the problem size by 1,
thus driving toward the base case so the recursion eventually stops. 
But, what would happen to the RTS if we called factorial(10000000)?


Considering the just-mentioned fact
that an RTS might allow around 1,000,000 frames before overflowing,
even a “correct” recursion may still overflow the RTS before it
bottoms out.
This is important.  In academic discussions of
recursion the essential elements of a good recursion are supposed to
be:

2. Must make recursive calls
that move toward the base case.


But, an industrial recursion has a third
requirement.
3. Must not call too deeply, since the RTS is
finite.

argv
parameter is obviously on the RTS.  But what about the
block of pointers to which it points?  Is that dynamically allocated
on the runtime heap?

Consider the output of line 49.  What does that
say about the question just posed?

It indicates that the block of pointers itself
(the starting address of which is the value of 
is in the same area of memory as the parameters, so that block must
be in 
stack frame along with 
itself. 

That's fairly typical for commandline parameter
target data; it's often just jammed into the bottommost stack frame
as part of setting up the program.

We alluded earlier to other stack frame content
aside from the parameters, locals, and return value.  Any state
relevant to a function call may be stored in the call's stack frame. 
For instance, a function needs to know what point in machine language
to return to after it's called.  Fa
might be called from line 44 or line 21.  When it
returns, it's expected to jump back to the point just after the call,
to resume execution in the caller.  That location is placed in its
stack frame by the caller and used when 
returns.
Any CPU has registers that hold current working
data, such as the value of temporary computations or of heavily used
variables.  When a function is called, the register contents being
used by the caller often must be saved so that the called function
may use the CPU registers for its own purposes.  The caller's
register content goes in the stack frame, for the called function to
restore upon return.
A more complete list of typical stack frame
content thus includes:


3. Saved register content from
the caller
4. The location in machine
language to return to
5. A spot for the return value,
at the bottom of the stack frame


The order will depend on the compiler; don't count
on any particular order.  But, those contents are typical.

A function call takes so little source code,
perhaps just part of a line, that it's tempting to think of it as a
simple operation.  But consider the overhead required to make the
call.  Entirely aside from running the function itself, we have:
1. Adding a new stack frame
(changing the TOS pointer)
2. Copying parameter values
into the new stack frame
3. Saving registers into the
stack frame
4. Copying the return location
into the stack frame.


6. Saving the return value into
the stack frame
7. Restoring the caller's
register content
8. Dropping the current stack
frame (reducing the TOS pointer)
9. Jumping back to the return
location.


That's a fair bit of work, so it's reasonable to
view a single function call as having overhead similar to several
lines of code.   Reducing the number of function calls can be
essential to code efficiency in certain cases.

Let's close by looking at the most common source
of security holes in C programs.  Consider the example code here
void
SittingDuck() {
char
buffer[10];


scanf(“%s”,
buffer); // Please don't enter more than 9 chars...



What happens if a malicious user doesn't honor
that pleading comment, and instead enters a much longer string than 9
chars.  Assume they might even enter one with non-ASCII values, so
they can induce your code to read arbitrary bytes into memory past
the end of .
 


What, generally speaking, will get trashed?  What
data lies after the end of 


is a local variable, and is thus in 
stack frame.  The data after it might be 
saved register state, other local variables if there were any, and,
critically Indeed, if
the input is long enough, the overwrite might even reach down into
lower stack frames.

invites a caller to write whatever they like into the current stack
frame and the frames below it.  A sufficiently clever and malicious
user might even write data in the fashion shown in the diagram,
containing machine language code, and a value overwriting the return
location that jumps instead into the introduced code.  Now, when

returns after the ,
it jumps mindlessly into the code provided by the user, and suddenly
your program is running externally-provided code.
buffer overflow
attack, and it remains one of the most common sources of
security holes to this date.  Generally that 
is instead some code that reads information supplied over the
internet from another program, and sloppily neglects to check whether
the data being transmitted exceeds the buffer space provided for it. 

The lesson is to always check any data provided
from outside your program to be sure it doesn't exceed the size of
the memory space you're copying it into.








	
	
	
	
	
	
	






This lecture segment covers the use of the
preprocessor #
directive and its relatives.  This directive is often used in large
codebases to manage compilation for different machines, to prevent
multiple file inclusion, and for other purposes.
As a prerequisite to this segment, you must
understand what the C preprocessor is, as opposed to the compiler,
when the preprocessor runs, and how this impacts the source code the
compiler actually sees.  Review early phases of the Lunar Lander
example, if needed.


	
	
	Conditional compilation
	(v)
	
	
	



example code, which begins with three preprocessor directives: a

and two s.
 As you know from prior review:
1. These directives will be done
by the preprocessor.  




directive will merge the entire content of 
into your source, and the first 
will replace all occurrences of 
with .
 



3. The code resulting from these
preprocessor directives is what the compiler sees and compiles.  It
does not see, nor compile, your original source directly.  



4. can see the result of this
preprocessor work via the 
compiler flag.


#define
INIT
which has no value for the INIT string.  This

will replace all instances of 
with nothing at all, but that's not its real purpose.  As we'll see
shortly, there are preprocessor directives that check whether a given

has been made at all, regardless of the value to be substituted.  To
support these directives, one often writes flag
defines: 
that declare a define string, with no substitution value.  The mere
existence of the flag define is sufficient; its value doesn't matter.

So, what preprocessor directive uses flag defines?
 Check out the s
on lines 10 and 13, and their partner s
on lines 12 and 16, respectively.  These look a little like
preprocessor if-statements, and so they are.  An 
takes one string argument, like DEBUG

for this string, either a flag define or a normal one, has been
encountered already, then the ifdef
#define

must already have been executed by the preprocessor.)

is true, then the code between it and the matching 
appears in the preprocessor output and is seen by the compiler.  But
if the 
is false, that code is omitted entirely by the preprocessor, and the
compiler even never sees it.  This ability to selectively include or
disclude segments of code from the compilation is called 

In the example file, the compiler will never see
the code on line 11 inside the #ifdef
DEBUG#define
DEBUG.  But, it will see lines 14-15, by virtue of the
flag define for 
on line 4.

Let's check this out by running a -E compilation. 
As you can see, we get first the very large, and largely unreadable,
content of ,
plus any header files it might in turn include.  (Recall that
includes are recursive – if an included header has 
within it, the preprocessor includes those as well.  That will be
important in our next segment.)  In the code we wrote, the
preprocessor substituted DIM
with 10, as expected.  And, per the conditional
compilation rules, the preprocessor drops line 11 entirely, but keeps
lines 14-15.

There are quite a few preprocessor directives
related to conditional compilation.  As an external research task,
look up some pages on preprocessor directives, and tell how you would
arrange for one of two alternate versions of a block of code to be
compiled, based on whether or not a flag define ca;;ed CHOICE







You may also have a solution using
#ifndef for the alternate block, but the #else is preferred in this
case. We'll be looking at #ifndef in a bit.

#ifdef is actually an old preprocessor directive
from C's origins in 1970.  The more “modern” (originated in 1989)
directive is 
which allows more powerful logical expressions as a conditional
compilation test.  
still gets a lot of use, so you really need to know both.  Here's how
the line 10 
would look using 
#if
defined(DEBUG)
printf(&quot;Entered
value: %d\n&quot;, val);



The #if directive allows full use of C-style
boolean operations, with 
acting like a boolean function to test flag defines.

Look up #if and its boolean abilities, and show
how you would conditionally compile a block of code only if flag
define 
was set and flag define 
was not set.

#if defined(V5) &amp;&amp;
!defined(UNIX)



permits general boolean expressions using relational and equality
operators, and boolean operators !, &amp;&amp;, and ||.  Importantly,
though, these work only on constant data, including constants
provided by #define substitutions:




#if VERSION &gt;= 2 &amp;&amp;
WORDSIZE == 32
   // Code for versions 2 or
later with 32 bit wordsize.



And, if you do comparisons on
nondefined constants, the result is always “false”.



What happens if I use #if with C variables as
opposed to preprocessor #defines, like this?  Try it out, actually
compile it, and explain the result:







The #if fails because version is not
a defined constant, and the test is thus false.  The preprocessor has
no knowledge of C.  It works only with its directives, and considers
all other text to be simply a target for inclusion or disclusion,
define substitution, etc.  So it doesn't know that version is a C
variable with value 2.  Since there is no #define version 2, the term
“version” is simply undefined to the preprocessor.


Indeed, people sometimes use the C preprocessor to
do define-substitution, conditional inclusion or disclusion of
content, etc. on text documents or on source code for other
languages.  It's really a separate tool from the C compiler.

A common use of conditional compilation is to
include or disclude debugging code, based on a flag define, e.g.
.
 Our line 10 conditional compilation is an example.  By including a
line,
we can get the line 11 debugging printf included in the source.  

#define
DEBUG at the top of every source file where we wanted
debug code included, but this would be pretty tedious, especially if
we often wanted to shift between including debugging code and
omitting it on different builds.  Instead, all C compilers allow you
to set a flag define via compiler commandline option -D, followed
(without space) by the define you want.  So:

#define
DEBUG in every source file.  As you can see from the
notes, doing this in combination with the -E option shows that line
11 printf in the preprocessor output.   


Conditional compilation is a tool to be used
sparingly.  Common uses include the debug example just discussed, to
get alternate debug or nondebug versions.  Another use would be to
get alternate source code for different architectures, e.g. different
source versions for big and little endian processors, or for 32 bit
and 64 bit processors.  

But, an excess of flag defines for conditional
compilation can make a project unmanageably complex.  Each different
flag define combination results in different conditional compilations
and thus in effect different  of the
code base.

With three different flag defines, each causing
conditional compilation effects, how many different possible versions
of the code can be obtained by varying the setting of the three flag
defines? 


8 versions.  For instance, if the
flag defines are DEBUG, LITTLE_ENDIAN, and BIT_64, then we can set
them to obtain:
1. A nondebug,big-endian, 64-bit
version
2. A nondebug, big-endian, 32-bit
version
3. A nondebug, little-endian, 64-bit
version
4. A nondebug, big-endian, 32-bit
version
and then the four debug versions of
these.

Ok, so now make it 10 different
conditional-compilation flag defines?  How many versions now?

n
where n is the number of flag defines controlling the
conditional compilation.  Each new such flag define doubles the
number of possibilities.  With 10, you get 1024 versions.
You don't even want to think about setting up test
cases for all those versions.  So, keep the number of
conditional-compilation flag defines to a minimum.










	
	
	
	
	
	
	






This lecture segment covers the use of conditional
compilation to protect against multiple header file inclusion. 
You've probably seen lines like #ifndef MYFILE_H at the start of C
header files; this segment will explain what those lines do, and give
you a deeper understanding of conditional compilation.


	
	
	Standard ifdef headers to
	protect against multiple inclusion
	#pragma once and pragmas
	in general
	Vicissitudes of
	“half-standards”


First, let's understand the problem.  Look at

in the diagram, which includes 
twice.  (And imagine for the moment that 
has only line 3 in it.).  Such double inclusion would repeat the
line-3 typedef of ,
resulting in a compiler error, since one cannot typedef the same
identifier twice.
Would this error really happen in practice? Not
quite as shown, no.  Most people don't write the same 
twice.  But it's very common for a C file to include many different
header files.  Those header files in turn may include yet other
headers, and in many cases may include the 
other header file, thus causing that other file to be included
multiple times via recursive inclusion.  If you include both 
and ,
and each of those in turn includes ,
then you'll get two includes of stdio.h,

So how do we prevent this?  The common practice is
to use the pattern on lines 1,2, and 4 of .
 


on line 1 is the opposite of 
It includes the source lines between it and the matching 
only if the condition it tests is false. 


#ifndef
TEST 





is included only if the flag define IFDEFS2_H

so once the code is included, 
will thenceforth be defined.  This is easiest to see in the expanded
version of 
shown in the comments on lines 11-22.  The 
block is repeated twice via inclusion, but by the second repetition,
has
been defined.  So, as shown on lines 22-28, what you really get is
just the first block, with the second omitted by conditional
compilation.  Any inclusion of the conditionally compiled code
automatically blocks any later inclusions, since the first inclusion
s
the flag that blocks the rest.  

So, by convention, almost all C programmers
convert the name of the header file to all-caps, turn the “.” to
an “_” since flag defines can't have “.” in their name, and
use the resultant flag define as a guard to automatically remove any
repeats of the header.

It's important that each header file have a unique
flag define for this purpose.  Basing the flag define off of the
header file name accomplishes this.   But, it's easy to mess it up by
yank/paste coding from one header file to another, forgetting to
adjust the flag define.  If a C file includes two headers: Header1.h
and Header2.h, but both use 
as their flag define, what happens?  Does the order in which they're
included matter?

The second header to be included
will be silently removed by conditional compilation, since the first
header will have defined HEADER1_H.  This can be a maddening bug,
since the effect is that all declarations provided by the second
header file appear to be missing, despite the fact that the file is
apparently included.  Indeed one include may have worked just fine on
its own, and then fail when the other include (with its matching flag
define) is inserted above it.  The new arrival is just fine, but the
old include that follows it suddenly fails to work.

That three-line solution is admittedly a little
awkward, and there is an alternative.  One may simply add this line:

at the top of any header file, and the
preprocessor will automatically drop second and later includes of the
file.  No need for messy #ifndefs
#pragma
once will also not even open the include file a second
time, speeding compilation.   The 
(pragma from “pragmatic”) directive is a catchall for special
commands directing the preprocessor or compiler in performing their
work.  Depending on what follows the 
you can adjust all manner of subtle options in compilation, silence
selected warnings, etc.  It's a powerful and useful directive.

That's the good news.  The bad news is that the
options following 
are, by design, different for each compiler.  It's meant to be a
nonstandard way of slipping special commands into C source.  If you
move your source to a different C compiler, s
that worked on the prior compiler may not on the new one.  They won't
cause errors: every C compiler simply ignores s
that it doesn't recognize.  But they won't work on all compilers.  

#pragma
once comes as close to a universal pragma as any. 
Practically all compilers recognize it, so you'll find some shops
that use it.  But there was a brief period in the late 90's when some
compilers that formerly recognized it temporarily decided to
“deprecate” it – giving warnings that it was a feature to be
phased out.  There were no good reasons for this, and they changed
their minds, so #pragma
once remains universal for all practical purposes.  But
many shops avoid its use because of that history, and frankly,
because the tried-and-true 
approach has been around for 40 years.  

That's all we'll say about this rather arcane
corner of C, but note it's a good case study of the vicissitudes of
having “almost standard” features.  A language feature that is
clearly nonstandard is easy to avoid or to use only in special
situations.  One that is universal is easy to rely on.  But, one that
is almost but not quite universal can be worse than either extreme
because it becomes a “half-standard” that some programmers follow
and others don't.




	
	
	
	
	
	
	






:
parameterized s
that are used like function calls.  These are important tools, but
tricky to design right; we'll discuss how to do this.


	
	operator stealing and
	macro design
	
	


s
with parameters.  Such parameterized 
are usually termed 
on line 3 is a good example.  You may list any number of parameters
after the 
name, and then use them in the substitution string that follows.  The
parameters take no types; they're just placeholders that are filled
in with string patterns when you use the macro.  When you use the
macro in code, you add actual parameters in parentheses after it. 
The preprocessor replaces the placeholder parameters with the actual
parameters, in the replacement string.  So,
Min1(alpha,
i+j)

alpha
&lt; i+j ? alpha : i+j

and ,
so the 
macro behaves like a function call computing the minimum of its two
arguments.   But, to be clear, there is no function call.  The
preprocessor just replaces each instance of -plus-parameters
with an expression that computes the minimum of those parameters.  

The preprocessor has no “understanding” of C. 
It's a mindless string-substituter  If you write
Min1(stupid
preprocessor, it cant tell prose from code)
the preprocessor, like a digital parrot, replaces
this with:
stupid
preprocessor &lt; it cant tell prose from code ? stupid preprocessor
: it cant tell prose from code
(And of course you'll get
compile errors from the substitution.)  This mindless substitution
behavior results in several design problems with macros, which are
covered and (mostly) solved in the following discussion.

Let's now go through several common problems with
macros, and show how to fix them.  I'll ask you repeatedly in
upcoming in-lecture questions to take a misbehaving macro call, and
make the macro substitution by hand to figure out why it fails.  You
could do this mechanically via compiler option -E, but for this
lecture please do it by hand to reinforce the ideas.

to print the minimum of 
and .
 As  you can see on the line 28 output, this works as advertised. 
But, line 17 attempts to use the result of an assignment operator as
the first parameter, expecting that 
will be set to 44, and the min of 
and 
computed.  As the line 29 output shows, the min computation works,
but 
is set to 43, not 44.



set to 43?  Make the substitution by hand, and look closely at the
result, with operator precedence in mind.  If you still don't see the
answer, then parenthesize the substitution fully, according to
precedence rules.

The substitution is k = 44 &lt; j ?
k = 44 : j.  But operator precedence would perform this as: k = (44 &lt;
j ? (k = 44 ): j).  The inner assignment puts 44 into k, alright, but
then the conditional operation “steals” the 44 from what was
supposed to be the first k = 44 assignment, since ?: has higher
precedence than assignment.  So, k gets a final assignment of the
result of the min computation: 43.  And 43 is also the value of the
assignment, and thus of the entire substituted expression.


internal
operand stealing.  (That's a private term; there's no general
term for it.)  If you call a macro with expression parameters,
precedence rules in the subsitution may cause some of the operands,
like that 44, to be stolen by other parts of the macro.
Always
parenthesize every instance of every parameter in the substitution
string.
does this, and would substitute the line 17 call to (k = 44) &lt; (j)
? (k = 44) : (j), which does the right thing, albeit with a redundant
assignment into .



still has problems.  Line 19 uses 
to print the min of 
and 
plus 1.  As you can see on line 30, this fails when they're passed in
one order: Min(i, j)
+ 1

Min2(i,
j) + 1 and consider precedence, to figure out why it
returns 42 instead of the expected 43.

Substitution yields (i) &lt; (j) ?
(i ): (j) + 1, and the addition is done first, by precedence and (j)
+ 1 is the final operand of the conditional.  Since the test is true,
however, the result is i – 42.  

Let's call this
.  If you call a
macro as part of a larger expression, precedence rules may cause
operands of the larger expression to be stolen by the macro
substitution.
Again the fix is straightforward and ugly:
parenthesize the entire macro substitution string, as in .
 


Obsessive parenthesizing of macros can prevent
operand-stealing of both sorts, but as line 20 illustrates, we're
still not out of the woods.  Here we want to postincrement ,
and find the minimum of the old value of 
vs . 
 We'd expect a minimum of 42, and a new value of 43 for i
as a side effect.  But instead the result on line 32
shows 43 for the minimum, and a value of 44 for 

Why these results even after all that
parenthesizing?  Do the substitution.

The substitution yields ((i++)&lt;(j)
? (i++) : (j)).  It's parenthesized up to its ears, but this doesn't
change the fact that i++ is done twice, because it was substituted
twice.  Even though the test is true (postincrement yields 42), i has
43 by the time the true branch is evaluated, and evaluation of the
true branch in turn raises i to 44.  So the thing returns 43, and
leaves i at 44.
This one, sadly, has no easy solution.  (We'll see
some other macros for which it is solvable later.)  If an argument is
substituted more than once into a macro string, then that argument
must not have side effects like incrementation, or they'll be done
twice.
There is actually a term for parameter passing in
which the actual parameter literally substitutes for the formal
parameter, as in macros.  You should already know call-by-value and
call-by-reference parameter rules (ref earlier lectures).  This
macro-like parameter passing is .
 It's characteristic of any substitution mechanism like C's macros,
and as you can see from the just-noted bug, it's rather a nuisance.  

Remarkably, there was an early C predecessor
language called Algol that had call-by-name behavior for function
parameters, even though they were compiled, not string-substituted. 
Doing this required some serious cleverness, and wasted cleverness at
that, since call-by-name is bad parameter behavior.   It's just one
you're stuck with if the underlying mechanism is a substitution
system.  


So far our macros have expanded to expressions,
and acted like value-returning functions.  There is another
possibility: a macro that expands to a multi-statement block of code.
 


on lines 7-11 is a good example.   It expands to a code block,
complete with block-scoped variable ,
and three assignments that swap the two parameters 
and .
 Using it, as on line 23, results in the macro-use being replaced by
that entire 3-statement block, which exchanges i
,
as the line 32 output shows.
Statement-block macros can be more powerful than
single-expression macros, but they act like a void function,
performing some action but returning no value.  Single expressions
can return a value, but code blocks can't.
Technically, one cannot break a macro substitution
string over many lines; it must go on just one.  But, the
preprocessor lets you “escape” a return at the end of a line by
preceding it with a backslash, as we do on lines 7 – 10.  This is
like adding a “just kidding” to the return, and the preprocessor
will ignore the return, omitting it from the substitution string. 
So, you get to look at something rationally indented, while the
preprocessor still sees it as a single line, as you can see in the
final line of the -E output in the diagram.
The bad news is that it's really easy to put a
space after the backslash, and then a return.  In this case, you're
only escaping the space, not the return, and you'll get odd
preprocessor errors.  Watch out for this one; it's easy to do, and
hard to see.

,
without the overhead of an actual function call, and the messiness of
passing addresses (which would be needed for a conventional Swap
function).  But, if I have an array ,
and an integer 
whose value is within the index range of the array, and I swap them
thus: Swap(i, a[i])
Swap(a[i],
i)

Here's the substitution string for
the first case: 

{ int __swapTemp = (i); (i) =
(a[i]); (a[i]) = __swapTemp;};

gets the value of a[i], which might be anything, and then i is used
in the final assignment to index a, apparently out of range since we
got a segfault.  Doing it the other way, however, avoids modifying i
until all uses of it as an index are done:
{ int __swapTemp = (a[i]); (a[i]) =
(i); (i) = __swapTemp;};




?
 It's valid, but pretty odd looking.  Wouldn't a simple 
have done as well for this purpose?  What specifically could go wrong
if the macro used 
instead?  (Note, by the way, that any variable declared inside a code
block is local to that block, so 's
block-local temp

variable in the calling code.)

What if the calling code actually
passes temp as one of the arguments?  Then the substitution code will
be totally messed up.


So... call-by-name strikes yet again.  And we add
obscure naming of block-local variables to the list of protective
design measures in macros.






	
	
	
	
	
	
	






This lecture segment looks at the reasons that
macros are very common in C code, and the relationship between macros
and an important modern language feature.  Macros are an early
example of what in a modern language would be an inline
function.  We'll look at how to mimic inline functions with
macros, including avoiding the call-by-name problems we saw in the
prior segment.


	
	Fixing call-by-name
	problems with block-local variables


So why do we want macros in the first place? 
Given their design complexities, why use them instead of functions? 
Wouldn't a 
function be better than a 
macro in all respects?  Certainly we wouldn't worry about side
effects in call-by-name parameters, writing obsessive parentheses,
and giving odd names to locals.

This is something you can reason out for yourself,
if you think carefully about prior lectures on the RTS, and what it
takes to do a function call to 

The major advantage is speed.  With
macro-substitution, there's no stack frame to create and initialize,
no parameter list to copy, no jump to the function, no return value
to copy, no stack frame to destroy after return, etc.  Especially if
the actual code is small, as in Min, a macro can be more than 10x
faster than a function call


Of course, you do have the space-inefficiency of
substituting the same macro code over and over into the caller every
time the macro is used.  For a sizeable macro, this can result in
larger executable sizes, but in the right cases the larger executable
is worth it for the speed.   

And recall from earlier lecture that a function
call is not exactly a small bit of code either.  It's easy to think
that a one-line function call would have the same executable size as
any other statement.  But as the lecture on RTS explained, a function
call translates into the equivalent of several lines of standard
source, with all the register saving, stack frame building, parameter
copying, etc.  So, a small macro like Min
smaller
executable sizes than an equivalent function call, despite the
repetition of substituted code.

The speed of code-substitution vs standard
function calls is more than a curiosity.  It's a central design issue
in the engineering of large software systems, and in programming
languages.  C's macros are an early, and admittedly primitive,
example of what in a modern language would be an inline
function.   Almost every modern compiled language offers a
means by which one may designate an otherwise standard function to be
inline, meaning that “calls” to the function will be carried out
by substitution of the function's code directly into that of the
caller, like C macros.  In many languages the syntax for this is to
simply add an 
keyword to the function header, with no other alteration of the
function code.
And inline functions, despite working by code
substitution, do not suffer from call-by-name problems; they work
just as normal functions would.   Here's an exercise to see how a
compiler might accomplish this.


function as a macro, without changing the basic design of its loop. 
And make it immune to call-by-name problems.  (Consider making
temporary copies of the parameters – this is what a compiler does
to inline functions to prevent call-by-name problems.)
void strcpy(char *s1, char *s2) {
   while (*s1++ = *s2++)
      ;
}
Answer 2:
Here's one possible answer.  

#define
strcpy(s1, s2) {\
   char
*__strcpyS1 = (s1), *__strcpyS2 = (s2);\
   while
(*__strcpyS1++ = *__strcpyS2++) \




This code evaluates each parameter
exactly once, in parentheses to avoid operand stealing, and stores
the results in block-local variables with almost certainly unique
names, and then uses those local variables in lieu of the parameters 
This avoids call-by-name problems.  Your answer may have different
variable names, but to be correct it needs the same basic pattern of
one-time evaluation of parameters, storage in oddly-named block-local
variables, and use of the block-local variables instead of the
parameter.


Sadly, there is no way to return a value from a
code-block macro, so code-block macros can only mimic inline void
functions.  Expression macros can imitate inline functions with
return values, but cannot run loops or other complex code, nor
declare helper variables to avoid call-by-name problems.   Some C
compilers actually add a special feature allowing a code-block to
return a value, to let code-block macros imitate any kind of inline
function.  And of course, a compiler offering function inlining would
use something similar in its internal machine-language translations
of inline function calls.

Look up the syntax for returning a value from a
code block in the gcc compiler.  Use this to rewrite the 
macro to return the min value of its parameters, but without
pass-by-name problems.  Assume the macro should work only on integer
values.

The syntax is to enclose the block
in parentheses.  This makes it into an expression, with the value of
the final expression in the block.  So, we could rewrite Min thus:
#define
Min(x, y) ({\
   int
__MinX = (x), __MinY = (y);\
   __MinX
&lt; __MinY ? __MinX : __MinY;\


One of the languages that provides inline
functions is C itself, in its C99 version.  Standard ANSI C offers no
inline functions – only the old macros.  But almost all C compilers
now meet the C99 standard, and you can pretty safely use its 
keyword in place of macros.  

So, did we just waste our time discussing macros? 
No.  First, you get a really clear understanding of how inline
functions work by studying macros, and you get a sense of what it
takes to make a code-substitution system behave like a function call,
in particular shedding its call-by-name characteristics.  Second,
there are billions of lines of existing C code, including many of the
standard libraries, that use macros.  (And for that matter hundreds
of thousands of old-fashioned C programmers who still write them.)  
And, importantly, C's 
keyword is treated as a  by many C
compilers – one they may elect to ignore.  In such compilers, if
you want to be dead sure of inline implementation, you still need a
macro.
So, prefer inline functions when you can, and
understand how the work “under the hood”, but know your macros.






	
	
	
	
	
	
	






In this segment we'll look at how functions that
take varying numbers of parameters – 
functions – work. 



	
	Variadic parameter
	declaration and retrieval
	Variadic parameter
	promotion rules
	Ancient C parameter
	passing


Like many languages, C lets you declare functions
that have varying types and numbers of parameters.  
and 
are good examples.  Consider these calls:
printf(“Value
is: %d”, i) vs
printf(“Sum
and Average are %f %f”, j, k)


char
* for first parameter, but after that all bets are off.
 The first takes an int, and the second takes two doubles.  In
general the parameters after the format string are completely
unpredictable in number and in type, since they depend on the number
and type of the format specifiers in the format string.  Functions
that may be called with many different types and numbers of
parameters are called 

The first interesting question is how one would
declare a prototype or header for such a function.  The prototype for
,
for instance, would start with a char
* parameter for the format string, but what would
follow?  There might be no further parameters (e.g. for
printf(“Hello,
world”) or as we just saw, any number and type of
parameters.  


int
printf(char *format, ...);
(Recall printf returns an int.)  That “...” is
legitimate C syntax, not some abbreviation.  It's the C equivalent of
“eh, whatever”.  You may pass any number and type of parameters
you like in place of the “...”, whether that's 100 parameters of
varying types, or none at all.  Let's call these the variadic
parameters.  

Importantly, as we'll see, there must always be at
least one conventionally declared parameter before the variadic ones.
 One may not declare a function thus: 

void
f(...);  // Not allowed

So, the “...” notation lets you declare a
variadic function, but when it's time to use the variadic parameters,
e.g. to print the ints or doubles that were passed to ,
how do we refer to them?  All we have in the function header is
“...”.
The answer to this involves some serious runtime
stack hacking in C.  Variadic functions operate on the assumption
that parameters are in a predictable pattern on the RTS, e.g. one
after another.  Since any variadic function has at least one normal
parameter, the function can use this normal parameter's address as a
starting point, and deduce the locations of the variadic parameters
from it.
The Variadic.c example in the slide does just
this, on the assumption that parameters fall one after another in
increasing memory order, from left to right within the header or the
call.  This assumption is valid for the gcc compiler used in the
example, though may not be for other compilers, as we'll discuss in a
bit.  Function 
assumes, as a simple example, that it will be passed an ,
a ,
and a .
  


Follow the pointer math on lines 4-6.  By how many
bytes will the addresses in 
and 
differ, and why?  


By 8 bytes, because thirdPtr is
derived by adding 1 to secondPtr, which adds the size of a double, or
8 bytes, since secondPtr is a pointer to double.


As the output on line 21 shows, this works, with
the 
and 
parameters being correctly pointed  to by 
and ,
respectively.  The associated diagram shows why.  Assuming the order
of parameters described, the pointer logic on lines 4-6 point

and 
to the 
and 
parameters respectively, with each addition of 1 to the prior pointer
“skipping past” that pointer's parameter to the next parameter in
memory order.
As long as we know the types of the parameters,
this method will work with any number of variadic parameters.  In the
case of 
and ,
the format strings give the type and number of variadic parameters
via the format specifiers within them.  
and 
use their format strings to guide the pointer arithmetic needed to
retrieve the variables corresponding to each format specifier.  Other
variadic functions may deduce the type and number of their variadic
parameters in other ways, but they must have some means of doing so
in order to use this RTS-hacking approach.


is a float variable, not double.  On line 15 we cast it to the
correct type, but on line 16 we don't, and yet the output of that
second call remains correct on line 22.  


Based on the discussion thus far, this should
surprise you.  Why is it odd that this second call should still work?
 What would we expect might go wrong with it?

Because a float is 4 bytes while a
double is 8, and thus the second parameter on line 16 should take
only 4 bytes, which would throw off the address calculations on lines
4-6, which assume an 8-byte double for the second parameter.  As the
diagram in the notes shows, passing only 4 bytes for the second
parameter would result in secondPtr pointing to the combination of
two parameters, and thirdPtr pointing past the end of the paramers.


The second call works because of a special
parameter passing rule for variadic parameters.  As we just saw,
getting the types of variadic parameters even a little bit wrong
(e.g. float vs double) badly messes up the delicate pointer
arithmetic that the function uses to retrieve the parameters.  To
reduce the risk of this, C promotes all “small” types passed as
variadic parameters to their full-sized equivalent.  Specifically, it
promotes char and short to int, and float to double.  So, line 16 
passing a double, appearances notwithstanding.  You get the (double)
cast for free.
But, line 17 is not passing a double.  The second
parameter there is just a 4 byte int, which is passed unpromoted. 
The result on line 23 serves as a cautionary tale about getting
variadic parameter types right.  Clearly the second parameter is
messed up in the line 23 output.   Why doesn't the compiler catch
this as a type error?  Because the matching formal parameter in

is just “...”, offering no information for type checking.  And
the compiler isn't going to pick apart the pointer logic on lines 4-6
to figure out what's expected.  With variadic parameters, there's
no type checking; it's all on the honor system, with ample
opportunity for interesting bugs.  On that point, here are two
questions regarding line 17:

 get
printed as the second parameter value?  What does 
end up pointing to and treating as a double, exactly?

It points to 8 bytes formed by the
integer 3, and the pointer address in 
 There are a lot of 0 bytes in those 8 bytes, and the result is
either a double-precision value of 0.0 or one that is very close to
it.




did the “Hello” get printed anyway?  To answer this, you
need to think back to earlier RTS discussions, and be clear that
nothing was passed for the third parameter in line 17 because the 3
and the 
formal parameters got treated collectively as the second parameter. 
What did 
point to?

ThirdPtr pointed to the next four
bytes after the parameters, which generally would be random data, but
in this case is the leftover third parameter from the prior call on
line 16.  Remember that the stack frames for the two calls will
occupy the same area of memory.


What you should get from these two questions is an
informed fear of messing up variadic parameters.  The wild-west
variadic “anything goes” is nice, until you realize how subtly
you can shoot yourself in the foot with it.  And this is compounded
by the fact that two of the most common C library functions –

and 
-- are variadic.

printf,

below work, printing A each time?  (Try it if you doubt me.)  
does let you pass an int to a %c specifier, assuming the int contains
a valid ASCII code.  But, since the char and the int are passed
variadically, how does 
know to expect one byte for the first and four bytes for the second?

int ai = 65;        // A is
ASCII 65
printf(“%c %c”, ac, ai); 




Printf doesn't know the difference,
and it doesn't need to, because you can't pass a char to printf.  The
ac is promoted to int.  The %c format specifier ALWAYS expects an
int, and always has.  It never expects a char.



1. For variadic parameters, the type checker is

2. Omitting a variadic parameter, or accidentally
passing too few bytes, results in the recruitment of random bytes
following the real parameters.  Sometimes, unluckily, these actually
sort-of work since they're leftover parameters from earlier calls.
3. You cannot pass chars, shorts, or floats to
variadic parameters, no matter how hard you try.  They get promoted
to ints or doubles.

In original (1970-1989) C, even non-variadic
functions followed variadic-like parameter rules, in that there was
no parameter type checking.  The function would declare parameters
explicitly, so there was no need for pointer arithmetic.  But, you
could pass anything you wanted, at your peril.  And the variadic
small-promotes-to-large rules applied to 
parameters, not just variadic ones.  Even a modern C compiler will do
this kind of function for you (or ) if
you write a function using the old style header:
int f(int a, double d, char *s)
{   // Standard modern function header




int f(a, d, s)           //
Nasty disco-era function header.








As you can see in the second
function, the parameters are given without types in the parentheses,
and their types instead appear in a local-variable style block before
the opening curly brace.  



If you ever see such an
old-style function, be aware you are looking at Really Old Code, and
variadic rules will apply.  If possible, revise such code, and of
course, never write it yourself.






	
	
	
	
	
	
	






In this segment we'll look at library-based
implementation of variadic functions, which is more orderly and
portable than the handcrafted pointer-manipulation we did earlier.


	
	va_list, va_start, va_arg,
	va_end
	


As discussed in the prior segment, retrieving
variadic parameters in a variadic function requires delicate pointer
arithmetic.  Even worse, the exact arithmetic required depends on the
layout of the RTS stack frames, which differs per compiler and
machine.  So, in principle, you'd need to rewrite code like our
example Variadic.c for each different compiler and machine.
The solution is to abstract the process of
traversing the variadic parameters into a library – the system

library, in particular.  
supplies standard macros for variadic parameter retrieval.  Each
compiler and target machine gets its own version of ,
which has macros implemented appropriately for the RTS in question.
Let's illustrate these macros by walking though an
implementation of a simplified 
function.  The 
function is variadic, as you can see on line 4 of the diagram.  Its
format string allows format specifiers %c,
%
and and

retrieves for each, respectively, a variadic int,
int, char
*
expects an int parameter.) 

The function first declares, on line 5, a pointer
to walk through the variadic parameters.  The 
macro  
 substitutes into the right type for such a pointer.  This is
probably a or
,
so 
might expand to void
*params.  But, it may be a different type if the
author
wanted it to be.  We just trust it to be correct. 


macro (not function) call expands to an appropriate initialization of
.
 This is likely to be params
= &amp;format +
1, but again the implementation is abstracted by the
macro, and we just trust the macro to expand to “the right
initialization”.
's
main loop (more on its logic in a bit), we retrieve the next variadic
parameter via macro calls like va_arg(params,
int).  This expands to the right expression to both
dereference 
to get an ,
and also to advance 
by the size of an int, preparatory for the next 
call to get whatever follosws the int.  



is ,
and is pointing to a variadic int parameter, write an expression that
both returns the int to which 
points, and advances params
to the address just after the int.  You'll need pointer
casts.

One way to do it is *(int *)
((params += sizeof(int)) – sizeof(int)).  You need something tricky
like this to both increment params and yet dereference, as an int
pointer, its original value.
And, finally, the line-41 macro call

does any cleanup necessary after all variadic parameters are
retrieved.  This is rarely needed, so in most 
implementations line 41 would expand to nothing at all.  But the
macro call is there, just in case.

library.  You declare a 
variable, initialize it with ,
iterate and retrieve variadic parameters with ,
and wrap it up with a 
call.  And your code works under all compilers and machines.

Why are all of these macros?  Why couldn't macros
,

and 
be functions?  There are at least two good reasons; see if you can
come up with both.

First, if they're functions, they'll need to be
passed the 
by reference, requiring an awkward &amp;, which the library designers
wanted to abstract away.  Also, 
must return a different type on different calls, and must accept a
type as one of its parameters.  No function can do that.


logic is not essential to this discussion, but it leads into an
upcoming look at the stdio.h library, and we should review it for
completeness.

string one char at a time.  If the char is not a '%', then the
line-38 else branch simply prints it out via the stdio 
function, which 
uses to do all its output.  So any non-format-specifier content in
the 
string gets printed directly.
The format specifier handling is more interesting.
 The line-12 
statement advances 
to the char after the '%' and switches on that char.  If' it's a 'c',
then line 14 prints out the ASCII code in the expected 

accepts an int parameter, expecting it to contain an ASCII code).  If
the format char is a 'u', then line 17 copies the variadic parameter
into ,
and lines 18-22 convert 
into a series of decimal digits, assigning them from right to left,
from least to most significant, into array 
and then printing them out, from left to right.
Read lines 18-22 carefully and answer these
questions:

?
 Putchar accepts an int, right?

Value is a binary integer, not an
ASCII code.  If, say, value is 123, we want “123” printed, not
'{', which is the character with ASCII code 123.

value
% 10
doesn't need all 10 elements of 
 Will it print garbage?

value % 10 yields the numerical
value of the lowest digit in value.  Adding '0' gives the ASCII code
for the digit representing that value.  And, since lines 24-25
iterate forward from ndx, not from 0, any unused chars at the start
of iVal will not be printed.


Finally, lines 28-30 cover the “%s” case,
retreiving a char * variadic parameter, and traversing the string to
which it points, printing said string char by char.  And the default
case simply prints any unrecognized format specifier literally,
including the '%'.

Except as an exercise, you should not
hand-traverse the RTS  with pointers like 
did.  In professional code, implement any variadic function using
.





	
	
	
	
	
	
	






This lecture segment ties together prior
discussions to give a complete picture of a the memory space for a
standard running program or “process”.  A clear understanding of
the process space is critical to writing reliable C, and for deeper
study of operating systems.


	
	
	




Review if necessary the concepts of RTS, runtime
heap, string table, global data, static local data, MMU, memory
segment, and virtual address spaces.

A 32-bit architecture, with 4 byte addresses and
pointers, permits 4 gigabytes of addressable memory in a program. 
And a 64-bit architecture permits as many as 16 quintillion bytes. 
Either way, that's a lotta bytes, and different areas of that huge
space are used for different purposes.  In prior lectures, we've
discussed many of the different areas of memory that make up a
running program.  Let's review these, and add a few more terms and
concepts.

Program code, in machine language form, takes up
part of the running memory, in what is usually called the text
section  of memory. 
Function pointers contain addresses into the text segment, for
instance.
 (You'd expect this to be called the “code
segment”, since it contains code, not text.  The name comes from
the outdated term “program text”, and we're stuck with it.) 

In many operating systems, the text segment is
further divided into an area that's filled with machine language upon
program startup, and another that is reserved for loading dynamic
libraries as the program runs.  Such libraries are loaded into
memory only when the code they contain is actually called.  But,
space must be reserved in the memory area for them.  That seems a
waste of space, perhaps, but we'll see later in the lecture that
clever use of the MMU makes it very efficient.

 is the
area of memory that holds global data, as opposed to the RTS, which
holds local data, parameters, etc.  Of course, a well-written program
has little, if any, global data, but in this context the term applies
to  data of which there is only one copy
shared by all the function calls in the program – data not local to
any one function call.  Thus, the string table and static local
variables also fall in the data segment.

Wait a minute, aren't static locals still local to
one function?  Why do they go in the data segment?  Ditto for string
constants.  Any one string constant appears in just one function,
right?

This is really a review question.  
Static locals are local to a function, but what I said above was that
the data segment contains data not local to any one function CALL –
data that doesn't belong in an RTS stack frame.  Multiple calls of a
function share the same one static local variable; static locals are
thus global data in disguise; they don't go on the RTS.  (Review the
earlier lecture on global data if needed.)  And while a string
constant may be created in one function, it may be passed around to
other functions by reference.  The sequence of characters comprising
the constant must thus persist outside of any one function call.  So,
string constants are also “global variables in disguise”.


Like the text segment, the data segment is usually
divided into two areas.  The main data segment holds global data that
is initialized on program startup, such as the string table, and
variables that are initialized in their declarations.  And a reserved
area of the data segment, usually called the BSS
segment, holds global data that is uninitialized on program
startup.
Why separate initialized global data from
uninitialized?  Because global data is not initialized by running a
bunch of assignment statements before starting the main program.  It
makes more sense, and is much faster, to store a binary image of the
initial global data, and copy it directly into the data segment as
part of loading the program in the first place.  So, a compiled
executable includes not only code, but also a binary copy of the
content of the data segment (not the BSS segment), which is loaded
into memory along with the code, on program start.  

But, uninitialized global data doesn't need to be
stored this way; the executable only needs to hold a count of the
number of bytes for such data so we know how big to make the BSS
segment.   The term originated in the 1950's with
assembler code, and stands rather awkwardly for “Block Started by
Symbol”.  This suggests an area of memory that is brought into
existence merely by declaring a global variable, or a “symbol” in
1950's assembler-speak.  

So, it makes sense to group all the initialized
global data together so it can be initialized in one big binary copy
from the executable, while uninitialized global data goes in a
separate area.

The runtime heap and RTS are yet two other areas
of memory.  We've talked a good bit about these already, but note
they differ from the text and data segments in one important way:
they may grow during program execution.   The runtime heap starts at
some initial size, and can be expanded up to a point if more dynamic
memory is needed.  The RTS also starts off small, with just the frame
for ,
but as calls occur, especially recursive ones, it may grow quite
large.   In our abstract diagram, let's show the runtime heap just
after the BSS, but show the RTS at the end of memory, growing upward
as in our earlier RTS lecture.  The space between them will be “room
to grow”, though there's a more complex story behind this that
we'll cover a little later. 


In almost all modern OS's, the BSS is
automatically initialized to all-zero bytes.  This is not so much a
part of loading the program as it is a side effect of operating
system policy.  The operating system itself sets the entire area of
memory given to a new program to all zeros, so you get initial data
of 0 for free if you don't otherwise initialize the memory in your
program with data or code.  This applies to any area of memory,
including RTS and runtime heap, as well as the BSS segment.

Why is it necessary for the OS to do this?  It's
not being done to save you from uninitialized data; this is C, after
all, and initialization is  problem. 
There's an important security issue involved.  Imagine the ongoing
history of programs starting, running, ending, new programs starting,
etc.  In that context, what would be wrong with leaving memory that
is given to a new program uninitialized?

The uninitialized data would be data
either from the OS itself or some earlier running program, inviting a
clever user to simply read the uninitialized content of memory with
which his program was started, and obtain valuable information (e.g.
SSNs, passwords, account numbers, etc.) from the garbage left in
memory by earlier programs.


This is not just an obscure possibility.  The
college I attended in the late 70s had an HP 3000 timesharing
computer, and its relatively primitive OS did not zero out memory
between programs.  Clever students could dump the initial “garbage”
in their program's memory space and get other people's
username/password combinations from it.  Quite a security hole.
Now, wait a minute...  I've been prating on
throughout the course about the dangers of uninitialized variables,
“unlucky” bugs, and so forth, and now I'm telling you that you
can be sure that your program's memory will contain zeros by default
in all modern OS's?  Does that mean you never really get garbage in
your variables after all?

This doesn't mean you won't hit uninitialized
variables containing garbage.  How could you get nonzero garbage data
despite this OS policy, say in a local variable?  How about in an
allocated block from the runtime heap?  Describe exactly the scenario
that would cause nonzero garbage content, despite the OS policy of
zeroing out your memory.  And describe 
that nonzero garbage data would come from.

If you make a function call A, and
return from it, then make a new function call B, the stack frame area
for B overlaps the old frame for A, and will contain A's leftover
garbage.  We went over this in some length in earlier lectures.  And,
if you allocate a block, fill it, and then free it, a later
allocation may get that same area of memory, complete with the old
data you put into it.


So, uninitialized variables are still a problem. 
But the important, and somewhat interesting, point is that any
garbage data you see in a variable is ,
from earlier uses by  of the
same area of memory.  It never comes from some other program, at
least not in any operating system with half a brain.






	
	
	
	
	
	
	






This lecture segment finishes up our discussion of
process memory space, looking at how its layout differs on different
machines, and looking at “holes” in the virtual memory space. 
And we'll end with a little drill we call “safe/risky/dumb”.


	
	Virtual vs physical memory
	(v)
	Readonly memory and shared
	physical memory
	


The text segment, data segment, BSS, RTS, and
runtime heap exist in any C program on any architecture.  But, their
relative positions, and the direction in which the RTS grows (upward
in memory or downward) vary per architecture.
I'll run the ProcSpace.c program shown in the
diagram on my local machine.  The output is as shown.  Look closely
at the code for ProcSpace.c, and determine in which memory segment
each variable or address resides.  Be careful about the difference
between the address of a pointer and the address of its target.  From
your analysis, answer these questions:

What are the relative positions of the text
segment, data segment, BSS segment, RTS, and runtime heap on my local
machine?  Does the RTS grow up or down?  What limits might there be
on its growth?  Is the BSS higher or lower in memory than the main
data segment?

The function addresses on line 17
give a sample of text segment addresses.  Looks like those addresses
are in the 4.1 million range.
The addresses of alloc1, alloc2, and
str (not their content) mark main's stack frame as being in the
2,665,500 range, below the text segments.  The address of fLocal, in
the call of f(), marks its stack frame as in the same range, but
slightly lower, so the RTS apparently grows downward in memory, and
can't very well grow below address 0, so it won't exceed 2.5 MBytes
or so (perhaps less).
The locations of sLocal1, sLocal2,
and global1 are all in the data (non-BSS) segment since they're
initialized, above the text segment, and are adjacent to one another
starting with global1 at 4202496.  Nearby is the location of the
“Hello” string at 4202574 (along with other string constants, of
course).  

The locations of sLocal3 and global2
(all BSS residents) are about 4K above the other data segment
variables, at 4206592 and 4206848.  So the BSS is above the
initialized data.
And finally, the addresses in alloc1
and alloc2 are way up at around 536 million, a long way from the rest
of the data.   And the two successive allocations are in increasing
memory order, so that address is probably the start of the runtime
heap.
So, summarizing, we have first the RTS, growing
then the text segment, then the
data segment with the BSS on top, and finally, way up at 536 million,
the runtime heap.

OK, so here's the same program, run on another
machine.  Decipher this one the same way, drawing a similar diagram.

Looks like we start with text
segment, and way up at address 134,513,000 or so.   Right above that
is the data segment, which apparently starts with the string table,
then the rest of the globals, again with the BSS data at the top. 
Then we have the runtime heap starting at 150 million or so, and
finally, way up at 3.2 billion, the RTS, growing downward.
The arrangement of RTS and heap in this case is a
little more conventional, with the RTS based at a very high address,
and growing downward toward the heap.
Do you really need to know the exact memory layout
of each process space?  No, not for routine programming.  But
understanding the way it all works is critical to proper C
programming even so.  We'll see this in the exercise at the end of
this segment.  And, seeing the huge memory gaps between the RTS and
runtime heap, especially in the second example, leads to an
interesting discussion on virtual memory space...

As you know from earlier lectures, the MMU maps
your program's zero-based memory addresses to real addresses that may
be anywhere in memory.  We speak of virtual
addressesphysical
addresses 
And, though your virtual addresses, assuming a
32-bit machine, can run from 0 to over 4 billion, your program
doesn't actually get that much physical memory to use.  (Indeed, on
an older machine, there may not even  that
much physical memory.)  Instead, you get physical memory to support
only part of your virtual addresses, and if you access outside of
that, the result is a segmentation fault, as described in earlier
lectures.  


But, what we did not discuss earlier is that your
allowed virtual space may have  in it. 
Look back at the second architecture with the RTS at 3.2 billion, and
the runtime heap at 150 million.  Are there really 3 billion bytes of
unused memory between the two?  In terms of virtual addresses, yes,
but the vast majority of that space is not mapped to physical memory,
and if the program tried to use it, a segmentation fault would
result.  In a typical process space, the usable virtual addresses are
not contiguous.
If the RTS or runtime heap runs out of mapped
space, it's usually possible for a program to request that the
operating system arrange for more virtual addresses to be mapped and
thus usable, “filling in the hole”, and extending the area for
the RTS and/or heap.  But unless this is needed, it's a waste of
memory to map those unused virtual addresses to physical memory, and
almost invariably there'll be some space between the two that is not
mapped at all.

Not all usable virtual addresses are writeable. 
Almost all MMUs can be configured to map parts of a program's virtual
address space to physical memory in read only


For which of the areas of the process space does
read only access make sense?  There's one in particular that is
almost always mapped read only.

The text segments contain code that
should not be modified by the program, and are almost always mapped
read only.  Indeed, modifications to the code would probably result
only from a wild pointer; it's certainly not something any program
should do intentionally.


Mapping the text segments this way opens up an
even more interesting option.  If several programs are running the
same code (for instance, several running instances of the same word
processor), then their text segments may all map to the 
physical copy of the code.  Since they can only read, not modify, the
code, there's no reason for them to have independent copies.  Their
RTS, data, and runtime heap all have to be separate, but they can
share code.

Visualizing the layout of process space helps you
decide whether certain C code patterns might end up accessing bad
locations in memory.   For instance, you already know not to follow a
pointer to an allocated block that has been freed.  Each of the
following in-lecture questions presents a small C function.  For
each, you should decide whether what the function does is safe (not
likely to cause a memory-access bug), risky (might cause a bug unless
the caller clearly understands how to use the function), or plain
dumb (will automatically be a bug).

Let's start with this one.  Is it safe, risky, or
dumb?
int *f1() {
   int loc;
   ...
   return &amp;loc;
}

Answer 4:
Dumb.  This is really review from
the RTS discussions.  Loc becomes garbage upon return from f1, so f1
is returning the address of garbage data on the RTS.  Worse still,
loc will retain its old value until its area in the RTS is
overwritten by a later call, so this is an unlucky bug.


int *f2() {
   static int loc;
   ...
   return &amp;loc;
}

Answer 5:
Safe.  Loc is now static, and it
thus has a life beyond the current function call, and is not on the
RTS at all.


int *f3() {
   int *ptr = calloc(42, sizeof(int));
   return ptr;
}

Answer 5:
Risky.  The caller needs to know
that it's getting back a pointer to an allocated block, and thus has
responsibility for freeing it, since f3 sure won't be doing so.  If
you thought that the block itself would be freed because ptr ceases
to exist, that's not true.  Allocated blocks are freed only by
calling free.


void f4(int *data) {
   static int *myData;

   myData = data;
   *data = 42;  // Return a 42 to the caller.
}

Answer 6:
Risky or dumb, depending on your
viewpoint.  I'd say dumb, myself.  You're retaining a pointer, in
static storage, to an entity that you have no idea will stick around.
 Maybe “data” is pointing to a local variable in the caller. 
That local will stick around while f4 runs, and for a while after f4
returns to the caller, but once the caller returns it will cease to
exist, and yet myData will continue to refer to its location.  At the
very least, the documentation for f4 must clearly state that one may
only pass the address of permanent values like globals or other
static locals.


Examples like these make great test questions –
just sayin'... :)




	
	
	
	
	
	
	






In this lecture segment we'll look at binary file
I/O, using the Unix system calls for file I/O as an example, though
other operating systems offer very similar calls.


	


This and the following segments assume you are
familiar with the use (not detailed contents of ) the 
type, the 
stream, and the standard C I/O functions fopen,
fscanf, fprintf, getc, putc, getchar,
putchar

fclose
If you have prior background in binary file I/O,
some of this lecture may be review, but look it over carefully anyway
to be sure you understand all the details.  We'll include some
important deeper advice about binary input and output.

Until now, all file I/O discussed in this and
prior courses has involved reading or writing files of text – files
you could bring up in an editor, or print to screen.  The library
functions fopen,
fscanf, fprintf, getc, putc, and fclose do such file
I/O, and you use them in a way very similar to the standard printf,
scanf, putchar, and getchar that operate on the
keyboard and screen.  You're just replacing keyboard and screen with
input file and output file.  Let's call this text
file I/O.
Text file I/O is actually a specialized type of
file I/O, using files to contain readable text.  But files are a more
general concept than just “text holders”.  A file, in Unix,
Windows, OSX, or any other current OS, is a indexed
series of bytes on disk or some other storage medium.  It's akin
to an array of unsigned chars in C, and like the unsigned char
elements of such an array, the bytes of a file need not contain ASCII
codes representing text.   Each byte in a file may be assigned any
value from 0 to 0xFF or 255.  \
A text file just happens to use its bytes to hold
ASCII codes.  Our diagram shows a text file containing 123456, and a
second view of it, showing the actual bytes in the file in binary
form – the ASCII codes for '1', '2', '3', '4', '5', and '6'.

This means that fully 1/8 of the data in every
text file is in effect wasted, in that it is the same regardless of
the text contents.  What data is that? 


The top bit of every byte in a text
file is 0, since all ASCII codes are less than 128, or 0x80.



So, what can we do with the bytes of a file aside
from reading and writing ASCII codes?  We can make direct copies of
memory into them.  For instance, if you have an 
variable 
containing value 123456 (hex 0x0001E240) you can write it into a file
as text, using 6 bytes of the file to contain, literally, the ASCII
values 49, 50, 51, 52, 53, 54 for the digits 1 2 3 4 5 and 6.  Or you
can write the four bytes of x directly into 4 bytes of the file:
0x00, 0x01 0xE2 0x40.  Any variable – int, double, array, etc. can
be directly copied from memory into the bytes of a file, and read
back again, using functions we'll be looking at shortly.  Let's call
this 

What happens if I write x in binary form, and then
display the file as text on screen or in an editor?

It will look like gibberish.  In
paricular, the file would be treated as though it contained ASCII
codes, 0x00 is a NUL, which prints nothing, 0x01 is control-A, 0xE2
isn't even an ASCIi code – it would probably show as some odd
character depending on the system configuration.  0x40 is the only
byte that's actually a printable ASCII character.


Files with direct copies of internal memory
generally make poor text, and printing them results in “Lucky
Charms” all over your screen.  Files with such memory content are
usually termed and they're
very different from text files.  (The same file system is used for
either; the description  or
 refers to the contents itself,
not some property of the file.)

Just to drive home the distinction, and to get a
better grasp on the tradeoffs, let's do a bit of thinking on the
relative advantages of the text vs binary approach to storing data in
a file.  As a model, let's imagine we have an array of 1000 4-byte
integers to write into a file, either in text form, with say one
integer per line of the file, or in binary form, with exactly 4 bytes
in the file per integer.  I've drawn both cases here in the diagram,
at least for the first few integers.  (Don't be fooled by the larger
appearance of the binary data – it's drawn out at the bit level, so
of course each 8 bits is the same size as one symbol in the text
file)

er
for the machine to do: write the
ints as text, or in binary
form?  Consider the 
example from the lecture on 

It's faster for it to write it in
binary, since this involves a simple copy of memory data onto disk. 
Writing in human-readable base-10 is “unnatural” for a computer,
and involves a looping computatoin like that for the %u format
specifier in the example printf function from the varargs.h lecture.


The time required to do numerical text I/O is
often overlooked, but it can be important.  It gets even worse for
floating point data, with decimal points or exponential notation. 
Writing a 
in binary form is a simple 8-byte copy from memory to or from file. 
Writing it in textual form involves a loop of double-precision
computations that is comparable in complexity and time to performing
a square root, or a trig function.

Which is more machine-portable: text or binary? If
I write a file on one machine and read it on another, which form is
more universal?

Text is the same on any
architecture, but direct memory copies run into endianness issues. 
If you write a 4 byte int on a little-endian machine, and read it on
a big-endian machine, it will need to have tis bytes reversed.
  

This is the only major portability problem,
however.  Internal representation of integers and of floating point
is highly standard across all modern CPUs, modulo the endianness
issue.  The usual convention is to write all binary data in
big-endian order, placing the burden of reversing the bytes on the
little-endian machines.  This is sometimes called “network order”
because it's the standard for all binary communications on the
internet.
(An aside here that bears note in an international
software world:  text format is culturally
portable, because the notation used for fractions differs per culture
– many languages use a comma where English uses a decimal point.)

OK, so which is more compact?  This is a complex
question; you may not find a clear answer either way, but at least
think through when one or the other would be more compact.

Binary is more compact if it takes
more than, say, 4 bytes per int to write in textual form.  But for
small ints, text format may be more compact.


Importantly for the upcoming question, text format
requires some separator, e.g. a space or end-of-line, between values,
while binary format does not.  Integers or other numeric values are
of varying length in text form, depending on their value, but they
have fixed length in binary form.  The unpredictability of length
means you can't just jam all the text ouput together without a
separator between each value.
As we get further into file operations, we'll find
that you do not need to read or write a file from beginning to end. 
Any OS allows you to within a file –
to move directly and quickly to any offset within the file, and read
or write data starting at that offset.  So, files may be randomly
accessed, just like arrays.

Which format is better for random access?  If I
ask you to get the 500 integer in a file of 1000
integers, would you rather it be a text or a binary file?

Binary is better because the size of
each datum is predictable.  The 500 integer in a binary
file starts at offset 499*4 == 1996, since 499 4-byte integers
precede it.   The offset of the 500 integer in a text
file depends on the number of digits needed for the prior 499
integers, which can be determined only by reading each one starting
with the first.


So, summarizing: Text is humanly readable, and
more machine portable.  Binary is faster to read and write, and is
randomly seekable.  Size of data is a tossup (though in practice
binary is a bit more compact because text often includes extra labels
and markers).
In the next segment, we'll go through a program to
translate a text file into an equivalent binary file, and introduce
the library functions (technically “system calls”) for binary
file I/O on Unix.






	
	
	
	
	
	
	






In this lecture segment we'll look at the Unix
system calls for binary file I/O.  These are not C standard, but
they're a good example, and other operating systems offer very
similar calls.


	
	
	


We'll be looking at the TextToBinary.c example
program, which uses several library functions for opening, writing,
and closing a binary file: open,
write, .
 

But, these are more than just library functions. 
They're A system call is a
library function supplied by the operating system (e.g. Unix) itself.
 To a rough approximation, an operating system is
a big library of functions (system calls) for performing actions
that require special privileges.  These include opening, reading, and
writing disk files, starting other programs, communicating over a
network, etc.  

A typical OS provides several hundred different
system calls.  These are collectively termed the operating system
, to differentiate these core
functions from OS-related utility programs like editors, compilers,
etc. which are independent C programs.  Any action on your program's
part that uses I/O devices (display, keyboard, mouse, disk, network
interface, etc) or that involves controlling other programs (starting
them, pausing them, arranging communication with them, terminating
them, etc.) requires a system call.
like
normal functions, but calling them involves shifting the CPU to a
more privileged mode that allows hardware access and control over the
MMU, a mode not normally granted to ordinary running programs.  The
object-code translation of a system call uses a special machine
language instruction that says, in effect “Call this operating
system function, and go to privileged mode”.   You can't just say
“go to privileged mode”; the instruction requires
the call into the OS kernel, as part of granting the privilege. 
Otherwise a malicious program could grant itself privileged mode to
run code of its choice.  Your program gets the privileged mode, but
at the cost of running an OS system call, which can be presumed to
behave responsibly.  


Given this description, what would you guess is
one of the last things every system call does regarding CPU mode,
before returning to the nonkernel code that called it?

Turn off privileged mode.  The whole
system is airtight; you can't get privileged mode while running your
own code.  You get it only when running OS code, which  revokes it
before returning to your code.


In most operating systems, the operating system
kernel is mapped into each program's virtual memory (in Unix, often
as the final 1G or so of space), with one physical copy of the kernel
appearing in every virtual space, in the same manner that several
running copies of the same program may share the same physical copy
of a text segment (ref the earlier lecture on process space).  But,
interestingly, the MMU does not allow your program to even read
that area of your virtual space, let alone write into it, unless
the CPU is in privileged mode.  

So, you get the odd result that your program in
effect “includes” the entire operating system kernel as a big
library in its virtual memory space, but sharing the same physical
copy with all other running programs, and without being able to even
look at it, unless it shifts to a privileged mode by jumping into
kernel code that requires the program to behave responsibly.
This very brief discussion is just the tip of the
operating system iceberg.  A full operating system course would give
you details on the mechanics of system calls, the design of an OS
kernel, etc.

So, having discussed system calls, let's look at a
program that uses a few.  The TextToBinary program reads a textual
file of student data, comprising an integer id, a string name, and a
double GPA for each student, as shown in the diagram.  It writes out
an equivalent binary file, for which we show a binary dump in the
diagram (more on that later).

The program expects commandline arguments for the
name of the text file to read, and of the binary file to create and
write.  The command we'll run is shown in the diagram:  TextToBinary
Students.in Students.out.  Lines 16-19 check for the
right number of arguments, giving an error message if needed and
ending the program with .



in prior C work.  Where do you think the code for that function
resides, given that it stops a running program?

As the question implies, exit is a
system call, and its code resides in the operating system kernel. 
(Technically, on Unix, it's a small library function that in turn
makes a system call, but that's a detail we won't get into here.)


Starting and stopping programs is an OS privilege.
 Your program isn't even allowed to kill itself
without making a system call to do so.  (By the way, falling off
the end of 
results in an 
call that is automatically added by the compiler.)

Lines 21-22 open the text and binary files.  Line
21 uses the familiar 
but line 22 uses the system call 
to open a binary file.  We'll look at its parameters in a bit, but
first an important question.  If opening a file is an OS privilege,
then isn't 
also a system call?  It opens a file, after all.  


is the only system call for opening a file.  
.
 The standard I/O library functions all ultimately call system
functions to do the real file I/O.  The standard I/O library does all
the translation to and from textual ASCII codes, which the binary I/O
system calls don't know how to do.  But, ultimately the ASCII codes
get written to or read from files using the binary I/O system calls,
which can read and write raw ASCII data as easily as any other kind
of data.  We'll look much more closely at the standard library in an
upcoming lecture.

is the filename, as it is for .
 The second parameter determines how the file is opened, e.g. for
reading or writing, as for ,
but 's
second parameter is an int, not a string.  Each bit in this flag
int represents a different option.  You pass an integer value
with 1-bits for the options you want, and 0-bits for ones you don't
want.  The header file 
supplies #defines giving 1-bit masks for different options, which
makes it easy to assemble a single int with the right 1-bits by
simply or-ing together the relevant masks.  On line 22, we “or”
the O_WRONLY mask for write-only file access, the O_CREAT mask for
creating the file if it doesn't already exist, and the O_EXCL mask
for insisting that the file not already exist when we open it.  (This
prevents accidental overwrite of existing files.)
This pattern of using a flag int to express
options, with #defined masks you “or” together to create flag int
values, is extremely common in system calls – something to get very
used to.  The convention of prefixing the #defines to reflect the
call to which they belong, e.g. O_ for open, is also ubiquitous.

Do some external research, and figure out what
bits to set in 's
flag int in order to create a file if it doesn't exist, and if it
does exist, to clear its current content so we can write new
contents.

O_CREAT and O_TRUNC are the flags
needed, without O_EXCL.



is also an int, expressing the file permissions to give any new file
created by .
 (This does not modify permissions if you open an existing file.) 
The bits here are just like those for the 
command, with which you should be familiar, which is why the integer
is given in octal.  Whatever octal value you'd give 
to set permissions for a file, you may use unchanged here, as long as
you add the C-required leading 0 to make it octal.

Look up chmod, and set file X to have permissions
rw-r-xr-- using octal notation.  Test this with ls -l, see if you get
rw

chmod 654 X  And if you were
creating a file with open, and wanted those permissions, you'd use
0654 as the third parameter.



returns an integer .  Every
file your program opens is labelled by a file descriptor number,
starting with 0.  Any other system calls you make to work on that
file, e.g. to read or write data, expect the file descriptor as their
first parameter.

call, the call returns -1, which we check on lines 25-26.  Those
lines give a generic error message, but 

ou
can check  exact value to give
specific error messages.  Predictably, there are #define constants

 with names reflecting the
error in question.

More external research.  (There's a lot of this as
we get deeper into system calls.)  What is the #define constant for
the negative integer that 
returns if you use ,
but the file already exists?  And, is there a naming convention for
error constants?

EEXIST, and all error constants
start with E,for error.


In the next segment, we'll finish up the
TextToBinary.c example.




	
	
	
	
	
	
	






In this lecture segment we'll finish up the
TextToBinary.c example, introduce more file I/O system calls, talk
about standard file descriptors that are always open, and do some
octal dump debugging.


	
	
	standard in, standard out,
	standard error (v)
	



So, now that the binary file is open, how do we
write data into it?  As you can see, line 28 loops through the
textual input file, reading id,
name
into a struct .
 Lines 29-31 copy those binary values into the output file using
system call write.
This call has three parameters.  The first is,
predictably, the file descriptor of the open file to which to write. 
The second is a memory address from which you want to copy bytes to
the file – any memory address you like.  And the third parameter
tells how many bytes to copy.  A 
operation is typically used for this parameter.   


will copy any memory you like, from any location, into the file.  You
just tell it the file descriptor, the starting address, and the
number of bytes to copy.  There's a partner to 
called 
which we'll covered in a later lecture, but we'll find its parameters
are identical to those of write: a file descriptor, a memory address,
and a byte count.  The only difference is that 
works in the other direction, copying the specified number of bytes
from the file into the indicated memory location.


calls happening in this program.  Where and why?

As we discussed earlier, the system
binary I/O calls are the only way to work with a file.  All the stdio
library functions, including fscanf, call them.  When fscanf needs to
get ASCII data from the text file, it calls read to do so, and then
translates the textual ASCII into internal binary form.


Line 30 does have one small detail: it writes the
entire 
char array into the file, rather than stopping at the ASCII NUL that
terminates the string.  With a small loop writing one char at a time,
we could have avoided writing bytes past the NUL.

Why didn't we write that small loop?  What would
we lose by stopping at the NUL instead of writing the entire array?

Recall that predictable size of data
makes binary files randomly accessible.  Sometimes it's worth a few
extra bytes to preserve that, as we're doing here.



is not limited to individual data items.  Line 30 obviously writes
out an entire array with one call, and we could also have replaced
lines 29-31 entirely with the commented call on line 32, which writes
the entire struct 
to the file, in one step.  But, interestingly, you'll get different
binary file contents if you run line 32 than if you run lines 29-31.

Why is that?  In particular, you'll find that

is 32, which is more than the total size of ,

and .
 We've discussed this briefly in an earlier lecture.  Why is the size
of 
32?

This is a “padding” problem. 
8-byte doubles, at least on the architecture in question, must start
on an 8-byte boundary.  But the preceding 20 bytes for id and name
don't end on such a boundary, so 4 padding bytes are added to the
struct betrween name and gpa.  And the resultant binary output will
have those four extra bytes.


This is an important subtlety of binary I/O we
didn't discuss in the plusses-and-minusses section earlier, because
it's hard to explain until we get to an example like this.  If you
write binary data in large struct chunks, the result may be
architecture dependent because padding rules vary by architecture,
the same way byte ordering does.  For this reason, you'll often see
binary I/O done field by field, instead of in entire structs.

close,
on line 35.  This is passed the file descriptor and it
closes the file.  It's more than just a niciety, however.  Forgetting
a close call, especially in a program that opens and closes a lot of
files, is a classic nasty bug.
To see why, it helps to know that the file
descriptor is actually an array index, into an array of open files
that the OS kernel keeps for each running program.  This array is of
limited size, and thus a given running program may keep only so many
files open at a time.  Closing a file frees its kernel array entry
for reuse, in much the same fashion that 
releases runtime heap storage for reuse.  So forgetting a 
has the same effect as a storage leak – do it too many times and
you run out of open files.  The classic effect is failure of 
partway through the program.  


Just to drive this important point home, what
error constant does 

in such a case – more external research.




in ,
you'll find it's 3, not 0.  This would imply that 3 files were
already open by the time we did the 
call on line 22, and that's the case.
Every C program starts with three files already
opened.  These are provided by the operating system, with no need for
an 
call by the program.  They have file descriptors 0, 1, and 2.  Let's
call these the and

files, respectively.  As the names imply, standard in is open for
reading, and standard out and error are open for writing.
In a typical program run, the standard in file is
the keyboard, and both the standard out and standard error files are
the screen.

output
file​? Yep.  Unix has a remarkably flexible definition of
“file”, and other operating systems have followed its lead on
this.  The essential expectation we have of an input file is that we
can read it to obtain bytes of data.  This is certainly true of a
disk file, but it's also true of the keyboard.  From the point of
view of your program, the keyboard is an input file, from which may
be read the ASCII characters you're typing.  It's a kind of slow
file, and every once in a while it requires an hour to read the next
few bytes because you left for lunch in the middle of a program run,
but it's a file just the same.  You've already seen this from the
user standpoint.  You know for instance that the keyboard input has
an “end of file”, marked by control-D in Unix.  The program view
of this is the open standard-in file descriptor 0.
Similarly, all we expect of an output file is that
we be able to write bytes to it, and the screen certainly qualifies. 
When your program writes ASCII codes to file descriptor 1 or 2
(standard out or standard error) they appear on screen in normal
situations.
You are also familiar with file redirection in
Unix or Windows, using &lt; or &gt; to cause a program to read from a
file instead of the keyboard, or write to a file instead of the
screen.  All that is happening when you redirect input or output is
that the shell program that runs your commands arranges with the
operating system to set up standard in and standard out file
descriptors that read from or write to files instead of the keyboard
and screen.  Your program is none the wiser, and simply thinks that
you've become a really fast typist.  This is a good example of the
elegant design that comes from a broad interpretation of “file”.
This flexible definition of “file” extends
further than just the keyboard and screen.  If you open an internet
connection to a web server, each end of the connection appears to be
a “file”, with an integer file descriptor.  One program sends
data by writing to this “file”, and the other receives it by
reading from the “file”.  In an upcoming lecture, we'll set up
something called a  between two
programs that works similarly.
So, why are there two output files: standard out
and standard error?  Because when you redirect output to a file,
there may be some data you still want to appear on screen.  If your
program prints an error message “Warning, this will erase the
disk.” you'd like the user to that on
screen, rather than redirecting it to a file.  When you redirect
output with &gt;, it is only the standard out that goes to the file;
the standard error remains directed to the screen.
These three standard files appear at the binary
file level as open file descriptors, but the standard I/O library
also represents them as FILE pointers stdin,
stdout, stderr.
 We'll look at just how those work in the lecture on
the standard I/O library, but for now, note that fprintf(stderr,
...  writes to standard error – file descriptor 2,
while 
writes to standard out – file descriptor 1.  By convention, error
messages are fprintf-ed to stderr, as on lines 24 and 26

Finally, let's look at the file our program has
created.  The listing in the diagram is an octal dump of
,
produced by the Unix 
utility.  Similar binary file dump or editing utilities are available
in any OS.  They show the file content byte by byte, usually in hex
or, in the case of 70's vintage apps like ,
in octal.  This particular listing, with the 
command options, shows 16 bytes per line, in octal, and then repeats
them on the next line, as a character if the byte holds an ASCII
code, or as an octal value if it does not..  The second line makes it
easier to see which byte values are characters from the 
strings.  And, finally, along the left are the file offsets at which
each line-pair starts, also in octal (so 0000020 indicates offset 16,
for instance).
Deciphering an octal dump is a critical debugging
skill if you're working with binary files, so let's piece through the

dump, and answer these questions:


come from?  Is that really an end-of-line character?  (Note that this
was produced on a little-endian machine)

It's an EOL if you look at it as
ASCII, but it's really the LSB of Staley's ID number, which is10
(octal 012).


It's interesting that there's no way to tell what
“type” the binary content of a file is (e.g. an ASCII code or the
first binary byte of an int) without knowing how the program that
wrote it generated the output.

Where does the data for Staley's name begin and
end?

We wrote out the entire array, so it
starts 4 bytes into the first line
and ends 4 bytes into the second (16 bytes per line, remember).  But
it may also be said to end with the \0 after the 'y', since that's
the terminating NUL.

What is the 014 byte at the end of the second
line-pair, and what are the 8 bytes preceding it?

That's the id for Wu (decimal 12) preceded by the
8 bytes of Staley's gpa.  Don't try to read those 8 bytes –
floating point binary representations are crazy.

Why is there an “ley” after “Wu” on the
third line-pair?

Leftover garbage from the “Staley” that was in
the 
array prior to .
 The NUL after the 'u' means it will be ignored.




	
	
	
	
	
	
	






In this lecture segment we'll look at more
advanced binary I/O concepts, including seeking, and file metadata.


	
	
	end of file issues in
	binary data
	


We'll illustrate the concepts with a TrackStudents
application that creates a file like the one in the prior lecture: a
binary file containing a series of student data, with an integer id,
a name, and a gpa per student.
TrackStudents takes the filename as a commandline
argument, and treats the file like a small database, opening it and
allowing three commands:
add &lt;id&gt; &lt;name&gt;
&lt;gpa&gt;   -- adds a student to the end of the file
drop &lt;id&gt;                
         -- removes student with specified id from the file
find &lt;id&gt;                           -- finds
and prints student with specified id.
The sample run in the diagram illustrates the
commands.  It starts with an empty file Test, adds a couple students,
finds one, fails to find another that isn't there, adds a third and
then drops one.   The 
dump that follows shows the resultant file.


data in this test run?  Examine the od dump to determine this.

None.  (The run was made on a
machine that didn't require 8-byte alignment, unlike the run from the
prior lecture that resulted in padding.)

TrackStudents.c.
After checking argument count on lines 19-20,
TrackStudents attempts to open the file for reading and writing,
creating it if necessary.  To report an error in opening, it uses the

variable described earlier, but passes it to ,
a standard library function that returns an English string
corresponding to the error number passed to it.  Internal program
logic is easier if you check 
against integer constants, but printing error messages (at least in
English) is easiest if you use .


What's the lowest positive integer that is not a
valid error code?  Determine this by writing a two-line loop in C
that calls .
 Crank out the first 100 or so 
messages and see what they look like.

Error code 47 gets “Unknown error
47” back from strerror.  It's the lowest such number; all lower
ones have meaningful error strings.

Once the file is open, TrackStudents determines
and prints the number of students in the file, for which it requires
the size of the file.  

Every operating system provides some means of
getting 
filesize, access permissions, dates of modification and
creation, etc.  File metadata is any information having to do with
the file that is not actually content of the file.  


or both
of which return a struct
stat object with fields giving the metadata values. 
Line 24 calls ,
passing the open file descriptor and the address of 
which 
fills in with the metadata of the file.  Lines 25-26 use the 
(file size in bytes) field of 
to determine the number of 
structs in the file, dividing by the size of a 


and 
 Look them up online.

lstat accepts a filename; you don't
need an opened file descriptor.

On Windows, what function gets file metadata like
size, modification dates, etc.?  (There are several.  Any reasonable
answer is fine here; just do the research.)

GetFileInformationByHandle, or its
cousins, are good examples.

Look up the
fields of struct
stat
to determine if all users had permission to read the database file.

The st_mode field has the same bit
content pattern as the third parameter of open, representing file
access permissions, so the test if (stats.st_mode &amp; 04) would
check if the world-readability bit in st_mode were set.

As mentioned in prior lectures, a file may be
viewed as an indexed series of bytes, rather like an array of
unsigned chars.  The 0-based “index” of a file byte is called its
Normally, file read/write
operations start at offset 0, and advance through the file, with the
offset increasing as they go.  So, file operations differ from arrays
in that there is always a 
within the file – which some programmers visualize as a marker
showing the point where the next read or write will occur.  And,
unlike an array, the very act of reading or writing causes the
current offset to advance by the amount that was written or read.
To allow general random access in a file, all we
need is a way of adjusting the current offset to any location in the
file that we please, without doing reads or writes.  This is called
 in the file.  Every operating
system provides a means of doing this, at least for files on disk or
similar random-access storage.  (For obvious reasons, one may not
“seek” a file that is actually the keyboard or terminal.)  

“Seek” is used in both noun and verb form: “I
did a seek” or “This line seeks to offset 100”.  And oddly, the
past tense usage is “seeked”: “The program seeked to EOF”,
not “.. sought to EOF”.
lseek.
There's an example on line 24.  Its first parameter is
an open file descriptor, and the second is an offset to which to
seek.  That's simple enough, but the third parameter makes it a
little more interesting. You may specify three different starting
points from which to seek, by passing different integer constants as
the third parameter.  

If you pass SEEK_SET, you get the obvious option –
seeking from the start of the file.  Line 34, for instance, moves the
current offset to the start of the file.  

If you pass SEEK_END, you are seeking relative to
the end of the file.  The second parameter is usually 0 or negative
in this case, so you seek to the end, or to some number of bytes
before the end.  But, as we'll see in a bit, one may also see 
the end of file, using a positive offset with SEEK_END.  The example
on line 30, for instance, seeks exactly to the end of file.
The third option is SEEK_CUR, on line 43 for
instance, which seeks relative to the current offset, skipping
forward (with a positive second parameter) or backing up (with a
negative second parameter) from the current offset.  


is whatever the new current offset is, and this is always relative to
the start of the file, regardless of the third parameter.

lseek(fd,
lseek(fd, 0, SEEK_CUR), SEEK_SET);

Absolutely nothing.  The inner lseek
call doesn't move the current offset, and it returns the current
offset, which is then used by the outer lseek call, relative to start
of file, so this again doesn't move the current offset.



understood, let's continue looking through the TrackStudents code.
Line 27 repeatedly scans for a command and an id
number, which all three command types require.
Lines 28-32 handle the “add” command, scanning
the additional name and gpa required by that command, and then
seeking to the end of the file, and writing a new 
struct there.   Writing past the end of file is allowed, and simply
increases the file length.
Lines 33-50 handle the “find” and “drop”
commands.  Both start by moving the current offset to the start of
the file (line 34), and then looping through the file, reading
Student structs until one is found that matches the entered id, or
until we hit end of file.


used in code, though it was described in a prior lecture.  Its
parameters are just like those of ,
but it copies data from the file, into memory, instead of writing it
out.   Those parameters again are: the open file descriptor, the
location in memory to which to copy data, and the number of bytes to
copy from the file.
s
return value is the number of bytes successfully read.  Normally this
is the same as the number you requested in the third parameter (e.g.
),
but it may be less if there are not that many bytes left in the file.
 In a well-organized case like our lines 35-37 loop, we expect either
to get all bytes requested, or none at all if we have read all

structs in the file and are at EOF.  In the latter case, 
returns 0, and in general a return of 0 from 
shows that you've hit the end of the file; there's no other situation
that would make that happen.  Importantly, read does not return the
EOF constant – that's standard library behavior, not system call
behavior, and we'll see how it works in a later lecture on the
standard library.

returns a negative value is if there's an error, such as a bad file
descriptor or a negative requested byte count, and in this case 
sets ,
like most of the other system calls.
Returning to TrackStudents, we see that line 38
checks whether we've hit EOF, and if so indicates that the id entered
was not found.  Otherwise, if the command was “find”, we simply
print the student data.  

But the “drop” command is a little more
complex...

TrackStudents implements “drop” by copying the
last Student in the file on top of the Student to be dropped, and
then shortening the file to remove the last student.  (If there are 5
students, and we want to drop the third, then TrackStudents preserves
the fifth by copying it on top of the third, and then reduces the
file to just 4 students.)
This “copy down the last item and shorten the
data” trick is useful when you don't care about the order of the
data, and when moving a bunch of elements to close a gap is slow or
inconvenient.
Line 43 starts this process by recording the
offset at which the student we want to erase resides.

?
 What does that do?

We just read the Student we want to
delete, so the current offset is at the Student after it.  The
subtraction adjusts it to the start of the Student to delete.  
Remember that reading or writing automatically moves the current
offset.


Line 44 moves the current offset to the beginning
of the last student in the file, backing up one 
struct size from the EOF, and records that offset in .
 Lines 45-47 then read the last student, move back to the location of
the student we wanted to drop, and write the last student on top of
the student to drop. 


The final step is shortening the file.  System
call 
does this, taking as parameters the open file descriptor and the
desired new size.  If the last student was at, say, offset 64 indexed
from 0, then reducing the file size to 64 drops the last student.
You may seek past the end of file if you like,
even say 1000000 bytes past the end of the file, for instance, and
write data at such a location.  All bytes between the original EOF
and your new data are automatically filled with 0's, and the file's
size automatically expands to include the new data you wrote at the
past-EOF location.
That sounds like a recipe for using up a lot of
disk space very quickly.  If you seeked to offset 4 billion and wrote
a byte or two, would Unix really fill 4 billion bytes of disk with
0's?  No, it's more clever than that.  The file system records the
fact that you have all those zero bytes nominally in the file, and if
you try to read them, the 
system call will return 0's as if they were really on the disk.  But
it's a smoke-and-mirrors game, with no disk space actually used to
store the added zero-padding bytes.  If you actually write to those
intervening offsets, then real disk is used, but not otherwise.




	
	
	
	
	
	
	






In this segment and the following two, we'll look
at how the “standard I/O library” (stdio) works under the hood,
and how all its functions ultimately call binary file I/O calls to do
the real I/O.  We'll walk through an example implementation of
stdio.h, and the stdio.c file that goes with it.


	
	
	
	
	


Binary system calls are the “true I/O functions”
supplied by the OS, but they have significant drawbacks.  First and
foremost, they don't do any translation to and from textual numbers
and internal binary representation.  If a user types “123456” or
if a file contains that text, then a 
call will return 6 ASCII codes, not the binary integer value 123456. 
Also, it's difficult to use binary calls for formatted text data in
general.  There is no way, for instance, to tell 
to read only up to the end of the current line of input. 

And system I/O calls can be very slow, especially
if they're working with a disk file.   Finding and reading or writing
information on disk requires several milliseconds, which is enough
time for a typical CPU to perform several million machine language
instructions.  So, it makes sense to read and write files in large
chunks, perhaps several KBytes at a time, rather than just a few
bytes at a time.
,
generally abbreviated fixes these
problems.  It provides functions (e.g. printf,
scanf) that do text &lt;-&gt; binary translations, and
it buffers I/O, doing reads and writes in large blocks.

The real stdio library is implemented in the
stdio.h/stdio.c file pair.  You routinely #include stdio.h, but you
rarely see stdio.c, since its stdio.o object file, along with certain
other standard libraries like those for malloc and free, is
automatically linked in by the compiler.
To explain how stdio works internally, we'll walk
through an example implementation of it that works very much like the
real one, though with less cumbersome detail, and without providing
the entire library of functions.  Our example's functions and macros
are named identically to the stdio equivalents, but capitalized, and
with an 
prefix, so they don't clash with the real ones when we compile the
example.


mimicked by our 
type on lines 7-13 of AltStdio.h.  As you know from using stdio, any
open file is represented by a pointer to a 
Our 
has the same type of content as stdio's FILE.


it manages an open file descriptor, held in its 
field.  It also holds a buffer of data for the file.
Buffered reading requires fetching data in a large
block, e.g. 1K, from the file, and then holding onto that data until
,

or similar calls need it.  By serving many ,

or other calls with the same large 
operation, we cut down on highly-expensive disk fetches.  

Buffered writing works the other way, gathering
output from ,
,
or similar calls into a buffer, until a large block of data has been
accumulated, and then writes all the accumulated data in one 
call.  

In either case, we need three critical data: the
buffer, a pointer to the next unused location within the buffer, as
we consume it for reading or fill it for writing, and the buffer
size, which as we'll see is sometimes not the full length of the
buffer.  These are held in 
,

and 
fields respectively.

field, ,
is a flag integer with bits for various file states, such as whether
the file is open for reading or writing, or has reached EOF.


structs as needed to represent files, but like the real stdio, our
example library declares a single global array 
on line 15.  This contains all 
structs that will exist.
Since we are allowed only a fixed number of open
files at a time anyway, it makes sense to do this.  Also, as we'll
see when we look at the 
array definition in ,
array initialization syntax lets us easily initialize the first three

structs to work with the file descriptors 0, 1, and 2 that are
automatically open when the program starts, per earlier lectures.


comprises prototypes for the stdio functions for which we'll provide
alternate versions, plus a few macros we'll look at later.  Let's
start with the most fundamental operations: altGetc,
altPutc, 


illustrates the basics of stdio buffering.  All of them assume an
already-open ALT_FILE
s
in a bit.

the analog of stdio's ,
writes a char to an .
 It assumes there is at least one open space in .
 Line 17 puts the char into the next open space, advancing .
 Lines 18-19 check to see if 
is full (if 
is pointing past the end of the usable buffer space), and if so, they
call 
to write out the buffer and clear it (more on 
in a moment).

the analog of stdio's ,
gets the next char from an 
that is open for reading and returns it as an int.  On lines 23-24 it
checks first to see if the buffer is empty, calling 
to fill it if so.  Then, having ensured a full buffer if possible, it
returns either EOF if the 
flag is set, meaning we've hit end of file, or returns the next char
in the buffer, advancing 
,
the analog of stdio's ,
is a critical function.  It's the only one that actually reads or
writes data.  It starts with an error check on lines 32-33, returning
EOF, as the stdio 
does, if the ALT_FILE

of -1) or if the file has reached EOF.  Then lines 35-39 handle the
read case, reading in a new buffer of data from 
into ,
attempting to read up to 
bytes, and recording the actual number read in .
 



being 0?  What does that signify?

Recall from prior lecture that read
returns 0 when we've reached EOF.  If we have, then line 38 ors
FILE_ATEOF into flags.  




becomes the new .
 In general, 
may be less than the total size of the 
array, if there are fewer useful bytes in ,
in particular if we weren't able to read an entire bufferful. 

Line 42 handles the write case, writing out all
bytes between the start of 
and .
 And, in both the read and write cases, line 44 resets 
to the start of the buffer, and line 45 returns 0 if all is well, or
EOF if there was a 
or 
error, like the real 
does.
In the next segment, we'll look at opening and
closing files, and at some of the macros.






	
	
	
	
	
	
	






In this segment we'll look at our “alt”
versions of the stdio fopen

calls, and several stdio macros.


	
	



is the analog of stdio's .
 It opens an 
given the file name and a string describing the mode.  Lines 52-53
hunt 
for an unused entry – one with an 
of -1.  Assuming one is available, lines 56-58 point 
to it, start 
at the beginning of the entry's ,
and set 
to show open for reading if 
starts with 'r' (otherwise open for writing is simply assumed).  


gets 0 if the file's open for reading, since there are no buffered
bytes read in as yet, or 
if it's open for writing, since all 
bytes are available for writing.
Lines 60-61 actually open the file via system call
,
saving the 
that results.   Second parameter mode bits are set appropriately (a
question on that in a moment).  And line 64 returns an
ALT_FILE 
element, for use as a parameter to other calls like altGetc
altPutc.


Look closely at those second-parameter bits on
line 61.  If we open for writing, and the file already exists, what
happens?  What if it doesn't exist?

We open with mode O_TRUNC, so
existing file content gets erased.  We also open with O_CREAT, so the
file gets created, with permissions 0644, if it doesn't exist.



What happens if we open an empty file, one with no
bytes, for reading?  Explain whether the first call of 
on the file returns EOF or not, and exactly how if so, tracing the
and

calls.

altFopen leaves the read buffer
empty by setting next = buffer and bufSize = 0.  On the first call of
altGetc, the line 23 test is true, resulting in an altFflush.  That
call in turn does a read call with a 0 return, setting the FILE_ATEOF
flag on line 38.  The altGetc return on line 26 picks this up and
returns EOF.


Note that questions like that one make good test
questions.


opens a file for writing, bufSize is set to BUF_SIZE.  Is it always
the same as long as that file is open, or does it change for that
file, and if so when?

It remains the same throughout the
file's open time.  The full length of buffer is always available to
“queue up” output.  By contrast, a partially-filled read call on
line 36 may result in a shorter bufSize for a file open for reading.

Lines 6-10 define and initialize the array
.
 Most of the entries set 
the first field in the struct, to -1, marking them as available for
use by .
 But, the first three have nonnegative 
fields, because they represent the guaranteed-open file descriptors
0, 1, and 2 for standard input, output, and error.  (Ref earlier
lectures on these three file descriptors.).  Their next,
flags
values are also initialized as if they had been opened by 
for reading or writing, but with one important exception:

What is that one exception?  Which of these three
elements of altFiles

would have initialized it to?

altFiles[2], for standard error,
file descriptor 2, has a bufSize of 1, not BUF_SIZE, as would be
expected for a file open for writing.




of 1?  How does it affect the behavior of altPutc calls done on
,
the standard error?

The small bufSize means that each
char of output is immediately flushed so nothing stays in the buffer.
 Line 18 is true on every call of altPutc.


This is reasonable for standard error output,
which is used only for important error messages that must not be lost
by redirection to a file.  It's also important that they not be lost
because of a program crash that wipes out buffer data before the
buffer can be flushed.  (Ref earlier lectures on subtle problems
using debugging printfs due to buffer loss.)
&amp;altFiles[0],
&amp;altFiles[1], 
as the 
pointers when working with standard input, output, or error,
respectively.  But the library user really isn't supposed to know
about the 
array, except via the ALT_FILE
,
and it would be more convenient to have simple names for these three
important 
pointers.  So, lines 12-14 define altStdin,
altStdout, altStderr

elements for this purpose.  Any time we want to specify I/O on the
standard input, output, or error, we use one of these three globals. 
And, of course, the real stdio library's stdin,
stdout
work exactly the same way – they're just global 
pointers to the first three entries of the stdio library's array of



like its stdio analog ,
shuts down an 
struct and closes the associated open file.  This code is pretty
simple; its main jobs are to flush any remaining buffer content,
close the open file descriptor and reset 
to -1 so the ALT_FILE


Quick reality check question.  The line 73 call,
while accurate, is slightly wasteful.  Why, and what would we do to
fix that?

Calling altFflush is unnecessary if
the file was open for reading, and even results in a needless read
call.  Better to add an if-test to do this flush only for write
files.




were never initialized by .
 And programs are not generally responsible for calling close on file
descriptors 0, 1, and 2.  So do we need to call 
on altStdin,
altStdout ?
 Why or why not?  (You should find yourself worried about one of
these in particular.)

altStdout is worrisome, because it
might have unflushed buffer content.  Buffer content in altStdin is
just for reading, and doesn't need copying to file, and altStderr has
that 1-element buffer that gets automatically flushed each time.  But
altStdout needs to be flushed before the end of the program.
A 


on 
automatically after the end of main.  We don't get that courtesy for
our 
library, so we'll have to directly call 
on 
if necessary when the program ends.
Stdio Macros 

Let's look at some of the other I/O functions,
implemented as three macros on 
lines 25-28.  The first two of these, 
and ,
work like 
and 
of the stdio library (which are also usually implemented as macros
calling 
and ).
  They automatically do a 
or 
on 
or .
 Doing character gets and puts on 
and 
are so common that having macros for them is convenient.  

,
the analog of stdio 
is more interesting.  This one works directly with the ALT_FILE
fp.


First, what does it do and what does it return, in
non-error cases?  Also, what error cases does it test for, and what
does it do for those?

It “unreads” one character of
input, putting the “c” character back into fp-&gt;buffer and
backing up fp-&gt;next one byte via the assignment in the “true”
branch of the conditional.   In this case it returns the character
that was “unread”.  But, if fp-&gt;next is at the start of the
buffer (not greater than the start), or if we're trying to “unread”
an EOF, it leaves the buffer unchanged and returns EOF.


This is a remarkably useful little macro, as we'll
see shortly.  But it must be used carefully.


call, and haven't closed or otherwise disrupted the ALT_FILE

call?  A related question: why did we put the buffer flush in 
at the start of the function, instead of doing it at the end of the
function, the way we did in 

Yes, you always can do the altUngetc
call, and an important reason is that the buffer flush is at the
start of altGetc.  altGetc is designed so that it leaves the buffer
with at least one “used up” character so that there is room for
“unreading” one character.  After a successful altGetc call,
fp-&gt;next &gt; fp-&gt;buffer is true.



calls in a row are guaranteed to work. 
If we just started reading through a new buffer, there may be only
one char of room to “unread” a character.  The stdio 
has the same limitation.






	
	
	
	
	
	
	






In this segment we'll look at a sample main
program for our stdio knockoff library, and we'll look at our verison
of the two most sophisticated functions in stdio: 
and 


	



and 
provide limited implementations of the 
and 
functions from stdio.   We'll look at their code in a moment, but
first look at the 
file in the notes to see some example calls of them.  

altFprintf
to prompt for a name and a count on lines 9-10, and an

call to read them on line 11.  We're passing the 
and 
pointers to them, so these calls are like stdio's fprintf(stdout,
.. fscanf(stdin,
..  which are of course have the same effect as plain

and 
calls.  Pay special note to these three lines: they're a simple
prompt-and-reply, but they illustrate an issue we'll look at further
on.
The line 12-18 loop reads and sums a series of
integers equal in number to ,
and lines 19-20 print the total and then ask if another try is
desired.  Line 21 scans a 1-letter reply, skipping whitespace before
the character (format string “ %c”) and if the scan is successful
(return value of 1) and the answer is 'y', the process repeats.

Now let's look at the code for these functions. 

is easy.  It's a near-duplicate of the tPrintf
function from the lectures on variadic parameters.  The
only significant change is that altFprintf
ALT_FILE

calls to it, instead of 
calls.

is new, by contrast, and has several points worth comment.   You're
in a position to decipher much of this code by using the lecture thus
far and your prior knowledge of variadic functions, and I'll ask you
to do so with a series of in-lecture questions.  But first, let's
discuss a couple of design issues in this function.  

Line 128 gets the next character of input before
we even know what format specifiers are in the format string.  And,
in general, 
must read one character ahead in order to parse input.  For instance,
it can't know when an int (specifier %i) is completed until it reads
the first nondigit character after the int, nor can it know when a
whitespace-delimited string (specifier %s) is done until it reads the
first whitespace after the string.  So, throughout ,
we assume we've already read the next character into ,
and that we will read one character too far, and as you can see on
line 182, we repair this with an 
call at the end.

counts the number of format specifiers thus far successfully matched,
and 
remains true as long as no errors have been encountered.  Remember
that ,
which we're imitating, returns the number of format specifiers
successfully matched, or returns EOF.
So, with those points in mind, here are a few
questions on the main loop.  (Don't worry about lines 125-126 yet;
we'll come back to those.) 



pointer is advanced throughout the function.  It in fact advances by
exactly the same number of bytes on each execution of the line 141
.
 Why is that so?

Because all the variadic parameters
are pointers.  Be sure you see that every va_arg call fetches a
pointer of some sort from the parameter list.  And of course all
pointers have the same size in bytes.

What is the significance of the asterisk applied
to the 
calls on line 135 and 149?

Those calls return a pointer
parameter, and we must dereference the pointer to assign scanned
values into their targets.


skip leading whitespace when reading a character per specifier %c? 
What line of code indicates this?  And, same question for reading a
string per specifier %s.  Does it skip leading whitespace, and what
line(s) of code indicate this?

Consistent with the fscanf spec,
altFscanf doesn't skip leading whitespace for %c.  Line 135 assigns
the next char into the target of the associated char *, regardless of
its content.  But, lines 156-157 in the %s handling code skip
whitespace before reading a string.


call on line 136, given that the character was already assigned on
line 135?

For consistency with the other
switch branches and the altUngetc on line 182.  Every format
specifier results in a “character too many” being read, and we
always assume sym contains the next unused input character.

So, what if the format string itself contains a
space?  Does that have any effect on the scanning process?  What
lines cause the effect if so?

Lines 173-175 cover this case, and
the effect is to skip any whitespace in the input.   This is
consistent with the fscanf spec – space in the format string causes
whitespace in the input to be skipped,  This makes no difference for
format specifiers like %s and %i, which already skip leading
whitespace.  But, in both altFscanf and fscanf, there is an important
difference between format string “%c” and “ %c”.  The latter
will skip leading whitespace before reading the character.

What happens if the format string includes
nonblank, non format specifier content?  For instance, what if we use
a format specifier of “Hello %i”?  And, what line(s) enforce
this?

altFscanf will expect the
non-specifier text to be matched exactly in the input.  The input
will have to be literally “Hello”, followed by optional
whitespace and then an integer.  Lines 176-177 enforce this,
requiring the next symbol to match the format character if the
character is not a space or a format specifier.




is called thus: altStdin,

and immediately hits EOF, does it return EOF, or 0?  Trace the code
exactly to justify your answer.

Line 128 will set sym to EOF, and
lines 174-175 will run due to the space in the format string.  But,
the while loop will be false so sym will not change.  Line 180 then
advances format to point to the terminating NUL, so the main loop
exits, with ok = 1 and matched = 0, but sym == EOF.  The test on line
184 is thus
true,
and the line returns 0


and lines 125-126 in .
 Why are the 
lines needed in order for the .c
prompt-and-reply to work properly?  What would go wrong
without them?

The line 9-10 prompt would be
buffered, and not necessarily appear on screen as a prompt until much
later, when sufficient output into the altStdout buffer caused an
altFflush call.  Normally output buffering is “invisible” to a
human user, even for screen output, because the program runs so
quickly.  But, when the program pauses for a typed input, any content
buffered for standard output must be flushed to be visible.  


and other input functions have similar logic, forcing a flush of the

buffer before doing their input.

A final question, just to be sure you follow the
logic of the %i handler in altFscanf.
What would it take to handle a %o format specifier
(which reads an integer in octal)?  How would it differ from the %i
handler?

We'd need to change '9' to '7',
testing for digits in the 0 to 7 range, and we'd need to change the
10 factor on line 145 to 8, so that we increase the placevalue of
existing digits by a factor of 8 instead of 10, before adding in the
next digit.  









	
	
	
	
	
	
	






In this lecture segment we'll discuss some Unix
system calls for creating and managing processes.


	
	
	
	
	
	



Let's start by clearly defining what we mean by
In Unix or any other operating
system, a process is a running instance of a program.  That's not
quite the same thing as just “a program” because one program,
e.g. the vi editor or the C compiler, might have many different
simultaneous running instances on the same machine, e.g. if there are
multiple users each running their own vi sessions and compilations.  
Each running instance is a process.  While several processes running
the same program would have the same code and thus the same text
segment, they would each have different data segments and stack
segments, making them separate instances of the program.
A fair number of system calls deal with processes,
including system calls to create new processes, to track their
execution, resource utilization, etc., and to shut them down in an
orderly fashion.  The OS kernel has an internal data structure, the
, usually a big array of
structs, that has detailed information on each running process.
Unix and most other operating systems identify
each running process by an integer .
 Most system calls that work with processes use a process id to
identify the process in question.  You can obtain the process id for
the current running process via system call getpid
as on line 14 here, which returns the current process
id.  That's our first example of a system call that deals with
processes.
Each process is created by some other process. 
Processes thus have a parent/child relationship.  (There is one
“grandparent process” called ,
with process id 1, that is automatically started at system boot, and
has no parent – more on 
later.) 


So, how does one process create another?  Via one
of the two most interesting system calls in the Unix API – .
 (The other is ,
which we'll cover in its different forms in a later topic.)  As you
can see on line 11 of our example code, it's a simple call to make:
it takes no parameters, and returns an int.  



call  the current process.  It
might better have been named “duplicateMe” or “cloneMe”.  The
result of a successful 
call is a new child process that is a perfect duplicate, including
code, global data, heap, and RTS, of the parent process that created
it.  

It's important to understand the impact of such a
duplication.  The child process will “begin life” with data,
heap, and RTS state that are exactly as if it had run from the start
and made a 
call (because that's what the parent process' state looks like as of
the 
call, and that state is duplicated in the child).  After that, the
child runs independently, and its state and that of the parent
process may diverge.  The child doesn't 
run from the start of ,
but it  it did, since its heap, RTS,
etc are just as if it had done so.
It's a little like one of those Star Trek episodes
where someone steps into the transporter, and due to some glitch is
duplicated into two people, each with identical bodies and memories. 
The duplicate he's the original,
since he has all the original's memories.  Both the original and the
duplicate step out of the transporter thinking “Wow, that was
weird, and who's that other guy that looks like me?” :)
In our code example, this means that while one
process (the parent) calls ,
that
callOne call results in two returns,
in two different processes.  We might diagram that by duplicating the
code, with the parent process on the left, and the child on the
right.  The parent really is returning from the fork,
and the child thinks it is, too. This takes some
practice to correctly visualize, since we're so used to seeing a
given body of code as one running process.  Perhaps duplicating the
code in the diagram here will help.  Remember that after a successful
,
there will be two processes, each running the same code, with
initially identical data (though, again, their data may start to
diverge after the 
call).  

OK, so then what keeps the two processes from
behaving absolutely identically after the return from fork?

difference between the parent and child, and it has to do with the
return value of .


Fork returns one of three possible values.  If it
fails, it returns -1.  This can happen, for instance, if a user is
allowed only a limited number of processes (which is a common
precaution) and if the 
call would exceed that limit.   A successful fork returns the process
id of the newly created child process, or it returns 0.  The former
return value is what the parent process gets, informing it of its
child's ID.  The 0 value is what the child gets.  And this is the one
and only way in which each “transporter duplicate” can determine
whether it's the original, or just a
copy with carefully duplicated memories.  But, this difference is
enough to  let us make a major if-else branch based on the 
return, and thus cause completely different post-fork behavior in the
two processes.  Virtually every program that does a 
call tests the 's
return value, and behaves very differently depending on whether a
nonzero process id is returned, or 0 is returned.  An if-else like
that on lines 11-30 in our code example is typical.  The first branch
handles the (unlikely) error case.  The second branch is run only by
the parent process, and the final else-branch is run only by the
child process.
Why duplicate a parent process like this, instead
of having a system call that takes the name of an executable file and
simply starts a new process running that executable from the start? 
Because, as we'll see, it allows a parent and child process to
cooperatively set up various configurations before the child goes on
to run another program.  If the child has all the parent's knowledge
and data to begin with, this helps it set things up before starting a
new program.  The aforementioned 
system call (actually a family of related calls) does start a
different executable from scratch, but it's normally called by the
child process after some setup is done post-,
as we'll see in a later topic.

fork
call.   They are two different processes, but since
both are printing to the same screen, their outputs will mingle, as
in the diagram.  And, so we can see the code at a larger resolution,
I'll drop the second diagram copy now, and we'll instead just keep
two red arrows going, representing the current location of the two
different processes running the same code.  Don't forget that those
two arrows represent entirely different processes, each with their
own copy of all data.
The parent and child begin with printfs on lines
14 and 23, respectively.  Evidently the parent gets a bit ahead of
the child, printing first, though the child might have gone first in
a different run.  Both branches run concurrently, but which one runs
faster is unpredictable; they're different processes and the CPU may
run one or the other depending on how the operating system schedules
it.  This is an important principle: two
different processes may run at unpredictably different speeds. 
A surprising number of bugs in multiprocessing code, and especially
multithreading code (a later topic) result from this fact.  

The parent process announces the process id (from
now on, “pid”) of the child, as well as its own.  It then drops
into the for-loop on lines 15-17, and gets at least a start on it
before the child process finally completes its first printf,
announcing its pid, which of course matches the value returned from
the parent's 
call.


which we can see shows at the start of the output from line 14 in the
parent process.  That's not surprising.  Line 9's output would have
been buffered by the 
call since it's an incomplete output line (ref our earlier lectures
on the standard I/O library and buffering of incomplete lines) . 
Then when line 14 finishes the output line, the buffered line-9
output and the line-14 output get printed together.  


printed at the start of the child's line-23 output?  Didn't we say
earlier that the child does  start from
the beginning of main, but instead is a duplicate that starts life at
the 
call, with a copy of the parent's data?   Did the child also do line
9, and why if so?

The child never ran line 9.  The
reason it showed the line 9 output is that the stdout buffer used by
printf is part of the data that is duplicated by fork.  So, the child
started life at line 11 thinking “Yeah, I just did a partial-line
printf – look, you can see it in my stdout buffer.”.  But that's
just a “duplicated memory”.  Line 9 is only executed once, by the
parent.  In the child, it's just an “implanted memory”. 



This stuff really does get SF-ish.  This case,
with its implanted-memory metaphor, is reminiscent of some Philip
Dick novel like We Can Remember It For You
Wholesale Total
Recall was based).  SF aside, though, it's a good example of the
subtlety of ,
and of multiprocess reasoning.
Proceeding on through the code branches for the
parent and child, we can see that each of them does a similar loop,
on lines 15-17 or 24-28.  These are just busywork loops, counting up
to 200 and announcing as each multiple of 50 is reached.  And, to be
redundantly clear, both are running at the same
time in different processes.  The interwoven child and parent
prints on lines 38 and 39, for instance, illustrate this.
But, the child's version is designed to be slower
than the parent's.  The 
system call on line 27 makes the calling process stop running for the
number of seconds specified by its parameter.  This ensures that the
child pauses for one second after each 50 counts, so the parent
finishes well before the child.  (Technically, that's not guaranteed
– a bizarre fluke of CPU scheduling might still cause the parent to
run so slowly that the child beats it despite four 
calls, but that's vanishingly unlikely.)  So, as you can see, the
parent finishes its loop before the child even gets to count 50.
If we commented out lines 19-20, then the parent
process would perform the line-18 printf, announcing its completion,
and then proceed to line 31 and end.  The child would work through
the rest of its slower loop, and ultimately reach line 29, returning
from main and ending as well.
But, that's not the way parent/child process pairs
usually interact.  Generally a parent checks for the completion of
its children.  It might be that the children are doing some
subcomputation on which the parent relies, or that a child process is
running a command on behalf of a parent shell process, and the parent
shell needs to wait for each command to complete before starting the
next.  Even if there is no practical reason for a parent to wait till
its child processes end, it's considered good form for it to do so. 
Management of processes is more orderly if each parent ensures that
any children it created via 
end properly.  In the next lecture segment, we'll look at how that's
done, with this 
call on line 19.




	
	
	
	
	
	
	






wait



	
	
	
	
	
	
	


So, picking up from the prior segment, how can our
parent process know when the child is done?,
as on line 19.  This system call, as its name implies, waits for a
child process to end (any child process, though we have only one in
our example).  
returns only when this occurs, and it returns the pid of the child
that ended.  We refer to the parent “waiting for the child” or
“doing a wait”.
So, in our example, even though the parent process
races ahead of the child and finishes its loop early, it stops on
line 19, in that 
call, until the child ends by returning from its main on line 29. 
Then the parent prints the return value of ,
which as you can see on line 46 is the child's pid, as advertised.
If a parent has several children, resulting from
multiple 
calls, then it must 
for each, via separate 
calls.  In general, every successful 
must be paired with a 
call (or with one of its variants – see the next question).

,
and its various alternate versions, and answer: 

a. What happens if a process that has no children
does a 
call?
for
a particular child, instead of just waiting for the next one
that finishes?

If there are no child processes, or
if all of them have ended and been “waited” for already, then
wait returns -1 and errno will indicate that there were no children. 
If you want to wait for a particular child, use system call waitpid,
one of the variations of wait.


There are almost a half-dozen wait variations,
with different parameters and rules.  Know where to look them up if
you need them.

Returning to our example, there's one more value
the parent prints: the child's .
 returns,
via the integer pointer parameter passed to it, the exit
statusexit
code plus some other flags. Every Unix process provides an
integer either as the return
value from its ,
or via the system call ,
which as the line-29 comment indicates has roughly the same effect as
returning from main:
it ends the program with the specified exit code.  

can be called from anywhere in the program, unlike a return from
. 
If you don't do an explicit return from 
or an 
call (a common sin in many programs) the result is a random-garbage
exit code.
The meaning of an exit code depends on the program
– each follows its own rules.  A common convention, however, uses 0
to indicate “all's well” and nonzero values to indicate various
errors.  Exit codes aren't usually visible to a human user of a
program; they're used by parent processes to determine the outcome of
child processes, and sometimes by shell scripts to determine the
result of commands run from the script.  If you want to see the exit
code of the most-recently run program, use this command in the Unix
command shell.
echo
$?


onto a Unix system, and run the command ,
first on two identical files, so there are no differences, then on
two files that do not match, and finally try giving it just one file,
which will cause an error message.  What is the exit code of 
in each case?

Diff exits with 0 if the files
match, and with 1 if they do not.  In the error case, it returns 2.
Wait returns the exit status of the child via an
integer out-parameter (&amp;status
in our code).  The exit status is just a single int,
but it's broken into various parts at a bit level.  8 of its bits
hold the exit code.  (And this means that exit codes can only be from
0 to 255.)  The other bits indicate whether the child exited normally
or as the result of some fault, and what kind of fault if so.  

You don't need to hack around with bitwise
operators to decipher the exit status and get the exit code from it. 
There are macros for everything you want to do.  For instance, on
line 20 the parent uses the 
macro to get just the child's exit code (42, from the line-29 return)
from the exit status and print it.
By the way, the terms exit code and exit status
get mingled a lot in practice, which can be confusing.  In our
lectures, we'll stick with the terms as defined here, but don't be
surprised to see them used somewhat interchangeably in practice.

What macro operates on
the exit status to determine whether the child exited normally or by
some runtime fault?

WIFEXITED(status) 


Unix requires that every child process be waited
for by some process, even if not its parent.  If a parent dies
without waiting for its children, then they become orphan
processes (Unix process terminology gets very whimsical).  The

process (pid 1) “adopts” any orphan processes, and waits for
them.  


is the ultimate parent of all other processes – it's a wonder it
wasn't named “Grampa” or some such.  It's the only process not
created by 
– the OS starts it automatically as part of the boot procedure. 
s
first job is to create any other needed processes, such as servers
for SSH connections, webservers, etc., to configure the network
interfaces, and to do various other system startup housekeeping. 
You'll get more on this in a Unix-based OS course.  Once that work is
done, 
settles down into an endless loop of 
calls, cleaning up any children not waited for by their parents.

has done the requisite 
call for it, the child process continues to live as an entry in the
process table, though without any running code or data.  In this
not-quite-dead state it is termed, unsurprisingly, a zombie
process.  Zombie processes don't eat brains, but they do eat
the limited space in the process table.  A parent that keeps running,
but doesn't wait for child processes that it created, can rack up
quite a few zombies, since they don't get adopted by 
unless the parent dies.  We'll see a few ways for this to happen by
accident in the next segment.  For now, the takeaway lesson is, be
sure to do a 
call to match each 
call you do.






	
	
	
	
	
	
	






In this lecture segment we'll look at various
deeper issues related to fork and multiprocessing.


	
	
	
	preemptive and
	nonpreemptive scheduling



is the most dangerous system call in the Unix API.  Improper use of
it can cause an explosion of processes, potentially bringing down the
OS itself.  There are some safeguards against this: users often have
a process limit that stops them from creating too many running
processes.  But these are not always turned on, and they're not
foolproof, as we'll see.  To illustrate how easy it is to do
destructive things with ,
consider these questions (AND DO NOT EXECUTE THE CODE IN THEM, EVEN
AS AN EXPERIMENT):

What does this code do?  How many processes are
created, how long do they run, and what is their relationship to each
other – who's the parent, who's the child?





The parent process will endlessly
spawn child processes, all siblings of one another.  Fortunately each
child process will exit the loop immediately since its fork call
returns 0, and it will end.  And hopefully the endless-loop silence
you get by running the rogue parent will prompt you to control-C it
quickly.

Since the children exit so quickly, at least the
process table won't get all choked up with processes by this rogue,
right?  Right??

Wrong.  The parent process does not
wait for any of the children, so this is a fast way to jam the
process table with zombies.  Killing the parent will finally cause
init to adopt the zombies and wait for them, but that process table's
gonna fill awful fast in the time it takes  you to do that control-C.

OK, so what about this one? 






Here, the parent  will spawn a
child, and then exit immediately.  It's child will do the same, and
so on.  The result is an endless sequence of single parents, each
dying immediately after giving birth.  There is always just one
process doing yet another fork call, with all its parents having
died.


Is it any better than what we did in question 1?

As far as jamming the table, yes
it's better because each dying process immediately gets inherited by
init since the process' parent has already died.  The result is init
busily waiting for all the dead parents, while the sole (and
constantly changing) living child  cranks out new generations.

So, we just kill the one runaway process, and
we're good, right?  Right?? 


Wrong.  The problem with this
scenario is that the process needing killing changes hundreds of
times a second as each new generation is forked and the old one dies,
like some fast-mutating virus.
Depending on the particulars, stopping this
runaway can require rebooting the OS.
Even writing this stuff in a text document is like
publishing the DNA sequence for smallpox.  Be really careful with
process creation.


call opens up some interesting discussion.  Does the 
code have some kind of loop where the operating system checks the
current time over and over until 1s has elapsed?  

do
{
check
the current time;
}
while (not waited one second yet)


No.  One second is a long time in CPU-land –
enough for a billion machine language instructions.  Any such loop
would consume a lot of CPU time, checking millions of times.  

Waiting for some event by repeated loop-check is
called  and it's a Bad Thing. 
The OS performs that 
call by marking (in the aforementioned process table) a flag saying
“don't even run this sleeping process until a full second has
elapsed, which will be at such-and-such a time”. 

If the OS doesn't spin-wait, then how does it
“know” when a second has passed?  How does the current time get
tracked?  The OS sets up a regular hardware-generated timer
interruptcoming typically once every
1/100th of a second.  When handling this interrupt, the OS does
housekeeping for all processes, including checking whether a sleep
time has completed and the process may be run again, and also
switching the CPU between different runnable processes so they all
get a fair share, and appear to be running in parallel.  (As you
probably know, at least in a one-CPU machine, only one process is
being run at any time, but if the running process changes as
frequently as once every .01s, they all appear to run at the same
time.)  

You'll learn a lot more about this in an OS class,
but for now it's worth a couple of in-lecture questions.

I just said that spin-waits were a Bad Thing –
in capitals no less – but now I tell you the OS gets interrupted
all the time by this timer interrupt.  Isn't that just as bad as a
spin-wait loop?

It's very important to get
perspective on relative times in the OS world.  To us, any
blindingly-fast time, from .01s to 1 nanosecond , all fall under the
category of “too fast to see”.  But they're very different in
practice.  If a CPU can run 1 billion instructions per second – one
per nanosecond – then it can run 10 million instructions between
timer interrupts.  That's a lotta instructions.  Timer interrupts at
.01s intervals are about as bothersome to the CPU as a weekly check
of a task list would be to you or me.  By contrast, a spin-wait would
occupy the CPU completely, like having to constantly watch a boiling
pot, and it wouldn't be able to do anything else.


Even if the CPU is running some user code, the
timer interrupt makes it jump to the operating system code for
timer-interrupt handling.  This way no user process can monopolize
the CPU, say in some long computing loop, with no chance to run OS
code that might switch the CPU to some other process.  Your program
may decide to compute the value of pi to infinite precision, but
within 1/100th of a second it's gonna be interrupted, the CPU will
forcibly jump to OS code, which code may decide it's time for you to
take a break and for the CPU to move on to some other process for a
while.  This is called ,
and operating systems that do it (which is to say all serious,
general purpose operating systems) are called preemptive
operating systems.   

nonpreemptive
operating systemOld versions of
Windows and Mac operating systems (
old, as in Windows 3.1 or pre-OSX Mac) were nonpreemptive, as are
some modern specialized operating systems including, importantly,
s.
 These are designed for embedded software where some processes
must have noninterrupted CPU time.  (You don't want the emergency
gimbal control routine on the rocket interrupted mid-calculation
because “someone else should get the CPU now”.)

So, speculate a bit: in a non-preemptive OS, when
 the CPU change to a different process? 
You gotta be running kernel code for this to even happen; a user
program won't do it.  But there's no timer interrupt, and no kernel
code to handle a timer interrupt.  Where in the kernel code does the
“let's check and see if we should switch running processes” code
appear?

Generally speaking, on every system
call.  Any time a user process makes a system call in a nonpreemptive
OS, that's the OS's chance to check on whether sleep times have
elapsed, the CPU should switch to a new process, etc.  In effect, one
of the first lines of code in any system call in a nonpreemptive OS
is some function call like DoScheduling().  But, if a user process
doesn't make a system call, then like a senator filibustering a bill,
it can indefinitely keep the CPU, never giving the kernel code a
chance to get a word in.
Again, all of this will be covered in much greater
detail in an OS class.  For now, just understand the terms given, and
the basic ideas.






	
	
	
	
	
	
	






In this short segment we look at the process
environment and the environment parameter, preparatory to using it
with the exec system calls.


	
	




In any operating system, it's useful for a process
to have access to information about the context, or 
in which it is running.  Environment information might include the
name of the computer and the logged-in user running the process, the
home directory of the user, and lists of other important directories,
such as those holding executable commands or loadable libraries.  The
way such information is obtained differs from language to language,
and the exact content differs per operating system, but all C
programs, under any OS, get their environment information via a
parameter to 

The environment parameter, traditionally named
,
is a third parameter after the 
and 
discussed in earlier topics.  Like those parameters, it is ignored if
you don't declare it, but can be used if you do, as on line 3 of our
short example.  

,

is a double 
pointer, and like 
it points to a block of 
pointers, which in turn point to strings.  Also like 's
pointer block, 's
block ends with a NULL pointer.  But, 
has no corresponding integer argument like 
giving the size of its block; the only way to determine the size of
the block is to traverse the pointers in the block, until reaching
the terminating 
sort
of traverse is exactly
what lines 4-5 of our
example do, repeatedly
checking to see if 's
target is non-NULL, and if so printing the string pointed to by the
target, and advancing 
to the next pointer in its block.  (Like ,

can altered by being walked down its block of pointers if you don't
mind losing track of the start of the block.)

The output of that loop shows on lines 10-21. 
These are typical strings in a Unix environment.  All of them follow
the format &lt;key&gt;=&lt;value&gt; where key is a short string,
usually though not always capitalized, identifying the information in
the value.  Looking at a few examples (no need to understand them
all) we can see on line 11 that our command shell is “/bin/bash”,
a common version of the Unix command shell, on line 13 that the user
running the program is “cstaley”, on line 16 that the program's
working directory is /home/cstaley/Modules, etc.

Of particular note is the PATH environment
variable, which as you can see is a series of directories, separated
by colons.  When you execute a Unix command, you are almost always
running some program that resides in one of several directories
reserved to hold executable programs, e.g. /bin, /usr/bin, etc.  The
command 
for instance, is .
 You can type the full pathname if you like, but if you type just
“ls”, the command shell program uses the PATH environment to find
the right directory.  It hunts through the list of directories from
left to right until it finds one that has an “ls” executable in
it, and then it runs that executable.
Interestingly, the command shell will not
automatically run even a program in the 
directory unless PATH includes “.” as one of the directories,
e.g. “/bin:/usr/games:.”  Absent that entry, to run an executable

in the current directory requires writing .
 

Paths, or lists of directories to search, are
pretty common environment variables in any OS.  The command path is
just one example.  For instance, any Java program relies on a
 environment variable to find
class or jar files that it needs.
All of this matters in the upcoming discussion of
,
because several versions of that system call use the PATH variable to
find the executable to be run.

First, get the value of PATH for your personal
Unix account by running the command 
in your command shell.  
works a lot like our example program, printing out the current
environment.  Then, look up the 
command in Unix docs, and use it to determine the location of ,
,
and the C compiler on your system.

There's no general answer here; it
depends on your system.  But, you should have learned that “which”
takes the name of an executable, e.g. “which ls” and tells you
what path directory the executable was found in.

Putting “.”, the current directory, in your
PATH is common enough practice, but only a patsy puts “.” as the
first entry in their PATH (or indeed anywhere in the PATH but as the
last entry).  What could a nefarious user do to you if you put “.”
first in the PATH?  In particular, consider that another user could
place executables of any name in his home directory, which you might
visit.

If the user creates executables, and
puts them in his home directory, giving them names like “ls” or
“vi”, and if you visit his home directory, making it the current
directory, and your PATH looks first at “.”, then you'll run his
executables, whatever they might actually do, when you meant to run
the system commands.  The first directory in PATH that has a matching
executable name is the one that gets used.  You want “.” to be
the last resort directory at the end of your PATH, if you put it in
your PATH at all.


and 
parameters come from?  It might seem that “the OS” is the obvious
answer, but in fact they are set by the process that starts a new
execution via an 
system call,as
we'll see in the next lecture segment.  The 
system calls we'll be looking at provide a means to pass both 
and 
content to a newly started executable.
In the case of the command shell, all the
blank-separated words on the commandline, starting with the command
itself, are passed by the shell as the 
contents to the newly executed command.
Any process starting another executable usually
passes along the same envp
values that it had, perhaps with a few modifications. 
When you log in and start the command shell process, the command
shell runs configuration files that set its environment, and it
passes that environment along to all other programs you run from it.






	
	
	
	
	
	
	







family of system calls.  These system calls are how a brand new
program is started, generally by a forked copy of a parent process.


	
	
	
	


execl,
execlp, execle, execv, execvp,

execvpe,exec
calls, are perhaps the most interesting Unix process control
calls, along with .
 These are the calls that start a new executable from scratch, each
in slightly different ways.

call on line 10 of the code.  This line is done in a child process
due to the fork on line 9.  The child's call of 
takes as its first parameter the name of another executable, in this
case the standard system command 
which simply prints its commandline arguments to the screen.  If you
run the command:
echo
Hello World

Hello
World
That makes it an easy executable to play around
with.  But, any executable could be provided for the first argument,
whether a system command or a user program. 


parameters are commandline arguments for the new executable.  
is variadic, so you may pass as many string commandline arguments as
you like, terminating the list with a NULL.  
then runs 
with the commandline arguments given.
execl

a new processexecl
call causes the child process itself to load the new
executable, wiping out the child's current code, data segment, RTS,
and indeed its entire process space, so that the child process is at
the start of the new 
executable, with no memory of its prior code, data, etc.
Another SF metaphor may be useful here.  An exec
call is a a complete
replacement of personality and memories with an alternate personality
and memories, and one starting &ldquo;at birth&rdquo;. 

So, the complete SF-metaphorical description of
how a new program starts in Unix is: a parent process steps into the
transporter ()
and gets duplicated.  The child initially has all memories (data) and
personality (code) of the parent.  It knows it's the child only by
the return value of .
 After possibly doing some preparatory setup, examples of which will
appear in later lectures, the child then steps into a brainwipe
machine (an exec call) and steps out as a brand new person, starting
as a baby (a process starting at main).


failed.  Exec calls can fail, e.g. as the result of a bad filename
for the first parameter.  They return -1 upon failure, and they set
.
 But our code doesn't even check this return value; it simply
announces an error.  Why is this reasonable?  Don't we at least need
an if-statement to see if the 
failed?

Because if the execl succeeds, there
is no way line 11 will be executed.  It can only happen if the execl
failed.  Execl replaces the entire child process space, current code
and all.  This includes the RTS and any memory that we just called
execl   


is odd in that one process makes the call, and two processes return
from it.  By contrast, an exec call is odd in that one process makes
the call, and if the call is successful, 
process returns from it.  If you return from it at all, that means
you didn't get your process space wiped and replaced, which means the
exec failed.  If you step out of the brainwipe machine and your first
question is &ldquo;Was the brainwipe a success?&rdquo;, the answer
is... uh, no! For this reason it's common practice to put error
handling directly after an exec call, with no check of the return
value.

Assume you are running a program that was started
via 
per our example.  In the new program, a call of 
returns your pid, which is 1234.  How would you get the pid of the
process that provided your commandline arguments?

Thisi s a bit of a trick question,
really.  The pid of the process that provided your commandline
arguments is 1234, because YOU arranged your commandline arguments by
passing them to execl, just before YOU brainwiped yourself.  You
don't remember doing so, of course, but it wasn't your parent or some
other process that did it.  You did.  

Your commandline arguments are like a a note you
wrote to yourself and pinned to your shirt before stepping into the
brainwipe machine.  Like the protagonist in the movie ,
you don't remember writing the note, but it came from you.
An important point to add,
relevant to later discussion, is that any open files you have,
including standard in, out, and error, plus any others you may have
opened, across
an exec call.  So, to carry our analogy a final step further, when
you wake up after the brainwipe, any books you had open at the time
are still there in front of you at the same page.  This allows the
pre-brainwipe code to set up files for the post brainwipe code to
use.

With that introduction, then, let's walk through
the entire Exec.c example.  Note that the particular output shown may
differ from run to run, and from machine to machine, because the
execution speed of the three child processes that we're going to
create may vary.  In our example, we first see the parent announcing
itself at line 14 of the code (line 32 in the output), after the
first ,
printing the child process id of 29170.  That child does the 
call of ,
the output of which appears on line 33.

What happened to the &ldquo;echo&rdquo;
commandline argument from the 
call?  Why wasn't that printed by 

Recall that the first commandline
argument is presumed to be the name of the program being run.  Echo
doesn't print its own name, only the second and later commandline
arguments.\
Interestingly, it is only by convention that the
first commandline argument is the program name.  We could have
replaced &ldquo;echo&rdquo; in that 
call by anything we liked.  The OS does not enforce any rule
regarding the first commandline argument, and in particular it does
not use the first parameter of the exec call as the first commandline
argument.  That first 
parameter is just the filename containing the executable to be run;
it's not a commandline argument.


on line 16, which as you can see is performed by a second child,
created by the fork on line 15.  This version of exec uses the PATH
environment variable to interpret its first parameter, so we don't
need to add 
before .
 
will automatically search the PATH variable for the parent directory
that contains the 
executable.   (Recall that 
is the Unix command to print the current environment.  We'll be using
it to illustrate exec calls that change the environment.)

shows on line 34, because the parent outraces the child process (pid
29171) that was created on line 15.  The result of the 
call by that child appears on lines 36-45.

,
appears on line 20, after a third fork.  The line 22 ,
whose output is on line 35, indicates that the third child has pid
29172, so we've now created three children, with pids 29170, 29171,
and 29172. 

,
but this time it explicitly gives the full executable pathname as its
first parameter, because the 
system call  consult PATH.  And

adds a final parameter letting you pass a new environment.  This is a
double char pointer, pointing to a standard block of char pointers to
environment strings, complete with final NULL pointer.   We've set an
example up in 
on line 7.  As you can see on lines 47-49, this second exec of

prints the supplied new environment.   So, you can see that the
environment a new program gets is determined by the exec call that
starts it, just like the commandline arguments are.

We've illustrated three of the six exec calls,
each with its own rules about PATH, passing the environment, etc. 
You're probably finding it a bit hard to remember them all, but there
is actually some rhyme and reason to their names.  They're all named

followed by some set of suffix letters, having the following
meanings:
p:  Use the PATH environment variable when
interpreting the first argument.
l: Accept commandline arguments as a variadic list
of string parameters after the first argument, terminated with NULL
e: Accept a final double char pointer parameter
giving a new environment
v: (which we did not use in the code) Accept
commandline arguments as a double char pointer to a block of
pointers, like ,
instead of as a variadic parameter list.  This is useful when the
number of commandline arguments may change or must be dynamically
computed.
Not all possible combinations of these exist: all
you have are the six exec calls given at the start of the lecture.

Some combinations wouldn't even make sense.  Why
would you 
for instance?

Because you can only pass
commandline arguments as a variadic list or as a double char pointer.
 It makes no sense to pass them both ways.

The final loop on lines 27-28 waits for all three
children, per our earlier discussion on parent processes waiting for
child processes.  (If you pass NULL for the status pointer, 
doesn't return status information, just the pid of the finished
child.) The results show on output lines 46, 50, and 51.

Why don't all three of those lines show at the
very end?  And, would it have been possible for all three instead to
show just after line 46?

As mentioned earlier, we cannot
ensure the relative speed at which different processes run.  The
first wait call shows output as early as line 46 because the parent
process has already done all its forks, and has reached the final
loop, before the third child started performing printenv.  The second
child is done by then and a wait returns its PID.  It would have been
possible also for the wait on pid 29170 to be printed on line 47,
since the first child is also done.  The third wait, however, cannot
return until the third child is done, after line 49.

returned before the first child's.  This is perfectly possible.  
only promises to return the pid of some child that is done.  If
several are done, it picks one at random, not necessarily the first
to have finished.


output line have appeared just after line 38?  Which one, if so, or
why not if not?

Sure, the wait for 29170, the echo
process that is done by line 33, might appear any time after that. 
Nothing prevents the parent's output line from appearing in the
middle of the output lines of the first printenv.  The parent and
second child are separate processes, competing for the same screen.


This discussion is meant to show that the order of
operations performed by simultaneously running processes really is
unpredictable.  Never count on processes to run in some order, unless
the first is ed
for before the second is ed.
 Assuming a particular execution order can cause very subtle bugs
that occur only once in a blue moon when the order in which competing
processes run is just right.  Such bugs, where a &ldquo;race&rdquo;
between one process and another (or one thread and another, when we
get to threads) determines whether the bug happens or not, are called
, and they're perhaps the
worst sort of bug to trace and fix, because they're unrepeatable, and
happen only sporadically.




	
	
	
	
	
	
	






In this lecture, we'll look at Unix pipes, which
are a way for one process to write output which is read directly by
another process, without having to use a file.  We'll start by having
a process set up a pipe to itself in this segment, and then progress
to setting up pipes between two processes in the next.


	Interprocess Communication
	(IPC) (v)
	
	


It's often useful for processes to communicate
information from one to another.  For instance, a process might
complete one portion of a computation and relay its results to
another process to do the next portion.  Or a sequence of processes,
each designed to do one step of a complex problem, might want to pass
work from one to the next, in assembly-line fashion.
One obvious way to do this might be for one
process to write information to a file, for another process to pick
up.  This works, but it's slow (recall earlier discussions on the
amazing relative slowness of disk access vs memory access).  Also, it
requires some way for one process to “lock” a file while writing
into it, so the other process doesn't read half-written information. 
Unix provides such means, but they're complex and errorprone to code.
 

Another way to do this might be for the operating
system to arrange for an area of 
that is mapped into both processes' spaces.  We discussed in an
earlier lecture the idea that a single copy of a code segment might
be shared by two processes running the same program.  It would appear
in both of the process spaces, but be only one physical copy of
memory.   A shared memory block would be similar, but would be
readable and by both processes, so
they could communicate through the shared block.  Shared memory is
provided by most versions of Unix, and it's a lot faster than a
shared file, but it has the same locking problem.  A process writing
into the shared memory block needs to lock it so the other processes
don't try to read partially written information.
Shared files and shared memory are examples of
.
 You may have a chance to work with one or both of these in later
courses or professionally.   But for now, we'll start with a less
complex, though still widely useful, Unix mechanism for IPC: the


It's quite common for IPC to take the form of one
process sending a series of data, in queue-like (FIFO) order to
another process.  The sending process writes data at its own pace,
into a queue, usually with some limit on how much can be queued, and
the receiving process reads the data from the queue, again at its own
pace.   If the sending process gets too far ahead, and the queue
fills up, the sending process  –
pauses its execution until there is room for the next data.  If the
receiving process gets too far ahead and attempts to get data from an
empty queue, it also blocks until data is available.  The two
processes might be on the same machine, or they might even be on
different machines.
This arrangement is simpler to keep track of than,
say, two processes commonly updating an array in shared memory in
random ways.  It's easier to coordinate access to the shared data
when one process writes only on one end, and the other reads only
from the other end.  And while such queued IPC is simple, it's
remarkably powerful.

In fact, when you think about it, queued IPC is
far and away the most common form of IPC, and is apparently
sufficient to support the most sophisticated software system ever
created, indeed the most complex intellectual artifact in human
history. You use queued IPC routinely; indeed you're probably using
it 

As is possibly obvious, I'm
referring to the internet.  Every time your browser fetches a page,
or a recorded lecture, from a web server, it uses a form of queued
IPC.  The browser sends a URL (technically a full HTTP get or post
request) in queued order to the server.  The server responds, on a
separate IPC queue with the requested page.
So, queued IPC is good enough for the internet, at
the least.  Internet client and server code arranges its IPC via
system calls that set up an .
 Once again, this is something you may encounter in later courses,
but the pipe we'll discuss is even simpler than that.  A socket
allows queued IPC between processes on different machines, even at
great distance, but a pipe assumes both processes are on the same
machine, and that the IPC queue between them can be set up by a
common parent process.

So, with that prolog out of the way, let's look at
the system calls to create and use a pipe.  We'll start with a
process that creates a pipe and acts as both the writer and reader; a
later example will expand the pipe to go between two processes.

system call on line 10 creates a pipe.  As you can see, 
takes a 2-element array: .
 It fills in both elements of the array with file descriptors; in a
sense it's a “double open” call, returning descriptors for what
the rest of the code will treat as two open files.  Element 
is set to a file descriptor for reading; 
gets a file descriptor open for writing.  Note for instance the 
and 
calls using fds[0]

on lines 11 and 12.
As you can see by the output of line 10, shown on
line 37 of the diagram, the read and write file descriptors for the
pipe are 3 and 4.

Why is it reasonable and not surprising that
exactly those two file descriptor numbers should have been returned
by the 
call?  Why not others, higher or lower?

From prior lecture you know that
descriptors 0, 1, and 2 are for standard input, output, and error,
respectively, and are generally already set up at the start of the
process.  So, it makes sense that the reading and writing ends of the
newly created pipe would be the next two file descriptors in order.



actually opening files?  No.  Recall that “file” is a very
flexible concept in Unix, and 
and 
can work with “files” that are actually keyboards, terminals,
etc.  The 
system call causes the kernel to set up a small in-memory queue, as
shown in the diagram, with a file descriptor (
to write to it, and another ()
to read from it.  To the program it looks like two open files, but

and 
operations to those “files” are implemented as adds to or removes
from the pipe-queue.
So, on line 11, we write 6 characters (including a
terminating ASCII NUL at the end of “Hello”) into the pipe, and
on line 12 we read up to 100 characters from the pipe into .
 As you know from our binary I/O lectures, 
may fail to read as many bytes as we ask for, and it returns the
number actually read, in this case, as you can see by line 13's
output (on line 38), we read just the 6 bytes that were put into the
pipe on line 11.
So, what would happen if we tried to read from a
pipe that had no data, say another 
call on line 14?  The 
call would block: it would not return at all until there was data in
the pipe to return.  In our case, that would result in a deadlocked
process, since we would not be able to do any 
calls while blocked.  Generally, it's another process that is
writing, so this isn't a problem.

to a pipe, but there is insufficient room to accommodate what we want
to write, the 
call blocks until the reader has removed enough data from the pipe. 
(The size of the pipe queue varies per Unix implementation, from 4K
to 64K, generally larger in newer Unix versions.)
When we're done writing to, or reading from, a
pipe, we 
the file descriptors, as for any other file.   Closing file
descriptors changes the blocking behaviors described above.  If all
write file descriptors on a pipe are closed, and if the pipe is empty
of data, then a 
call on the pipe returns 0 without blocking.  As you know from prior
lecture, a 0 return from 
indicates EOF.  So, one may reach EOF when reading a pipe even though
it's not really a file.  But, this happens only when all data from
the pipe has been read,  there is no hope
of future data being written because all writers are closed. 
Otherwise a 
on an empty pipe blocks, as already described.
Writing to a pipe that has no open readers,
whether or not there is room, causes a runtime fault – a “broken
pipe”.  We'll see how to handle this fault in a later lecture, but
for now the effect is to end the process doing the offending write
immediately.






	
	
	
	
	
	
	






In this lecture we show how to get a pipe to
replace standard input and output, and we look closely at EOF issues
on pipes.


	Duplication of fds in
	parent and child
	
	


As we saw in the prior segment, the read and write
file descriptors for the pipe are 3 and 4.  But, what if we wanted to
read from the pipe as standard input, say using scanf
to read the pipe, and write the pipe as standard
output, say using ?
 This would automatically happen if fds 0 and 1 were returned from
the 
call instead of 3 and 4.


and 
know to read/write the pipe in that case?  


Recall that the global-data stdin
and stdout FILE* objects used by scanf and printf respectively are
initialized to work on fds 0 and 1 automatically.  So, whatever those
two fds refer to, that's what scanf and printf will use.

returns, but we can “move” or copy one file descriptor to
another, using the 
system call.  Line 15 shows an example.  
takes two fds as parameters and “copies” the first into the
second.  The line 15 call takes fd 
(3 in our case) and makes fd 0 refer to the same “file”, in this
case the read end of the pipe.  Whatever fd 0 was referring to,
perhaps the keyboard, or a redirected input file, is closed.  After
the 
call, reads from either fd 3 or fd 0 will take their data from the
pipe, as you can see in the diagram, where we've laid out a table of
the fds and what they refer to.  Note that this means two separate
fds can refer to the same source of data, whether it's a pipe or a
file or what have you.  If we don't want two fds open for reading the
 pipe, we need the 
on line 16, which would close fd 3.

That two fds might refer to exactly the same thing
really shouldn't be surprising.  We've seen it before.  Indeed, it
happens in most programs.  Where is this?

Fds 1 and 2 often refer to the same
thing, say the screen.  One is used for standard output and the other
for standard error, but those may both go to the same destination.


The two-call combination on lines 15-16 is thus an
idiom for “change or move one fd to another instead”.  We do the
same on lines 18-19 for the pipe-writing fd, moving it to 1.  As a
result, the line 21 
writes “Talking to myself” into the pipe, and the line 22 
call reads it back out of the pipe, to be printed to .
 




Because writing to stdout would have
fed the string right back into the pipe, and we wouldn't have seen it
on screen.  At this point, the only data going to screen is what is
written on stderr.



is for exactly this purpose – sending text to screen when 
has been redirected.

The prior segment gave some exact rules for EOF
detection on pipes; be sure you understood those.  With them in mind,
let's look at how EOF works in our example.
Lines 23-24 are a commented-out effort to read
past the end of data in the pipe, and thus reach EOF.  Recall from
prior coursework that 
returns NULL if we read past EOF, and recall also that the 
function never returns true unless you have tried to read 
EOF, not just up to it.  (We really can't tell we've hit EOF until an
underlying 
call returns 0 bytes, right?)  So, it makes sense that before testing
for EOF on line 25 we'd do another 
as on line 23.

But, I had to comment out lines 23-24.  Why?  What
bad thing happens if we actually run them?  Reason this out carefully
from the pipe EOF logic from the prior segment.  It's probably the
most important question of this segment.

The program will deadlock, because
that line 23 fgets will do a read call on the pipe, but there is no
data presently in the pipe, but there is still a writer on the pipe
(our stdout), so the read blocks.  

And the program is left there, waiting forever for
the one remaining writer (us, but we're blocked) on the pipe to write
data to it, or to close it, so the 
can either return data or a 0.  

Now, you don't normally run pipes to yourself, but
this kind of deadlock on pipes is still common even when other
processes are the writers.  It's  easy
to set up a situation where one process has a forgotten open fd on a
pipe, and ignores it, neither writing to it nor closing it.  Other
processes reading the pipe end up hanging, waiting for that one
negligent process to “make up its mind”.  As we start adding new
processes to the pipe discussion in upcoming segments, we'll be
painfully careful to track all open writers to a pipe, and close them
when we don't want them.
OK, so now we can see why lines 25-26 do not yet
detect an EOF, as the line 41 output shows. Line 28 does the
all-important 
call, and then we can try reading past EOF, getting NULL, and
successfully checking for EOF on lines 32-33

Could we have omitted lines 29-30 and still gotten
a true from 
on line 33?

Nope.  This is, again, a basic stdio
library issue; the library cannot determine EOF on a stream until a
read call has actually returned 0.  If all we've seen so far are
successful reads, even if the next read is sure to return 0, we don't
know that until we actually try it.  We have to read THROUGH EOF, not
just up to EOF.

on a process that has a pipe open, and see how we can get two
different processes working on the same pipe.






	
	
	
	
	
	
	






In this lecture we extend the pipe concepts from
earlier lectures to create a pipe between a parent and child process.


	
	Duplication of fds in
	parent and child
	Special stdio buffering
	behavior


Our second pipe example program opens a pipe, so
that it has 5 open file descriptors (counting the standard 3 plus the
pipe).  It then immediately does a .
 Recall from earlier lectures what effect 
has on open file descriptors.  


After the fork, how many writers and how many
readers are there on the pipe?

Two of each.  Both the parent and new child will
have both ends of the pipe open, as in the diagram here, where we
assume fds 3 and 4 were returned by the pipe call.
Having multiple readers and writers on a pipe is
perfectly possible, either via multiple fds in the same process, or
via fds in different processes, as would be the case here.  When two
processes write to a pipe, data from both is added to the pipe, but
the order of their writes is indeterminate, and depends on the
relative running speed of the processes.  The same goes for reads;
multiple processes compete to read the same data from the pipe, and
the first one to do so “wins”.  In particular, any given byte is
read by only one reader, not duplicated for all readers.
In most cases, however, a pipe has a single writer
and reader, two different processes, and the writer process
communicates to the reader process via the pipe.  Also, in most
cases, it makes sense for the writer process to move the pipe to the
writer's standard output, and for the reader to move it to the
reader's standard input.
The parent logic on lines 13-20 does just this,
first moving the writer fd of the pipe to standard output via ,
and then doing two closes, one to close the original writer fd, and
the other to close the reader fd of the pipe, which the parent has
open, but does not need.  Let's diagram that process.
After this, the parent repeatedly reads lines from

(presumably the keyboard) and sends them to the child via the pipe,
also printing each onto stderr,
which still goes to the screen, prefixed by “Parent
sends: “.  It's the 
output that shows at the start of the sample run, with input in bold.
The child logic on lines 22-28, similarly moves
the pipe's reader fd to standard input, closing the extra open fds,
and then repeatedly reads lines from the pipe, and prints each,
ending only when the pipe reaches EOF (which will make 
return NULL).  And you can see the outcome in the sample run.

With the right execution order of processes,
what's the largest possible number of file descriptors simultaneously
open on the pipe, during the run of this program?


calls before doing any 
calls, there may be six open fds on the pipe at the same time: three
for reading and three for writing.
After both parent and child logic have done their

and 
calls, we'll have the arrangement shown now in the diagram, with only
the parent writing to the pipe, on standard output, and only the
child reading, on standard input.  


calls?  File descriptors are automatically closed when a process
ends, anyway.  


Perhaps it would have been messy to leave them
unclosed until the end of the processes, but it wouldn't have done
any harm, right?  Or wrong?  And, more exactly, which of the four

calls are just good housekeeping, and which are essential?


calls are cosmetic in this example, but one is not.  The line 24
of

ensures that once the parent process exits (with any of its open fds
closing) there will be no remaining writers to the pipe.  This is
necessary for the 
to return NULL for EOF.  Otherwise any read of the pipe will block
since there is a remaining writer.
When you set up pipes between processes, so many
file descriptors get duplicated that it's easy to accidentally leave
an open writer to the pipe, thus causing readers to hang when you'd
expected them to hit EOF.  Watch out for this error.

Note that the sample output shows the child
process running entirely after the parent.  This is not an accident
of process timing.  It happens every time the program runs, and it's
useful to understand why. 


Thinking about earlier segments regarding stdio
and buffering of ,
when would you expect the first line of output from the parent
process to actually go into the pipe?  (An important note here:
which
the parent uses to read lines from ,
automatically tacks a return onto the end of 
when it reads a line, so the s
on lines 17-18 are printing \n after each “Hello” or “Goodbye”


flushes its buffer at end-of-line, so we'd expect the pipe to get a
buffer-flushing write after the first line of output was -ed,
in other words after the parent writes “Hello”.
But, standard I/O libary code adapts to the actual
type of “file” being written on ,
and is slower to flush buffers when it's writing to a pipe or to a
file than to the terminal.  So since 
is going to a pipe, it may in fact buffer up as many as several
kilobytes, filling its buffer before finally flushing it to the pipe.
 For the small number of lines in our example, the stdout
buffer is unflushed until the parent ends, whereupon

is finally flushed into the pipe for the child to read.  This is
important sometimes when debugging pipe code, where long buffering of
pipe output may surprise you.

If the Unix system we're running on has pipes with
8 Kbytes of space, and we're printing output lines of 80 chars
apiece, how many lines can we print before the 
call blocks, assuming no one is reading the pipe?  Think carefully –
you should conclude that you don't have enough information to give an
exact answer.

A good bit more than the 8K/80 = 102 lines or so
you might have expected.  The 
buffer is local process memory, independent of the pipe, so for

to block, it must both fill the pipe and the buffer.  We'd need to
know how big the 
buffer is to know how many lines we can print before blocking.
Our example keeps things simple by having a pipe
from parent to child, but a far more common pattern is for a parent
to create two children with an interconnecting pipe between the
children.  The first child communicates to the second via the pipe. 
In the next lecture, we'll do this. setting up chains of child
processes, interconnected by pipes.






	
	
	
	
	
	
	






This is the first of three lecture segments in
which we'll combine what we've learned so far about ,
,

and ,
and create a simple command shell application called MiniShell.


	
	Basic data structures for
	MiniShell
	


First, let's look at what MiniShell does.  It
provides a simple version of the Unix commandline interface: it lets
you type commands and commandline arguments, with optional file
redirection for input and output.  Let's try that here.  I'll first
run &ldquo;cat Emails.txt&rdquo;, to show the content of the
Emails.txt file, and then run grep
cstaley Emails.txt to list just those lines containing
the pattern 
Minishell also lets you &ldquo;pipe&rdquo; one
command's output into the input of the next, just like the standard
commandline.  Here's an example of that.  We'll pipe the output of
the 
command through the 
command, to get the lines in sorted order, with the &ldquo;alpha&rdquo;
line first.
A brief review of Unix command shells may be
useful here:
You may have been under the
impression that Unix commandline processing is provided by the
operating system kernel, but this is not so.  Nothing in the Unix
kernel covers commands, redirection, etc.  The kernel supplies only
the system calls needed to set up a series of processes, with pipes
and redirection and commandline arguments.  Some user program must
actually read the commandline, and call the needed ,
,
,
etc. system calls to set up a child process to run a command (e.g.
,
,
etc), or perhaps a piped series of child processes, each running a
different command with interconnecting pipes and/or redirection to or
from files.  




 in Unix terminology.   It is this program, perhaps 100,000 lines of
C code, that you interact with during a Unix text command session. 
This shell program is started by whatever program handles your login
process (e.g. a terminal monitoring program for a hardwired terminal,
or more likely an SSH server program for remote connections).  When
the shell program ends, your login session is over.


There are several versions of the
Unix commandline shell.  The earliest version, called the Bourne
shell, was written for the original early 1970's Unix systems. 
Better versions have since been built, but they all follow the same
commandline syntax, more or less: a series of one or more commands
and arguments, and if there is more than one command, each command in
the series is separated from the next by a '|' symbol, indicating
that its output should be piped to the input of the next in the
series.



A quick question to refresh your
memory on Unix commandlines, if needed.  What does this do?  Try it
out if you need to, and look up the relevant manual entries for grep,
sort, uniq, and wc if you need to.


grep cstaley Emails.txt | sort |
uniq -i | wc -l &gt; count



The grep command
searches for lines containing &ldquo;&rdquo;
from Emails.txt,
his
output is piped into the sort command, which, absent any commandline
arguments, sorts its input and prints the sorted result onto its
output.  This output is in turn piped to the uniq command, which
removes any adjacent duplicate lines.  The duplicate-culled output of
uniq then goes into the wc program which, with
the -l option, counts the number of lines, putting
the result into the file count.  Assuming
Emails.txt is a file of emails, one per line, the whole command
counts the number of unique emails in that file that refer to
&ldquo;cstaley&rdquo;, leaving that count in the
file count.


Here's a quick demo  of that
command, running in the MiniShell program we'll be examining.


Piping of one command into
another is a major Unix feature, and allows creation of a complex
actions by &ldquo;gluing together&rdquo; a series of simpler
commands.


As the review says, a typical shell is a C program
of as many as 100,000 lines.  We'll be reading through MiniShell.c, a
simplified version of under 200 lines, but it will be able to set up
and run a commandline, as we just showed.

So, with that prolog, let's look at the
MiniShell.c code.  Our first slide shows only the basic data
structures for MiniShell.

Minishell keeps track of commandline arguments,
like &ldquo;-l&rdquo;.  Executable names (e.g. &ldquo;grep&rdquo;)
also count as commandline arguments.  We'll be making linked lists of
commandline arguments, so we'll need a suitable node type for such
lists.  ,
on lines 13-16, is that type.   Each 
node holds one string (of at most 100 char length) and a pointer to
the next 
on the list.

,
which means one executable name, possibly followed by arguments, and
possibly filenames to redirect to or from.  A full command line
comprises one or more commands, separated by pipes.  We'll represent
such a line with a linked list of 

type on lines 19-25 has a count of commandline arguments, a list of
the actual arguments, names for input and output redirect files, if
any, and a pointer to the next Command
s
may be put into a linked list.


the head pointer to the argument list, to be NULL?

Never.  There will always be at
least one commandline argument, the executable name, as the code
comment indicates.

There are several utility functions used by the
rest of the program to work with s
and 

on lines 28-35 allocates a new ,
with content from .
 


on lines 38-48, does the same for a new ,
creating just one 
for the executable name as given by ,
and setting input and output file names to &ldquo;&rdquo;.  
Additional command arguments, and in/out filenames, may be added
later to the .
 

,
on lines 51-60, deletes a ,
in particular walking down its 
list and deleting all s.
 It assumes that the 
is the first in a list of s,
and returns the 
that follows it in the list or NULL if this is the last 
in the list.

DeleteCommand, as written,
has a storage leak.  How would you fix it?

It doesn't
delete the Command itself.  And we can't just do a free(cmd)  since
we need to return cmd-&gt;next.  So, we'd need something like:
static Command
*DeleteCommand(Command *cmd) {   Command *rtn =
cmd-&gt;next;      temp
= cmd-&gt;args;     
free(temp);

s,
pointed to by head pointer ,
how would I delete them all, using 

in just a two-line loop?

while
(cmdList != NULL)
   
cmdList = DeleteCommand(cmdList);



is meant to be used this way &ndash; passing it a head pointer, and
then using its return value as the new head pointer, thus deleting
the first 
on the list.

We have two major functions yet to go:

which reads in a pipe-separated sequence of commands and returns a
pointer to a list of 
structs representing them, and RunCommands,
which sets up a series of child processes to run the
commands in a 
list, with pipes going from each process to the next.  

We'll go over these in the next two lecture
segments, but first let's look at the overall main,
on lines 175-188.  The line-179 loop continues until
EOF on ,
prompting the user with &ldquo;&gt;&gt; &ldquo;, and then calling
If
there are any commands, 
returns a non-NULL head pointer to a list of s,
which we then run via .
 (
returns NULL if it hits EOF without seeing a command, so we don't
call 
in that case.)  Then we delete the list of s,
using the code just discussed under Question 3.








	
	
	
	
	
	
	






In this lecture segment we'll look at the

function that reads a commandline and creates a list of 
nodes representing it.


	



code, let's use this as an example commandline:
grep cstaley &lt; Emails.txt | sort | uniq -i &gt;
filtered
It's substantially similar to the example in the
prior segment, but includes an input redirection (grep searches its
standard input if no file is provided) and has only two pipes instead
of three.


starts by reading a blank-delimited string of at most 100 characters.
 If this exists, 
uses it as the first command, returning NULL otherwise.  Lines 72-73
create a new 
node, and point both 
and 
to it.  
is the head pointer we'll ultimately return from the entire function,
but 
will point to the final 
on the list as we read the line.  Similarly, 
points to the last argument in the 
list of the current .
  So, here's a picture of the situation after lines 72-73.  These two
pointers make it easy to tack a new argument onto the end of the
current 
list, or a new 
onto the end of the current list of 

uses 
and a passed-in FILE pointer .
 This makes it possible to modify MiniShell to accept commands from a
file in the future.  For now, we always pass 
to 


operates “word by word”, taking each blank-delimited word from
the commandline in turn.  Words can be commands or arguments, but
symbols like '&lt;', '&gt;', and '|' also count.  Lines 80-81 skip
any blanks, leaving the next nonblank in .
 If that is the end of the line or EOF, we're done with the
commandline and we jump to the test on line 107 which will exit the
word-reading loop.  Otherwise, lines 86-106 decide what to do with
the word.

Just to be sure you've got that, how many
iterations will there be of the line 79-107word-reading loop for the
example command?

11.  grep, cstaley, &lt;,
Emails.txt, |, sort, |, uniq, -i, &gt;, and filtered.

What's with this blank-skipping on lines 80-81? 
Couldn't we just use, say, fscanf(in, “ %c”, &amp;nextChar)?  The
space before the %c would cause whitespace skipping.  Why do we have
to do this by hand?

We want to end the commandline when
we see '\n'.  Standard fscanf whitespace-skipping skips '\n' as well
as ' '.  And, we want to put EOF into nextChar if we hit that. 
Standard fscanf wouldn't put EOF into the character being read in.




do if the input line is blank?  Does it return NULL?

No, the fscanf on line 71 will skip
all whitespace, including returns, hunting through blank lines until
it sees something to read or hits EOF.


is a pipe symbol.  We'll cover that case in a moment.  First, let's
cover the false case. If 
is not a pipe, it's either a redirect or an argument.  In either
event, line 95 's

back onto the input so we can read the entire argument.  (This will
also make it easier to modify this code later for multicharacter
redirection tokens like &gt;&gt; or &gt;&amp;.)  Line 96 then reads
the next word, including the first character.  Lines 97-98 check if
it's an input redirection, and if so they read the next word,
presumably the input filename, into the relevant field of the current
.
 Lines 99-100 do the same for output redirection.  Lines 102-103
handle the default case of another command argument, tacking it onto
the end of the current 
list, and moving 
to point to the new .
 These are the lines we'd execute next in our example, creating a new

thus.  And, on the next iteration of the word-reading loop, we'd hit
the '&lt;', which results in reading “Emails.txt” into ,
thus.

The real shell is tolerant of missing spaces in
some cases.  For instance, one may write sort
&gt;outsort
&gt; out

Our shell is quite dependent on
space-separators, and in the case cited, would interpret &gt;out as a
single commandline argument to sort.

Returning now to the case of a pipe symbol, lines
88-90 scan for the executable name of the next command, and use this
to create a new Command, linking it to the end of the Command list on
line 89, and updating lastCmd to point to the new “end of list”
by chained assignment on that line.  Line 90 updates lastArg to point
to the last argument of the new Command.  That's all it takes to
handle a pipe at this point.  The fact that one Command follows
another on the list will signal 
to set up a pipe between them.
Be sure you understand the data structures we've
set up here.  
will use them intensively.  And, it would be a good exercise to
complete them for the rest of this commandline example.




	
	
	
	
	
	
	






In this lecture segment we'll look at the core
function of MiniShell: .
 This is where all the fork,
exec 
calls happen.


	
	
	walkthrough
	Reality checks on the
	significance of 
	calls.



walks through the 
list, via the big for-loop on lines 122-168, which forks and execs a
child process for each command.  As it does so, it keeps track of any
pipe or file from which the next child process should read, and it
creates any new pipe into which the child process should write for
the next command. 


is the fd of either the read-end ofa prior pipe or a file from which
the new child process should read, 
is the fd of any pipe or file to which it should write.
And, a note on diagrams for this discussion. 
There's a lot of tracking of open fds in code like this, so I'll use
white rectangles for each process, including the parent, to show open
fds.  Within each rectangle we'll have the executable name, and 7 or
so fd numbers, with arrows pointing either for
writing, or  for reading, whatever that
fd represents.  I won't show fds as variable-boxes, by the way, since
at least within the process space they're merely numbers. 

So, we start with just MiniShell, and its three
open fds.  And we'll walk through the same example command as for
,
keeping the list that was set up there in mind.  (Consult those notes
if you need a reference; repeating the linked list here would clutter
the diagram too much.)


to each 
in the 
list in turn.  For each ,
lines 123-127 do prefork setup.  Lines 123-124 open a file for input
redirection if one exists, and if there's not already an established
input fd (e.g. a pipe from a prior command).  For our example, there
is an 
string, &ldquo;Emails.txt&rdquo;, and so we'll open fd 3 on that
file, and store that in 
Then, lines 126-127 set up a new pipe if there's a

after the current one.  
always has the fds of the pipe to the next
,
not the pipe from the prior one.  The only remnant of the pipe from
the prior 
is the 
variable, which has the fd of that prior pipe's read end.
,
for the 
program, and so we'll set up a pipe to feed that process when we get
there.  
will have 4 and 5, and we'll show 's
fds 4 and 5 reading from and writing to that pipe, respectively.


Assuming a successful fork, we now have two
processes, both with the same open fds.   I'll add &ldquo;child&rdquo;
to the name of the second so we can tell them apart.  As you can see,
we have a real forest of open fds now.  We'll need to trim a lot of
those.
The parent process runs lines 132-138.  Line 132
increments a count of the number of successful child processes in

so we'll know how many 
calls to do at the end.   Then we do some fd-trimming.  Line 133
closes since
that is not going to be read by the parent, but by the child, who
already has a copy.  And lines 134-136 deal with any outgoing pipe to
the next ,
closing its write end, since it is the child who will be writing to
it, not the parent.  And, we record the fd of its read end in the now
liberated for
the benefit of the next child process on the next loop. 


Why did we wait till here to do lines 134-136? 
The new pipe was open up at line 127, and nothing's been done to 
or 
in the interim; could we have moved lines 134-137 up after line 127
inside the if-statement?

Remember to think in terms of two
processes.  No, the parent isn't using pipeFDs or inFD directly, but
the child created by fork will use both, so they both had to be
correct until the child was forked.  The fact that the child's code
is lower down may make it seem like the child code will run later,
but it runs right after the fork, in parallel with the parent, and it
will need the original inFD and pipeFDs duplicated by that fork. 
Once the child is fired off, with copies of those variables, then the
parent can safely update inFD and close pipeFDs[1] to prepare for the
next command.

So, is line 135 just good housekeeping, or will
omitting it cause some bug?  What bug, if so, or why not if not?

Omitting it leaves an extra writer
on the pipe.  Per earlier lecture segments and in-lecture questions,
this means that readers on the pipe will hang rather than get an EOF,
since the extra writer implies the possibility that more data will be
added to the pipe.
This one is worth the repetition; it's a very
common error.  When (not &ldquo;if&rdquo; -- everyone does it at some
point :)) you make a mistake like this, causing read-hangs on a pipe,
look for accidental extra open writers on the pipe.

So, what bad thing would happen if we dropped line
133?  A hint: it won't happen right away.

It wouldn't block the pipe.  Extra
readers are OK.  But, it would tie up an fd in the parent, and would
tie up a new one each time we created a new pipe and assigned its
read end to inFD.  You're only allowed so many open fds, so at a
certain point open and pipe calls would start to fail for lack of
available fds.
This is a classic nasty bug in these sorts of
programs, where lots of fds are flying around and being duplicated
across 
calls.  Keep  careful track of your fds
in such code; be sure all of them get closed at some point.

On the child side, lines 140-143 first move any

(file redirect or incoming pipe) to fd 0, so becomes the .
 

Then lines 145-151 determine whether a special
output fd is needed, storing it into outFD

 Lines 146-149 check if there is a next command and if we should thus
output to pipeFDs[1].

to 
close our copy of 
if so.  (We won't be reading the pipe; the next command will.  Here
again is an example of how careful you have to be to clean up those
extra fds.)  Lines 150-151 check for output file redirection, opening
the file if so, and setting 
accordingly.

If we redirect output to an existing file, do we
add to the present file contents?

No.  The O_TRUNC flag means we'll
wipe out any existing file contents.
This is consistent with the real shell's behavior,
too, and something to watch out for.  &ldquo;&gt; myfile&rdquo;
effectively includes an &ldquo;rm myfile&rdquo;.

?
 Why did we wait to do them in the child instead of doing them before
the 
as part of pre-fork preparation?

Opening outFD in the parent would
require closing it in the parent after the fork, which is extra work,
but even more importantly, we can't close pipeFDs[0] in the parent. 
The read end of the pipe must remain open in the parent to be given
to the next child.
This kind of parent vs child reasoning,
considering what has to remain open in the parent, what can be done
in just the child, etc. is critical to this type of code.

descriptor, then lines 154-157 move it to ,
and at that point we're ready to do an exec.  Our input is coming
from a file, in this example, and our output is going to the next
command's pipe.

list and create from it an -like
data structure suitable for passing to 
on line 166.

Follow lines 160-162 carefully, and draw the data
that results.  In particular, think about what the target of each
character pointer will be.  Is it an allocated block?

Sort of.  The code creates a block
of character pointers, and points them to strings, but the pointers
point directly to the value fields of the Arg structures in the args
list, so the strings here are not independently allocated character
blocks, though they are part of larger allocated data blocks (the Arg
nodes).

doesn't care where the character pointers point as long as they lead
to valid strings containing the command line arguments, so this is
fine.


of that ed
block.  That's a storage leak, right?  How should we fix it?

If I got you thinking about how to
do a free call, you fell for a trap.  We're about to do an execvp
call.  This will wipe our memory clean, including the entire runtime
heap.  When you're about to be brainwiped, you really don't need to
worry about tidying up your runtime heap.

What if the executable we're about to run is like
one of those we've written in the past that chews up its commandline
arguments, messing them all up by modifying 
and the strings it points to?  Won't that mess up the 
fields of the 
list?

Did I get you a second time?  The
args list is heading for the big bit bucket in the sky.  After line
166, it's not gonna exist.  

Note this means the OS kernel must do some careful
copying of whatever data 
is pointing to, moving it down into the bottom of the RTS of the 
post-exec process image.  This is one of the tasks of the 
system calls.  


OK, but what about those
pipes we carefully set up in earlier code?  What's the point of
having them if the 
is about to wipe them out?

Recall from
the discussion of exec that any open files, and this includes open
pipes, remain open across an exec call.  This is intentionally so; it
lets pre-exec code set up files or pipes for the post-exec code to
use.


get used twice in the 
call?  The second parameter is the argument list, fine.  But what's
the first parameter for?

The first argument is the executable
file name.  This happens also to be the first commandline argument,
so we get it via *cmdArgs. 

So, now that we've done the exec call, the diagram
should show our child process running ,
drawing input from ,
and feeding output to the pipe.

Now, take what we've done so far, and extend it
through the next iteration of the loop, including fd diagrams and
all, up to the point where we exec 



2. Lines 126-127 create a new pipe,
probably with fds 3 and 5 (recall 4 is still open on the earlier pipe
3. After the fork, we have a new
child MiniShell process with the same 6 open fds as the parent.
4. Parent closes fds 4, the input
from the old pipe, and 5, the output to the new pipe.  It then saves
3, the new pipe input, in inFD.
5  Child closes fds.  First, it dups
fd 4 (the old value of inFD as of fork) onto fd 0 and closes fd 4. 
Then, it saves 5 into outFD and closes the pipe read fd 3.  Finally,
it dups 5 onto fd 1 and closes 5.
5. Exec runs sort, with input from
the first pipe, and output to the second.  And the parent has inFD of
3, ready to give to the third command as its read fd.
.
 This big loop sets up as many child processes as needed, with pipes
between them, redirection arranged, etc.  They all run together to
perform the command line.

One last concern: won't MiniShell reprompt the
user once 
returns?  What if the child processes are still doing their work at
that time?  Might the new prompt get mixed up with any output they're
doing?

The wait loop on lines 171-172
ensures that RunCommands doesn't return till all the child processes
have completed, so there's no problem.

Now that we've seen how standard commands are
executed by ,
this is a good time to discuss a special category of shell command. 
As an example, let's look at how logging out of a command session
works.   Real shells often permit you to end the login session with a
command &ldquo;logout&rdquo;, instead of EOF. 


which
logout in a  command shell.  What happens?  Given what
we've seen so far, would you expect 
to be a C program that the shell runs, like ,
,
etc?  If so, what would its code look like?

The &ldquo;which logout&rdquo;
should fail, because logout is not a separate program.  If it were
run as a separate program in a child process, it would have to kill
its own parent. In principle, one could
design a program to do this, but it would cause a sudden, disorderly
end to the shell, and an orphan child process.

command is directly interpreted by the shell, not run as a child
process.  This illustrates an important general idea in command shell
design: some commands, called 
are performed directly by the shell.  Usually these are commands that
affect the shell program's state directly (like whether it keeps
running or not), which is something hard or impossible to do from a
child process.  



works as described.  It only takes two lines.

One simple way to do this is to add,
inside the first if-statement of main:
if
(!strcmp(cmds-&gt;args-&gt;value, &ldquo;logout&rdquo;))



And that completes our
discussion of MiniShell.  A real shell has a lot more to it, but
these &lt; 200 lines of code cover the core concepts, and are a good
model for any code you might write that sets up cooperating processes
that communicate via parent-arranged pipes.




	
	
	
	
	
	
	






In this lecture segment we give a brief overview
of Unix signals and some associated concepts in process management
and shell job control.


	
	
	Signal types: SIGKILL,
	SIGQUIT, SIGSEGV, SIGPIPE, SIGINT, SIGSTOP, SIGCONT (v)
	
	


The ideal model of a program running from start to
end does not always hold true.  There are a number of events that
might interrupt, either temporarily or permanently, a program's
execution before it finishes.  Some of these you're already aware of;
others you might not be.

We'll look at how a program may control its
response to such “interruptive events” in a bit, but first let's
review a few types of interruptive events.
A number of special keystrokes can cause
interruptive events.  Under Unix, and other OS's, you can end a
program by hitting control-C.   A second program-ending keystroke,
more rarely used, is control-\
Both control-C and control-\ generally end a
program's execution.  The keystroke control-Z, by contrast, 
a program, and the program's execution may later be resumed.  All of
these keystrokes qualify as interruptive events.
Runtime errors are also common interruptive
events: seg faults, bus errors, illegal instructions, etc. 


qualify as interruptive events.  Most operating systems, including
Unix, let a process request that it be interrupted after some time
has elapsed, or be repeatedly interrupted at some regular interval. 
This lets programs do such things as update clocks, advance
animations, etc.

In Unix, interruptive events of the types just
discussed are called .  Unix
recognizes several dozen types of signal, and has an integer
numbering system to identify each type.  For instance, the signal
resulting from control-C has id 2.  Memorizing the signal numbers is
not generally needed though, since each signal also has a name, and a
defined constant of that name to represent the signal number.  Just
include 
as on line 2 of our example code, and you can use any of these
constants, and quite a few more defined in the docs:
SIGINT, the signal for
control-C (value 2)
SIGQUIT, the signal for
control-\ 

SIGSTOP, the signal for
control-Z
SIGCONT, a signal for
resuming a paused program.
SIGSEGV, the signal for
segmentation fault
SIGPIPE, a signal sent
when the program writes to a pipe with no readers.
SIGALRM, an alarm
signal


These all apply to any version of Unix; there are
some more specialized signals that appear only in certain Unix
versions.

When an interruptive event occurs, the kernel
“sends a signal” to the process in question.  Sending a signal
can have several effects depending on the signal, and on how the
process is configured.  In most cases (SIGINT, SIGQUIT, etc) the
default result is that the process terminates immediately.  In some
cases (SIGSTOP, SIGCONT) the process may be paused, or may resume
running.
In almost all cases, however, a process may
determine what happens when some signal is sent to it, overruling the
default action.  It does so via the 
system call, like the three calls on lines 18-20 of our example code.
  (Include header 
to use this call.) The signal
call takes an int constant designating a signal, and a
pointer to a  function to be
called when that signal occurs.  The OS will call the signal hander
when the signal occurs, instead of ending the process.

Let's see how this works in our example program. 
Lines 18-20 make three 
calls to provide handlers for the signals for control-C, control-\,
and for reawakening the process after a control-Z.  The signal
handler functions must take one int and return void, with the one int
parameter being the signal number that occured.  This allows one
handler to deal with multiple signal types, as 
does, for instance, responding differently based on whether the
signal was SIGINT or SIGQUIT.
As you can see from lines 22-24, all our example
program does is endlessly count upward, announcing each multiple of
100,000,000 that it reaches.  However, the sample run includes not
just output from 
but also a full shell command session, during which we attempt to
kill, pause, etc. the running program.  

On line 30 of the output, after the program has
reached 100,000,000, we attempt to control-C it.  The result, rather
than termination, is a function call to signal handler ,
because of the 
call made on line 18.  
gives a sassy message, and returns to the main loop.  There's no
particular point in the line 22-24 loop where 
is called; the code simply jumps there from whatever machine language
instruction it had just completed as of the control-C, and it returns
to the next machine language instruction after running 

The same happens, with a slightly different sneer,
when we try to control-\ the program.
But, control-Z still does work to pause the
program on line 34 of the sample run.  (You cannot prevent this
pause, even with a signal
call.)  And the line 35 that follows is output from the
command shell, and is part of the shell's job
control

All of the various Unix command shell versions
offer a means of setting up and tracking multiple running programs,
or “jobs”.  At any given time, at most one foreground
program gets input from the terminal, and the others are either
paused (as ours presently is) or are run in the background,
meaning they continue to run as long as they need no input.  
The shell builtin command jobs,
as on line 36, lists all currently running or paused
programs, with a  for each. 
This job number is distinct from a process id; it's a shell-provided
number.  You can tell the shell to resume any paused program in the
background via the command bg
%# where # is the job number, or to resume it in the
foreground with fg
%#, as we do on line 38.  


Resuming a paused program, whether in the
background or the foreground, sends it a SIGCONT signal.  Normally
this does nothing – the program just resumes running.  But, you can
intercept it, as we did on line 20.  In our case we just print a
message, but a more practical use might be to do display updates or
other delayed housekeeping upon “awakening”.

Not all signals can be sent via keystrokes, and
even those that can be sent that way can also be sent via the command
. 
This command should probably have been named “sendSignal”, but
since most signals result in the process dying unless a handler is
set by ,
“kill” is probably appropriate enough.  This kill
command sends signal &lt;signal&gt; to the process with
id &lt;pid&gt;.
kill
-s &lt;signal&gt; &lt;pid&gt;
where &lt;signal&gt; is a signal number or name. 
On line 42 of our sample run, we once again pause the process, and
then list all current processes using the 
command, to get our process id.  This shows that our 
process has pid 4008.
On line 48, we send our process a SIGINT
(control-C) signal via .
 Waking it back up with 
(which wakes the most recently paused process, if given no argument),
we see it both gets the 
signal, and our SIGINT


Do a bit of research on ps, and find out how to
list all processes on the system, not just those for the current
user.

ps -a will do this.  The ps command
is remarkably useful; it's worth learning about its options.


As a final step, we pause the process yet again,
and then on line 54 send it signal number 9 (also named SIGKILL). 
This signal cannot be given a handler by 
or any other means.  It  results in
process termination, and is thus the process-killer of last resort
for processes that are otherwise ignoring all signals.


to cause a signal to be ignored completely, not even calling a
handler?

Pass SIG_IGN as the handler value. 
But, this doesn't work for signal 9.


There's a lot more to signals than this quick
intro, but this much should at least give you what you need to handle
most signals.




	
	
	
	
	
	
	






A repeated theme in this course is writing
programs that meet a numerical standard for elegance or conciseness. 
It's not enough to write working code; you must also write code that
is no more complex than some threshold, as measured by a complexity
metric.  This lecture looks at the &quot;code complexity&quot; metric
that's used in this class.


	


The exact rules for the complexity metric are
given in the IHS documentation, linked from any code-based IHS
exercise.   As of this writing the link is
Find
and read this document before going further.  

As the document
explains, the complexity rule assigns complexity
points based on the keywords, variables, and
operations that you use in your code.  For many of the point
assignments, the document also offers rationales that are worth
understanding, partly because they'll help you remember the rule, but
also because they discuss code patterns that are desirable, and not
so desirable.  


Just as a reality check
on your reading, what would the cost of this expression be, assuming
it's not nested inside any loop:

hat might
you do to reduce its cost?

The 5 variable references each cost
one point, the four operands (including assignment) each cost a
point, and each pair of  parentheses costs a point.  So, 11 points. 
But, the parentheses are needless, so we can reduce the cost to 9
points by dropping them.  And, in fact, we can rewrite the expression
as a = (b + c)*d, which has a cost of 8 points.

What's the point of charging you for using
parentheses to group operations?  You can't help the fact that some
operations have higher precedence than others.  What code elegance
behavior does the document say is the rationale for that?

It's meant to keep you from adding
spurious parentheses when precedence will produce the right order of
operations without the parentheses, as for instance in Question 1
above.  Although, interestingly (and intentionally) it's not enough
of a charge to offset the advantage of distributive refactoring, as
when we rewrote Question 1's expression as a = (b + c)*d.

Are these rules meant to push you toward perfect
coding style?  No.  Indeed, there is no such thing as &quot;perfect
coding style&quot; since style is a subjective matter.   People
differ over terseness vs clarity, for instance.  Should I write a
= b &lt;&lt; (c+1) or should I expect the reader to
know that + has higher precedence than &lt;&lt;, and thus simply
write a = b &lt;&lt;
c+1?  Should I use language shortcuts, for instance
writing 
instead of if (a !=
0)a
= b = 1 instead of using two separate assignments?  If
shortcuts are OK, then does anything go?  Is it OK to write a
= 1 + (b = c), because I wanted to sneak an assignment
of a value into 
as a side effect in a larger expression.  (And, btw, you should know
enough of C to know that that's a legal if somewhat obtuse use of an
assignment expression.)
This course's complexity metric tends to favor
brevity, and moderate, though not extreme, use of language shortcuts.
 Some programmers may differ with this choice, but fine points of
style really don't matter, because the main educational purpose of
the complexity metric is to get you to consider different ways to
write your code, and to make it more elegant in broad terms.   

It's been said that &quot;there is no great
writing, only great rewriting.&quot;  (That one's from Louis
Brandeis; you can find dozens of similar comments from many noted
writers.)  Programming is a highly quantitative form of writing, and
as such it benefits from revision as much as standard prose writing
does.  Most writers learn their craft by repeated revision of their
work, and so do most programmers.   Regardless of whether you agree
with every aspect of the complexity metric, the very process of
revising your code to be more elegant is a useful educational
experience, and it'll make you a better programmer.  Any reasonable
set of rules would serve just as well; it's the process of revision
that is the essential point.
That said, please do report any case where the
complexity metric encourages you to do really ugly things.  The
current metric has a number of revisions resulting from just such
reports.   For instance, an early version of the metric counted just
one point for each string constant, which induced people to create
huge, textually-meaningless string constants to hold numerical
tabular data in ASCII code form.  Now there's a charge for really
long strings that blocks that temptation.

Let's take a closer look at some of the more
complex point-rules in the metric, both to be sure they're
understood, and to give a bit of rationale for each. 


As you can see from the document, any use of
control-structures (if, loop, etc) gets charged 2 points.  Control
structures already incur the cost of their tests and increments, but
some additional charge seems reasonable just for using a loop or
if-statement, including each additional else-branch in the if.

To be sure you understand how this works, what's
the charge for this if-statement?
if
(i &lt; j)






The test costs 3 points, and the two
bodies cost 2 points each.  That, plus 2 points for the if-statement,
and another 2 for the else branch, comes to 11 points.

There are classic code-complexity metrics, such as
yclomatic

(you can look it up if you like) that in effect charge 
for control structures.  Under yclomatic
omplexity,
a program with no branches or loops gets a complexity of 1,

ach
addition of a loop or if-statement, roughly speaking, adds another
point.   This is justified by the argument that each
control structure adds new possible paths of execution through the
code, and the number of
different execution paths through a program strongly affects its
testability.  But, cyclomatic
complexity has the obvious
weakness that it rate
a 00-line

block of sophisticated mathematical assignment statements as 
complex than a simple 2-line loop.  

We're trying to measure subjective readability, so
counting only control structures doesn't make sense.  A reasonable
compromise seems to be charging for the tests and increment
operations the control structure needs, plus a nod to cyclomatic
complexity by charging another 2 points for the very existence of the
branch or loop.
It also makes sense to charge 2 points for
function declarations on the same subjective-readability basis.  A
function already gets charged for its formal parameters, and for the
actual parameters used in each call of the function, as described in
other areas of the document, but a modest additional charge for just
declaring a function seems warranted.



The x+1 costs 3 points, the use of the function
name sqrt costs another, and the () function-call operation adds a
5

The metric includes a
number of higher-point charges carefully designed to allow certain
coding practices while discouraging abuses. 

For instance, a ?:
operator gets a 4-point charge.  This is much more than the usual
1-point charge for an operator, but the conditional operator is
really an if-statement in disguise. 


The document maintains that a = b &lt; c ? c : b
is cheaper than the equivalent if-statement.  What are their two
costs?  How much cheaper is the conditional expression that its
equivalent if-statement?

The equivalent if-statement is if (b
&lt; c) a = c; else a = b;.  Total charge is 6 points for the bodies,
3 for the test, and 4 for the if and else, totalling 13 points.  By
contrast the conditional expression has 7 points for variables and
operators, plus 4 for the ?:, totalling 11.  So, it's 2 points
cheaper.


Another special charge category is for &quot;flow
breaking&quot; statements like 

or 
not at the end of a function.  Some stylists forbid these altogether
as hard to read.  That's extreme.  But, a 10-point charge makes them
worth using only in cases where they would save at least the cost of
a line or two of code. 


statements, which have an awkward old-school syntax, as anyone who
has forgotten a 
statement within one will testify, but can be more readable than
if-else-if blocks for large numbers of branches.   Switches would
have been effectively forbidden by charging 10 points for each 
statement.  Instead, the 
at the end of each 
is free, but there's a 10 point charge for the switch

wins over an equivalent if-else-if when there are at least 8 else
branches.  Prefer if-else-if for smaller cases.
There are two very high charges to discourage use
of universally disliked constructs.   A 
costs 20 points, and a nonconst global costs 100 points.   In certain
cases the 
might still be worth it, for breaking out of multiple nested loops at
once, but only if the alternative loop-test logic is quite complex. 
The noncost global will never be worth it.

One of the more complex rules in the complexity
metric is that code within a loop gets surcharged by 20%.  And the
20% is compounded for each further loop nesting.   This means that
code inside of four nested loops is surcharged by a factor of (1.2)4,
and is thus nearly twice as expensive as it would be standing
alone.  

The obvious rationale is that complex loops,
especially deeply nested ones, are hard to understand, and you should
factor as much code out of loops as possible.
There is no nested-code charge for if-statements. 
Reducing code in an if-statement almost always involves removing
duplicate lines from both the if and else branch, and putting them
before or after the if-statement.  The cost reduction of removing one
copy of a line is adequate incentive to simplify if-statements.

Lengthy functions also get a surcharge.  Like
nested loops, this takes the form of a compounded percentage applied
to the entire complexity count for the function.  There's no penalty
for functions with up to 250 complexity points, but there's a
gradually increasing penalty that doubles every 250 points
thereafter.
The penalty computation is rather complex as you
can see from the document &ndash; it's 1.0035,
but ideally you should never need it because the main point is to
keep your function complexity under 250 points.  

Why not just make it a hard limit?  Because
experience has shown that any hard limit on function complexity
results in much carping about having to break up functions that are
just slightly over the limit.  (&quot;Couldn't you just raise it to
260?&quot;) A gradually increasing penalty avoids this.  For
instance, a 260 point function costs you just a 10 point penalty, so
you can push the boundaries a little if you really want to.  But not
by much: 300 point function costs you an extra 57 points, for
instance.








In this lecture we'll walk through an exercise in
reducing code complexity, per the complexity metric discussed
earlier.


	
	


For our example, we'll use a program that
identifies sorted sequences within a series of input integers.  We'll
implement this program using the IHS interface for coding exercises. 
(That's IHS V1 as of this writing; you may hopefully have a better
version by the time you view this, but it will have the same
functionality.) 

If you haven't already, please register as an IHS
user, and enroll in the course IHS workbook for coding elegance, in
which the sorted sequences problem should be the first exercise. 
Read the IHS documentation for coding exercises (which will be linked
from that first exercise).  I'll bring up the IHS V1 version of the
problem here.
As the program description indicates, we're tasked
to write a program that reads a series of integers and reports how
many &quot;sorted sequences&quot; (sequences of rising or equal
value) there are in the series, and the length of the longest such
sequence.
Be sure you understand the spec.  And, as you
should  do with any IHS
coding exercise, review the supplied test cases.  The visible test
cases are 
as concrete examples to elucidate the spec.

With the task at hand understood, let's take a
first crack at a solution.  

Here's a reasonable if somewhat wordy
implementation.  It reads a first integer and tests to see if the
read succeeds.  Assuming there is at least one integer, it then loops
on lines 9-22.  Each iteration of that loop body finds one sorted
sequence.  
tracks the number of such sequences found, and 
tracks the length of the sequence currently being found.  The inner
loop on lines 11-19 endlessly scans for a 
integer, and if that scan succeeds, and results in an integer that is
still in ascending-or-equal order with the 
integer,    then we make the new integer our 
for the next iteration, and we increment 
to reflect the longer sequence.
Otherwise we break out of the sequence-tracking
loop, copy,
which is now the start of the next sequence, into prior

sequence.
Finally, on lines 25-32 we print the results,
dealing with the special requirement that we use &quot;one&quot; and
singular form when there is only one sequence and/or when the longest
sequence has only one integer.  This requires an irritating four
different possible printf formats, and attendant code complexity, not
to mention some pretty long lines.
Let's submit our inelegant solution to IHS and see
what happens.... Our code has a total complexity of 150 points, which
doesn't even meet the &quot;low&quot; bar of 110 for this problem,
and sure doesn't meet the &quot;high&quot; bar of 96.  Hmm.

OK.  So, let's improve this code, step by step. 
You may already see lots of ways to improve it, and you should feel
free to strike out on your own at this point if you like, getting it
down to that 96-point target.  But, if you prefer, here's a more
guided approach in the form of in-lecture questions, working from the
top of the program downward.

It's remarkable how often people will do a general
test prior to a while loop, when the loop itself could take care of
the test.


on line 7 is redundant, given the 
just under it.  How can we remove it?

Just drop line 7 altogether.  If the
test is false, the while loop won't execute anyway.


OK, that bought us 5 points.  Just under 50 to
go..

As the prior lecture on code complexity pointed
out, 
statements are not cheap.  Indeed, some shops would summarily reject
code like our little endless for-loop, in a code review.  Let's
redesign that loop into a 
with a test that continues the loop as long as the sorted sequence
continues, and has no break statement.

Do that redesign.  You may find you need to
duplicate the 
call to make it work.  That's OK for now; we'll fix it in the next
step.

The simplest answer involves moving
the sequence-continuation test up into a while condition, and doing a
scanf both in advance of the loop, and at the end in preparation for
the next iteration.


OK, that got us a nice 12 point improvement.  It's
a shame to have to duplicate that scanf,

and the inner if-else certainly made it worthwhile.

.
 If you use an assignment as an expression within the while
test, you can do this pretty easily.  And under our
complexity rules, that counts as a &quot;good&quot; use of an
assignment-expression, so we'll be charged just 1 point for it, not
4.

Reduce the complexity by removing the duplicate


Putting the res = scanf(&quot;%d&quot;,
&amp;next) into the while test as an expression allows one scanf to
serve for both the first iteration and later ones.


That gets us another 7.5 points or so.  And this
is about as far as you should go with nested assignments, lest you
trigger the 4-point rule.  And, it's good style, as I did in my
answer, to put the constant first (e.g. 1
== ....) to make it clear that you are testing the
result of the assignment expression, and to cause a compile error if
you neglect the needed parentheses around the assignment.

We're down to 127 points &ndash; just 33 to go. 
The next step is to look at the conditional operator for updating
.
The lecture on code complexity showed that a conditional operator is
priced to be cheaper than the equivalent if-else.  , this
is only true if we need an .
 



using an 
instead of the ?:.

A simple if can replace the ?:, and
the result is about 5 points saved.
If you're using a conditional operator when one
branch is just a &quot;noop&quot; decision, a small if-statement is
clearer, and cheaper per our rules.  If you count out the points, the
?: costs 12 points, and the if-statement costs only 8. 


If we reduced the complexity by just 4 points, why
did it drop by about 5 points?

The code in question is in a loop,
and thus gets a 20% surcharge.  Simplifying loop bodies is a bit more
valuable than simplifying code outside a loop.

The final item to fix is that ugly 4-way if-else
for formatting the output.  Any time you get an &quot;all
combinations&quot; if-else like that, it's worth trying to refactor
it so that each choice is handled by a smaller if-else.  In our case,
we can break the single printf into two printfs, one for the first
part of the line, and the other for the second. 


Think through how to refactor that if-else block,
and see if you can get the complexity down by 28 points, reaching the
goal of 96 points.  You should end up with two much simpler if-elses,
replacing the complex four-branch if-else-if.

If we print the output up to &quot;...
subsequence,&quot; as one if-else, and the part after that as a
second if-else, we'll only need to test 
and 
one time each.  And the printfs will have fewer parameters, and
shorter strings that don't exceed the over-40-character long string
charge.
Submitting that, we see we've reached the optimal
cost of 96 points.

This is just one example of the sort of code
improvement you need to do to meet the complexity standards in many
of the IHS exercises.   As you do exercises like this, focus on
finding many different ways to write the same code.  It's not a
matter of finding the perfect way the first time, so much as having
thought of a variety of ways to do the code, and then picking the
best one from them.
And, remember that the investment in elegant code
will stand you in good stead in professional work.  In both job
interviews, and internal code reviews, elegant concise code commands
respect.






